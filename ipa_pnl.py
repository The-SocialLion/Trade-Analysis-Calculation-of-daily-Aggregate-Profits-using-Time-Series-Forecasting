# -*- coding: utf-8 -*-
"""IPA-PNL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p-54TQFfWs54Gi5IfOCe6j6uH-ne2Or9

# **Trading Analysis performed using Profit/Loss(c) as main feature**
"""

pip install ta

import pandas as pd # Library to process the dataframe
import numpy as np # Library to handle with numpy arrays
from zipfile import ZipFile 
from ta import add_all_ta_features # Library that does financial technical analysis 
import fastai.tabular # Library that does date factors
import plotly.graph_objs as go  # Import the graph objects 
import os # Library that locates the respective files or folders and processes them
import time # Library that handles time and processes the same
import datetime # Library that handles datetime and processes the same
import sys # Library that handles all system functions like exit , etc
import random # Library that handles all functions like randomise etc
import warnings # Library that handles all the types of warnings during execution
warnings.filterwarnings("ignore") # Ignore all the warnings

zipf=ZipFile('CV task.zip')
zipf.extractall()

for dirname, _, filenames in os.walk('/content'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

"""### **Stage-1**

### **The below two code cells are dedicated to provide the best permutation based on profit and loss**

**The below code cell operates using User input(UI)**



**Note:** 

**1) The format of input should be HH:MM:SS am/pm**

**eg: 08:45:60 am**

**2) The format of time should be in local time format based on zone followed by am/pm as this algorithm consists of a built in 24 hr clock convertor which converts the same if necessary.**
"""

def data_preprocess(df1,sim):
  df1['SIM']=str(sim)
  df1=df1.dropna(how='any')
  df1['Entry DateTime'] = pd.to_datetime(df1['Entry DateTime'])
  df1['Exit DateTime'] = pd.to_datetime(df1['Exit DateTime'])
  #df1['Day']=pd.to_datetime(df1['Entry DateTime']).dt.day
  #df1['Month']=pd.to_datetime(df1['Entry DateTime']).dt.month
  #df1['year']=pd.to_datetime(df1['Entry DateTime']).dt.year
  df1['Time(Entry)']=pd.to_datetime(df1['Entry DateTime']).dt.time
  #df['Time(Exit)']=pd.to_datetime(df['Exit DateTime']).dt.time
  df1['DOW']=pd.to_datetime(df1['Entry DateTime']).dt.day_name()#Type of day of the week
  df1["Entry DateTime"]=df1["Entry DateTime"].dt.strftime("%y-%m-%d")
  df1['Time(Entry)']=df1['Time(Entry)'].astype(str)
  df1['Time(Entry)']=(df1['Time(Entry)'].str.split(':').apply(lambda x: int(x[0]) * 60 + int(x[1]))).astype(int)
  df1['Duration']=df1['Duration'].astype(str)
  df1['Duration']=(df1['Duration'].str.split(':').apply(lambda x: int(x[0]) * 60 + int(x[1]))).astype(int)
  df1=df1.drop(columns=['Symbol','Trade Type','Exit DateTime','Max Open Quantity','Max Closed Quantity','Cumulative Profit/Loss (C)','Exit Efficiency','Entry Efficiency','FlatToFlat Profit/Loss (C)','FlatToFlat Max Open Profit (C)','FlatToFlat Max Open Loss (C)','Max Open Profit (C)','Max Open Loss (C)','Note','Commission (C)','Open Position Quantity','Close Position Quantity',])
  df1=df1.rename(columns ={'Entry DateTime':'Date',}, inplace = False)
  df1['Total Efficiency'] = list(map(lambda x: x[:-1], df1['Total Efficiency'].values))
  df1['Total Efficiency'] = [float(x) for x in df1['Total Efficiency'].values]
  df1['Profit/Loss (C)'] = list(map(lambda x: x[:-1], df1['Profit/Loss (C)'].values))
  df1['Profit/Loss (C)'] = [float(x) for x in df1['Profit/Loss (C)'].values]
  df1['Time(Entry)']=df1['Time(Entry)'].astype(int)
  return df1
  
def process(mn,day):  
   sim=['sim100','sim101','sim102','sim103','sim110','sim111','sim112','sim113','sim120','sim121','sim122','sim123','sim130','sim131','sim132','sim133']  
   dg=[]
   loc=['/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim100 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim101 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim102 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim103 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim110 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim111 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim112 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim113 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim120 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim121 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim122 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim123 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim130 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim131 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim132 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim133 Trades.txt'] 
   for i in range(len(loc)):
     for j in range(len(sim)):
       if i==j:
         t= 'df' + '{}'.format(i)
         t=pd.read_csv('{}'.format(loc[i]),delimiter="\t")
         dg.append(t)
       else:
          continue
   print("\n The total number of permutations files is {}".format(len(dg)))
   df1=data_preprocess(dg[0],sim[0])
   df2=data_preprocess(dg[1],sim[1])
   df3=data_preprocess(dg[2],sim[2])
   df4=data_preprocess(dg[3],sim[3])
   df5=data_preprocess(dg[4],sim[4])
   df6=data_preprocess(dg[5],sim[5])
   df7=data_preprocess(dg[6],sim[6])
   df8=data_preprocess(dg[7],sim[7])
   df9=data_preprocess(dg[8],sim[8])
   df10=data_preprocess(dg[9],sim[9])
   df11=data_preprocess(dg[10],sim[10])
   df12=data_preprocess(dg[11],sim[11])
   df13=data_preprocess(dg[12],sim[12])
   df14=data_preprocess(dg[13],sim[13])
   df15=data_preprocess(dg[14],sim[14])
   df16=data_preprocess(dg[15],sim[15])
   pnl=[]
   te=[]
   fg=[df1,df2,df3,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16]
   for i in range(len(sim)):
    for j in range(len(fg)):
      if i==j:
        l,k=gather_details(mn,day,fg[j],sim[i])
        te.append(int(l))
        pnl.append(int(k))
      else:
        continue
   #print("\n" ,pnl)
   #print("\n" ,te)
   sm=process_1(te,pnl,sim)
   return sm
   #return df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16





def time_valid(tim): # Function to check validity of time
# inputs: time(str)
# ouptut: boolean value
  try:
      time.strptime(tim, '%H:%M:%S')
      return True
  except ValueError:
        return False

def hour_format(str1): # Function to convert the given time in 24 hr clock based on am or pm format
# inputs: time with am/pm (str)
# ouptut: time in 24hr clock
     if (str1[-2:] == "AM" or str1[-2:] == "Am" or str1[-2:] == "aM" or str1[-2:] == 'am') and str1[:2] == "12":
         return "00" + str1[2:-2]
     elif (str1[-2:] == "AM" or str1[-2:] == "Am" or str1[-2:] == "aM" or str1[-2:] == 'am') :
         return str1[:-2]
     elif (str1[-2:] == "PM" or str1[-2:] == "Pm" or str1[-2:] == "pM" or str1[-2:] == 'pm') and str1[:2] == "12":
         return str1[:-2]
     else:
      return str(int(str1[:2]) + 12) + str1[2:8]

def calc_mins(tm):#Function to convert hrs ,mins,secs into minutes
# inputs: time in Hours,minutes,seconds
# ouptut: returns time in minutes

     if int(tm[0:1]) ==0 and int(tm[3:4])!=0 : #if time in am like 03:00:00 then answer should not be zero rather the answer should be 3*60=180 so this condito would oversee the same
        mn=int((int(tm[1:2])*60)+int(tm[3:5])+int(int(tm[6:8])/60))
     elif int(tm[3:4]) ==0 and int(tm[0:1]!=0): #if time in am like 13:06:00 then answer should not be zero rather the answer should be 13*60=180 + 6 so this condito would oversee the same
        mn=int((int(tm[0:2])*60)+int(tm[4:5])+int(int(tm[6:8])/60))
     elif int(tm[3:4]) ==0 and int(tm[0:1] ==0): #if time in am like 03:06:00 then answer should not be zero rather the answer should be 3*60=180 + 6 so this condito would oversee the same
        mn=int((int(tm[1:2])*60)+int(tm[4:5])+int(int(tm[6:8])/60))
     else:
        mn=int((int(tm[0:2])*60)+int(tm[3:5])+int(int(tm[6:8])/60))
     return mn

def gather_details(mn,day,df,s):
# inputs: minutes(int),day(str)
# ouptut: returns the best simulator type(str)
  tf=[]
  sim=[]
  pl=[]
  for i in range(len(df)):
    if df['DOW'][i] == day:
      if int(df['Time(Entry)'][i])<= int(mn):# This condition should be valid due to the fact that say a person whowants to invest in stocks would require the knowledge of the stocks trading in the earlier times(history of profit/loss for the  stock): same principle followed here
          tf.append(int(df['Total Efficiency'][i]))
          pl.append(int(df['Profit/Loss (C)'][i]))
          sim.append(s)
      else:
        continue
    else:
      continue
  if len(tf)!=0 and len(pl)!=0:
    Mt=sum(tf)
    Mp=sum(pl)
    return Mt,Mp
  else:
    Mt=0
    Mp=0
    return Mt,Mp
    
  
def process_1(Mt,Mp,sim):
  i=Mt.index(max(Mt))
  j=Mp.index(max(Mp))
  return sim[j] # Due to the fact that maximum profit/loss is exhibited by this permutation


def get_dataframe(sim):
# inputs: best simulator type 
# ouptut: returns the best permutaion dataframe based on simulator type 
  fn="/content/GC AT IPS(2)+TM(A) 2016-05_2021 {} Trades.txt".format(sim)
  bp=pd.read_csv(fn,delimiter="\t")
  bp=bp.dropna(how='any')
  bp=bp.reset_index(drop=True)
  #bp['DOW']=pd.to_datetime(bp['Entry DateTime']).dt.day_name()#Type of day of the week
  bp['Entry DateTime'] = pd.to_datetime(bp['Entry DateTime'])
  bp['Time(Entry)']=pd.to_datetime(bp['Entry DateTime']).dt.time
  bp["Entry DateTime"]=bp["Entry DateTime"].dt.strftime("%y-%m-%d")
  bp['Time(Entry)']=bp['Time(Entry)'].astype(str)
  bp['Time(Entry)']=(bp['Time(Entry)'].str.split(':').apply(lambda x: int(x[0]) * 60 + int(x[1]))).astype(int)
  bp=bp.drop(columns=['Symbol','Trade Type','Exit DateTime','Duration','Total Efficiency','Time(Entry)','Max Open Quantity','Max Closed Quantity','Cumulative Profit/Loss (C)','Exit Efficiency','Entry Efficiency','FlatToFlat Profit/Loss (C)','FlatToFlat Max Open Profit (C)','FlatToFlat Max Open Loss (C)','Max Open Profit (C)','Max Open Loss (C)','Note','Commission (C)','Open Position Quantity','Close Position Quantity',])
  bp=bp.rename(columns ={'Entry DateTime':'Date','Entry Price':'Open','Exit Price':'Close','High Price While Open':'High','Low Price While Open':'Low','Trade Quantity':'Volume'}, inplace = False)
  #bp['Total Efficiency'] = list(map(lambda x: x[:-1], bp['Total Efficiency'].values))
  #bp['Total Efficiency'] = [float(x) for x in bp['Total Efficiency'].values]
  #bp['Time(Entry)']=bp['Time(Entry)'].astype(int)
  bp['Profit/Loss (C)'] = list(map(lambda x: x[:-1], bp['Profit/Loss (C)'].values))
  bp['Profit/Loss (C)'] = [float(x) for x in bp['Profit/Loss (C)'].values]
  bp['Open']=bp['Open'].astype(int)
  bp['Close']=bp['Close'].astype(int)
  bp['Volume']=bp['Volume'].astype(int)
  bp['High']=bp['High'].astype(int)
  bp['Low']=bp['Low'].astype(int)
  return bp

def bp_process(bp):
# inputs: best permutation dataframe
# ouptut: returns the best permutaion dataframe with perfect stae format
  for i in range(len(bp)):
    tmp=bp['Date'][i]
    tmp="20"+tmp[0:2]+tmp[2:]
    bp['Date'][i]=tmp
  return bp


def welcome(): #  function to initialize
  print("\n Welcome to Stock Analysis")
  print("\n Kindly enter the details with care below")
  day=input("\n Enter the day of the week")
  f1=['monday','tuesday','wednesday','thursday','friday','sunday','Monday','Tuesday','Wednesday','Thursday','Friday','Sunday','Saturday','saturday']
  if day in f1:
    day=day.capitalize()
    if day =='Sunday' or day == 'sunday':
      tim=input("\n Enter the time  in the format (hrs:min:sec) followed by am/pm after a space")# Enter time in normal method like 01:00:00 am or 02:50:00pm and not in 24 hr clock format
      tmi=tim[0:8]
      if time_valid(tmi):
        tm=hour_format(tim)
        print("\n Conversion of the time in 24 hours format (if in pm) hence the time after conversion would {}".format(tm[0:8]))# converting to 24 hr format for ease of comparision with the primary permutation df
        mn=calc_mins(tm)
        if mn>1000:
          print("\n Calculation of the time in Minutes based on the above performed conversion hence the time in minutes would be {}".format(mn))# useful for comparing with the entry time denoted in minutes (converted from 24 hr clock format)
          sim=process(mn,day)
          print("\n The best results for the day {} of the week  during time {} of the day is given by {} the permutation (dataset)".format(day,tim,sim))
          bp=get_dataframe(sim)
          bp=bp_process(bp)
          return bp
        else:
          print("\n Data not valid")
          sys.exit()
      else:
        print("\n Time Format invalid Please try again")
        sys.exit()
    else:
      tim=input("\n Enter the time  in the format (hrs:min:sec) followed by a space, followed by am/pm")# Enter time in normal method like 01:00:00 am or 02:50:00pm and not in 24 hr clock format
      tmi=tim[0:8]
      if time_valid(tmi):
        tm=hour_format(tim)
        print("\n Conversion of the time in 24 hours format (if in pm) hence the time after conversion would {}".format(tm[0:8]))# converting to 24 hr format for ease of comparision with the primary permutation df
        mn=calc_mins(tm)
        print("\n Calculation of the time in Minutes based on the above performed conversion hence the time in minutes would be {}".format(mn))# useful for comparing with the entry time denoted in minutes (converted from 24 hr clock format)
        sim=process(mn,day)
        if sim==-1:
          print("\n Input Data not valid")
          sys.exit()
        else:
          print("\n The best results for the day {} of the week  during time {} of the day is given by {} the permutation (dataset)".format(day,tim,sim))
          bp=get_dataframe(sim)
          bp=bp_process(bp)
          bp.to_csv(r'Best Permutation file {}.csv'.format(sim), index=False)
          print("\n Local copy of the file is saved")
          return bp
      else:
        print("\n Time Format invalid Please try again")
        sys.exit()
  else:
     print("\n Invalid Format of day Please try again")
     sys.exit()
  

bp=welcome()
if len(bp)!=0:
  print("\n Sample prview of the best permutation dataset after performing the necessary processes")
  display(bp)
else:
  bp=welcome()

"""**The below code cell  operates using automation (i.e using the current system date and time and processing the inputs and selecting the best model)**"""

def data_preprocess(df1,sim):
  df1['SIM']=str(sim)
  df1=df1.dropna(how='any')
  df1['Entry DateTime'] = pd.to_datetime(df1['Entry DateTime'])
  df1['Exit DateTime'] = pd.to_datetime(df1['Exit DateTime'])
  #df1['Day']=pd.to_datetime(df1['Entry DateTime']).dt.day
  #df1['Month']=pd.to_datetime(df1['Entry DateTime']).dt.month
  #df1['year']=pd.to_datetime(df1['Entry DateTime']).dt.year
  df1['Time(Entry)']=pd.to_datetime(df1['Entry DateTime']).dt.time
  #df['Time(Exit)']=pd.to_datetime(df['Exit DateTime']).dt.time
  df1['DOW']=pd.to_datetime(df1['Entry DateTime']).dt.day_name()#Type of day of the week
  df1["Entry DateTime"]=df1["Entry DateTime"].dt.strftime("%y-%m-%d")
  df1['Time(Entry)']=df1['Time(Entry)'].astype(str)
  df1['Time(Entry)']=(df1['Time(Entry)'].str.split(':').apply(lambda x: int(x[0]) * 60 + int(x[1]))).astype(int)
  df1['Duration']=df1['Duration'].astype(str)
  df1['Duration']=(df1['Duration'].str.split(':').apply(lambda x: int(x[0]) * 60 + int(x[1]))).astype(int)
  df1=df1.drop(columns=['Symbol','Trade Type','Exit DateTime','Max Open Quantity','Max Closed Quantity','Cumulative Profit/Loss (C)','Exit Efficiency','Entry Efficiency','FlatToFlat Profit/Loss (C)','FlatToFlat Max Open Profit (C)','FlatToFlat Max Open Loss (C)','Max Open Profit (C)','Max Open Loss (C)','Note','Commission (C)','Open Position Quantity','Close Position Quantity',])
  df1=df1.rename(columns ={'Entry DateTime':'Date',}, inplace = False)
  df1['Total Efficiency'] = list(map(lambda x: x[:-1], df1['Total Efficiency'].values))
  df1['Total Efficiency'] = [float(x) for x in df1['Total Efficiency'].values]
  df1['Profit/Loss (C)'] = list(map(lambda x: x[:-1], df1['Profit/Loss (C)'].values))
  df1['Profit/Loss (C)'] = [float(x) for x in df1['Profit/Loss (C)'].values]
  df1['Time(Entry)']=df1['Time(Entry)'].astype(int)
  return df1
  
def process(mn,day):  
   sim=['sim100','sim101','sim102','sim103','sim110','sim111','sim112','sim113','sim120','sim121','sim122','sim123','sim130','sim131','sim132','sim133']  
   dg=[]
   loc=['/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim100 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim101 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim102 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim103 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim110 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim111 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim112 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim113 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim120 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim121 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim122 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim123 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim130 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim131 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim132 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim133 Trades.txt'] 
   for i in range(len(loc)):
     for j in range(len(sim)):
       if i==j:
         t= 'df' + '{}'.format(i)
         t=pd.read_csv('{}'.format(loc[i]),delimiter="\t")
         dg.append(t)
       else:
          continue
   print("\n The total number of permutations files is {}".format(len(dg)))
   df1=data_preprocess(dg[0],sim[0])
   df2=data_preprocess(dg[1],sim[1])
   df3=data_preprocess(dg[2],sim[2])
   df4=data_preprocess(dg[3],sim[3])
   df5=data_preprocess(dg[4],sim[4])
   df6=data_preprocess(dg[5],sim[5])
   df7=data_preprocess(dg[6],sim[6])
   df8=data_preprocess(dg[7],sim[7])
   df9=data_preprocess(dg[8],sim[8])
   df10=data_preprocess(dg[9],sim[9])
   df11=data_preprocess(dg[10],sim[10])
   df12=data_preprocess(dg[11],sim[11])
   df13=data_preprocess(dg[12],sim[12])
   df14=data_preprocess(dg[13],sim[13])
   df15=data_preprocess(dg[14],sim[14])
   df16=data_preprocess(dg[15],sim[15])
   pnl=[]
   te=[]
   fg=[df1,df2,df3,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16]
   for i in range(len(sim)):
    for j in range(len(fg)):
      if i==j:
        l,k=gather_details(mn,day,fg[j],sim[i])
        te.append(int(l))
        pnl.append(int(k))
      else:
        continue
   #print("\n" ,pnl)
   #print("\n" ,te)
   sm=process_1(te,pnl,sim)
   return sm
   #return df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16

def time_valid(tim): # Function to check validity of time
# inputs: time(str)
# ouptut: boolean value
  try:
      time.strptime(tim, '%H:%M:%S')
      return True
  except ValueError:
        return False

def calc_mins(tm):#Function to convert hrs ,mins,secs into minutes
# inputs: time in Hours,minutes,seconds
# ouptut: returns time in minutes
     if int(tm[0:1]) ==0 and int(tm[3:4])!=0 : #if time in am like 03:00:00 then answer should not be zero rather the answer should be 3*60=180 so this condito would oversee the same
        mn=int((int(tm[1:2])*60)+int(tm[3:5])+int(int(tm[6:8])/60))
     elif int(tm[3:4]) ==0 and int(tm[0:1]!=0): #if time in am like 13:06:00 then answer should not be zero rather the answer should be 13*60=180 + 6 so this condito would oversee the same
        mn=int((int(tm[0:2])*60)+int(tm[4:5])+int(int(tm[6:8])/60))
     elif int(tm[3:4]) ==0 and int(tm[0:1] ==0): #if time in am like 03:06:00 then answer should not be zero rather the answer should be 3*60=180 + 6 so this condito would oversee the same
        mn=int((int(tm[1:2])*60)+int(tm[4:5])+int(int(tm[6:8])/60))
     else:
        mn=int((int(tm[0:2])*60)+int(tm[3:5])+int(int(tm[6:8])/60))
     return mn
     
def gather_details(mn,day,df,s):
# inputs: minutes(int),day(str)
# ouptut: returns the best simulator type(str)
  tf=[]
  sim=[]
  pl=[]
  for i in range(len(df)):
    if df['DOW'][i] == day:
      if int(df['Time(Entry)'][i])<= int(mn):# This condition should be valid due to the fact that say a person whowants to invest in stocks would require the knowledge of the stocks trading in the earlier times(history of profit/loss for the  stock): same principle followed here
          tf.append(int(df['Total Efficiency'][i]))
          pl.append(int(df['Profit/Loss (C)'][i]))
          sim.append(s)
      else:
        continue
    else:
      continue
  if len(tf)!=0 and len(pl)!=0:
    Mt=sum(tf)
    Mp=sum(pl)
    return Mt,Mp
  else:
    Mt=0
    Mp=0
    return Mt,Mp
    
  
def process_1(Mt,Mp,sim):
  i=Mt.index(max(Mt))
  j=Mp.index(max(Mp))
  return sim[j] # Due to the fact that maximum profit/loss is exhibited by this permutation



def get_dataframe(sim):
# inputs: best simulator type 
# ouptut: returns the best permutaion dataframe based on simulator type 
  fn="/content/GC AT IPS(2)+TM(A) 2016-05_2021 {} Trades.txt".format(sim)
  bp=pd.read_csv(fn,delimiter="\t")
  bp=bp.dropna(how='any')
  bp=bp.reset_index(drop=True)
  #bp['DOW']=pd.to_datetime(bp['Entry DateTime']).dt.day_name()#Type of day of the week
  bp['Entry DateTime'] = pd.to_datetime(bp['Entry DateTime'])
  bp['Time(Entry)']=pd.to_datetime(bp['Entry DateTime']).dt.time
  bp["Entry DateTime"]=bp["Entry DateTime"].dt.strftime("%y-%m-%d")
  bp['Time(Entry)']=bp['Time(Entry)'].astype(str)
  bp['Time(Entry)']=(bp['Time(Entry)'].str.split(':').apply(lambda x: int(x[0]) * 60 + int(x[1]))).astype(int)
  bp=bp.drop(columns=['Symbol','Trade Type','Exit DateTime','Duration','Total Efficiency','Time(Entry)','Max Open Quantity','Max Closed Quantity','Cumulative Profit/Loss (C)','Exit Efficiency','Entry Efficiency','FlatToFlat Profit/Loss (C)','FlatToFlat Max Open Profit (C)','FlatToFlat Max Open Loss (C)','Max Open Profit (C)','Max Open Loss (C)','Note','Commission (C)','Open Position Quantity','Close Position Quantity',])
  bp=bp.rename(columns ={'Entry DateTime':'Date','Entry Price':'Open','Exit Price':'Close','High Price While Open':'High','Low Price While Open':'Low','Trade Quantity':'Volume'}, inplace = False)
  #bp['Total Efficiency'] = list(map(lambda x: x[:-1], bp['Total Efficiency'].values))
  #bp['Total Efficiency'] = [float(x) for x in bp['Total Efficiency'].values]
  #bp['Time(Entry)']=bp['Time(Entry)'].astype(int)
  bp['Profit/Loss (C)'] = list(map(lambda x: x[:-1], bp['Profit/Loss (C)'].values))
  bp['Profit/Loss (C)'] = [float(x) for x in bp['Profit/Loss (C)'].values]
  bp['Open']=bp['Open'].astype(int)
  bp['Close']=bp['Close'].astype(int)
  bp['Volume']=bp['Volume'].astype(int)
  bp['High']=bp['High'].astype(int)
  bp['Low']=bp['Low'].astype(int)
  return bp

def bp_process(bp):
# inputs: best permutation dataframe
# ouptut: returns the best permutaion dataframe with perfect stae format
  for i in range(len(bp)):
    tmp=bp['Date'][i]
    tmp="20"+tmp[0:2]+tmp[2:]
    bp['Date'][i]=tmp
  return bp


def welcome(): #  function to initialize
  print("\n Welcome to Stock Analysis")
  today=datetime.date.today()
  today=today.strftime('%d %m %Y')
  dy=datetime.datetime.strptime(today, '%d %m %Y').weekday()
  d=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']
  day=d[dy]
  print("The day of the week based on the date is {}".format(day))
  f1=['monday','tuesday','wednesday','thursday','friday','sunday','Monday','Tuesday','Wednesday','Thursday','Friday','Sunday','Saturday','saturday']
  if day in f1:
    day=day.capitalize()
    if day =='Sunday' or day == 'sunday':
      tim=datetime.datetime.now().time()
      tim=tim.strftime("%H:%M:%S")
      tmi=tim[0:8]
      if time_valid(tmi):
        print("\n Conversion of the time in 24 hours format (if in pm) hence the time after conversion would {}".format(tim))# converting to 24 hr format for ease of comparision with the primary permutation df
        mn=calc_mins(tmi)
        if mn>1000:
          print("\n Calculation of the time in Minutes based on the above performed conversion hence the time in minutes would be {}".format(mn))# useful for comparing with the entry time denoted in minutes (converted from 24 hr clock format)
          sim=process(mn,day)
          print("\n The best results for the day {} of the week  during time {} of the day is given by {} the permutation (dataset)".format(day,tim,sim))
          bp=get_dataframe(sim)
          bp=bp_process(bp)
          return bp
        else:
          print("\n Data not valid")
      else:
        print("\n Time Format invalid Please try again")
        sys.exit()
    else:
      tim=datetime.datetime.now().time()
      tim=tim.strftime("%H:%M:%S")
      tmi=tim[0:8]
      if time_valid(tmi):
        print("\n Conversion of the time in 24 hours format (if in pm) hence the time after conversion would {}".format(tim))# converting to 24 hr format for ease of comparision with the primary permutation df
        mn=calc_mins(tmi)
        print("\n Calculation of the time in Minutes based on the above performed conversion hence the time in minutes would be {}".format(mn))# useful for comparing with the entry time denoted in minutes (converted from 24 hr clock format)
        sim=process(mn,day)
        if sim==-1:
          print("\n Input Data not valid")
          sys.exit()
        else:
          print("\n The best results for the day {} of the week  during time {} of the day is given by {} the permutation (dataset)".format(day,tim,sim))
          bp=get_dataframe(sim)
          bp=bp_process(bp)
          bp.to_csv(r'Best Permutation file {}.csv'.format(sim), index=False)
          print("\n Local copy of the file is saved")
          return bp
      else:
        print("\n Time Format invalid Please try again")
        sys.exit()
  else:
     print("\n Invalid Format of day Please try again")
     sys.exit()
  

bp=welcome()
if len(bp)!=0:
  print("\n Sample prview of the best permutation dataset after performing the necessary processes")
  display(bp)
else:
  bp=welcome()

"""### **Stage-2**"""

bp=pd.read_csv("Best Permutation file sim120.csv",index_col=False)
bp=bp.set_index('Date')

bp

bp = bp.reindex(['Open','High','Low','Close','Volume','Profit/Loss (C)'], axis=1)

bp

date_change = '%Y-%m-%d'
bp['Date'] = bp.index
bp['Date'] = pd.to_datetime(bp['Date'], format = date_change)
Dates = bp['Date']

bp = add_all_ta_features(bp, "Open", "High", "Low", "Close", "Volume", fillna=True) #Gathering extra technical features which can be used for predicting the OOS profit/loss 

print(bp.columns)

date_change = '%Y-%m-%d'
# Define the date parts 
fastai.tabular.add_datepart(bp,'Date', drop = 'True')


# Ensure the correct format
bp['Date'] = pd.to_datetime(bp.index.values, format = date_change)


# Add the date parts
fastai.tabular.add_cyclic_datepart(bp, 'Date', drop = 'True')

from sklearn.metrics import mean_squared_error # Install error metrics 
from sklearn.preprocessing import StandardScaler # to scale for ann
# importing all the seven different regression models 
from sklearn.linear_model import LinearRegression 
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.svm import SVR
from sklearn.ensemble import AdaBoostRegressor
from sklearn.ensemble import BaggingRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import ExtraTreesRegressor
from sklearn.model_selection import TimeSeriesSplit
from sklearn.model_selection import cross_val_score
from numpy import mean
from datetime import datetime, timedelta

"""### **Trading Analysis using Profit and Loss as inputs and other features**

**Without Cross Validation**
"""

def CorrectColumnTypes(bp):# Ensure column types are correct
  # Input: dataframe 
  # ouptut: dataframe (with column types changed)

  # Numbers
  for col in bp.columns[1:80]:
      bp[col] = bp[col].astype('float')

  for col in bp.columns[-10:]:
      bp[col] = bp[col].astype('float')

  # Categories 
  for col in bp.columns[80:-10]:
      bp[col] = bp[col].astype('category')
  return bp


def CreateLags(df,lag_size): # Creating lags for prediction os OOS (Out of Samples)
  # inputs: dataframe , size of the lag (int)
  # ouptut: dataframe ( with extra lag column), shift size (int)
  # add lag
  shiftdays = int(lag_size)
  shft = -shiftdays
  df['Close_lag'] = df['Close'].shift(shft)
  return df, shft

def SplitData(df, train_pct, shift): # Splitting the dataframe into train and test
  # inputs: dataframe , training_pct (float between 0 and 1), size of the lag (int)
  # ouptut: x train dataframe, y train data frame, x test dataframe, y test dataframe, train data frame, test dataframe

  train_pt = int(len(df)*train_pct)
  train = df.iloc[:train_pt,:]
  test = df.iloc[train_pt:,:]
  x_train = train.iloc[:shift,1:-1]
  y_train = train['Close_lag'][:shift]
  x_test = test.iloc[:shift,1:-1]
  y_test = test['Close'][:shift]

  return x_train, y_train, x_test, y_test, train, test

def calc_prof_plot(df,shft,pos,bm,train_pct):
  # inputs: dataframe , list,maximum  number of days position(int), best model(str)
  # ouptut: plot,details on a daily basis based on shft list
  disp(pos,shft)
  sfd=shft.copy()
  tpd=[]
  pa=[]
  if bm=='Linear Regression':
    for j in shft:
      print(str(j) + ' days out:')
      print('------------')
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred =LinearRegression_fnc(x_train,y_train, x_test, y_test)
      test2, profit_dollars, td = CalcProfit(test,lr_pred,j)
      pa.append(profit_dollars)
      tpd.append(td)
      if j<=min(shft):
        PlotModelResults_Plotly(train, test, lr_pred, j, 'Linear Regression',shift)
      else:
        print("\n As a lot of API calls occur this leads to crashing of the colab notebook and hence the graphs for the subsequent days are not displayed  ")
    x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
    PlotModelProfit_Plotly(train, test, pa ,pos,'Linear Regression',shift)
    create_dataframe(test,pa,tpd)


        
  elif bm=='K-Nearest Regression':
    for j in shft:
      print(str(j) + ' days out:')
      print('------------')
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred =KNearestRegression_fnc(x_train,y_train, x_test, y_test)
      test2, profit_dollars,td = CalcProfit(test,lr_pred,j)
      pa.append(profit_dollars)
      tpd.append(td)
      if j<=min(shft):
        PlotModelResults_Plotly(train, test, lr_pred, j, 'K-Nearest Regression',shift)
      else:
        print("As a lot of API calls occur this leads to crashing of the colab notebook and hence the graphs for the subsequent days are not displayed")
    x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
    PlotModelProfit_Plotly(train, test, pa ,pos,'Linear Regression',shift)
    create_dataframe(test,pa,tpd)

  elif bm=='Decision Tree Regression':
      for j in shft:
        print(str(j) + ' days out:')
        print('------------')
        df_lag, shift = CreateLags(df,j)
        df_lag = CorrectColumnTypes(df_lag)
        x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
        lr_pred =DecisionTreeRegression_fnc(x_train,y_train, x_test, y_test)
        test2, profit_dollars,td = CalcProfit(test,lr_pred,j)
        pa.append(profit_dollars)
        tpd.append(td)
        if j<=min(shft):
          PlotModelResults_Plotly(train, test, lr_pred, j, 'Decision Tree Regression',shift)
        else:
          print("As a lot of API calls occur this leads to crashing of the colab notebook and hence the graphs for the subsequent days are not displayed")
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      PlotModelProfit_Plotly(train, test, pa ,pos,'Linear Regression',shift)
      create_dataframe(test,pa,tpd)

  elif bm=='Bagging Regression':
    for j in shifts: 
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred = BaggingRegressor_fnc(x_train,y_train, x_test, y_test)
      test2, profit_dollars,td = CalcProfit(test,lr_pred,j)
      pa.append(profit_dollars)
      tpd.append(td)
      if j<=min(shft):
        PlotModelResults_Plotly(train, test, lr_pred, j, 'Bagging Regression',shift)
      else:
        print("As a lot of API calls occur this leads to crashing of the colab notebook and hence the graphs for the subsequent days are not displayed")
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      PlotModelProfit_Plotly(train, test, pa ,pos,'Linear Regression',shift)
      create_dataframe(test,pa,tpd)

  elif bm=='Extra Tree Regression':
      for j in shft:
          print(str(j) + ' days out:')
          print('------------')
          df_lag, shift = CreateLags(df,j)
          df_lag = CorrectColumnTypes(df_lag)
          x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
          lr_pred =ExtraTreeRegression_fnc(x_train,y_train, x_test, y_test)
          test2, profit_dollars,td = CalcProfit(test,lr_pred,j)
          pa.append(profit_dollars)
          tpd.append(td)
          if j<=min(shft):
            PlotModelResults_Plotly(train, test, lr_pred, j, 'Extra Tree Regression',shift)
          else:
            print("As a lot of API calls occur this leads to crashing of the colab notebook and hence the graphs for the subsequent days are not displayed")
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      PlotModelProfit_Plotly(train, test, pa ,pos,'Linear Regression',shift)
      create_dataframe(test,pa,tpd)
   

def disp(pos,shft): # Displays the valid number of days,months,weeks during the model is considered to be valid

   if pos %7==0 and pos %28!=0:
      print("The model can work for {} weeks".format(pos//7))
   elif pos %28==0 and pos %7!=0:
      print("The model can work for {} months".format(pos//28))
   else:
      print("The model can work for {} days".format(pos))

# Regreesion Functions

def LinearRegression_fnc(x_train,y_train, x_test, y_test):
  #inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the predicted values of the test data (list)
  #print("\n Linear Regression Model")
  lr = LinearRegression()
  lr.fit(x_train,y_train)
  lr_pred = lr.predict(x_test)
  return lr_pred



def LinearRegression_fnc1(df,shifts,train_pct):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the  list of values for MSE
  print("\n Linear Regression Model")
  LMSE=[]
  for j in shifts: 
    df_lag, shift = CreateLags(df,j)
    df_lag = CorrectColumnTypes(df_lag)
    x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
    lr = LinearRegression()
    lr.fit(x_train,y_train)
    lr_pred = lr.predict(x_test)
    lr_MSE = mean_squared_error(y_test, lr_pred)
    lr_R2 = lr.score(x_test, y_test)
    LMSE.append(lr_MSE)
  return LMSE




def KNearestRegression_fnc(x_train,y_train, x_test, y_test):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the predicted values for the test data (list)
  #print("\n K- Nearest Neighbors Regression Model")
  knr = KNeighborsRegressor()
  knr.fit(x_train,y_train)
  knr_pred = knr.predict(x_test)
  return knr_pred



def KNearestRegression_fnc1(df,shifts,train_pct):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the  list of values for MSE
  print("\n K- Nearest Neighbors Regression Model")
  KMSE=[]
  for j in shifts: 
    df_lag, shift = CreateLags(df,j)
    df_lag = CorrectColumnTypes(df_lag)
    x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
    knr = KNeighborsRegressor()
    knr.fit(x_train,y_train)
    knr_pred = knr.predict(x_test)
    knr_MSE = mean_squared_error(y_test, knr_pred)
    knr_R2 = knr.score(x_test, y_test)
    KMSE.append(knr_MSE)
  return KMSE

def DecisionTreeRegression_fnc(x_train,y_train, x_test, y_test):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the predicted values for the test data (list)
  #print("\n Decision Tree Regression Model")
  dtr = DecisionTreeRegressor()
  dtr.fit(x_train,y_train)
  dtr_pred = dtr.predict(x_test)
  return dtr_pred

def DecisionTreeRegression_fnc1(df,shifts,train_pct):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the  list of values for MSE
  print("\n Decision Tree Regression Model")
  DMSE=[]
  for j in shifts: 
    df_lag, shift = CreateLags(df,j)
    df_lag = CorrectColumnTypes(df_lag)
    x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
    dtr = DecisionTreeRegressor()
    dtr.fit(x_train,y_train)
    dtr_pred = dtr.predict(x_test)
    dtr_MSE = mean_squared_error(y_test, dtr_pred)
    dtr_R2 = dtr.score(x_test, y_test)
    DMSE.append(dtr_MSE)
  return DMSE

def BaggingRegressor_fnc(x_train,y_train, x_test, y_test):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the predicted values for the test data (list)
  #print("\n Bagging Regression Model")
  br = BaggingRegressor()
  br.fit(x_train,y_train)
  br_pred = br.predict(x_test)
  return br_pred

def BaggingRegressor_fnc1(df,shifts,train_pct):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the  list of values for MSE
  print("\n Bagging Regression Model")
  BMSE=[]
  for j in shifts: 
    df_lag, shift = CreateLags(df,j)
    df_lag = CorrectColumnTypes(df_lag)
    x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
    br = BaggingRegressor()
    br.fit(x_train,y_train)
    br_pred = br.predict(x_test)
    br_MSE = mean_squared_error(y_test, br_pred)
    br_R2 = br.score(x_test, y_test)
    BMSE.append(br_MSE)
  return BMSE


def ExtraTreesRegressor_fnc(x_train,y_train, x_test, y_test):
  #inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the predicted values for the test data (list)
  #print("\n Extra Trees Regression Model")
  etr = RandomForestRegressor()
  etr.fit(x_train,y_train)
  etr_pred = etr.predict(x_test)
  return etr_pred


def ExtraTreesRegressor_fnc1(df,shifts,train_pct):
  #inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the  list of values for MSE
  print("\n Extra Trees Regression Model")
  EMSE=[]
  for j in shifts: 
    df_lag, shift = CreateLags(df,j)
    df_lag = CorrectColumnTypes(df_lag)
    x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
    etr = RandomForestRegressor()
    etr.fit(x_train,y_train)
    etr_pred = etr.predict(x_test)  
    etr_MSE = mean_squared_error(y_test, etr_pred)
    etr_R2 = etr.score(x_test, y_test)
    EMSE.append(etr_MSE)
  return EMSE


def Calctradingdays(test_df,pred,j):# Calculates number of good trading days based on the model prediction
  # inputs: dataframe,predicted values, day
  # output: the number of good trading days
  pd.set_option('mode.chained_assignment', None)
  test_df['pred'] = np.nan
  test_df['pred'].iloc[:-j] = pred
  test_df['change'] = test_df['Close_lag'] - test_df['Close'] 
  test_df['change_pred'] = test_df['pred'] - test_df['Close'] 
  test_df['MadeMoney'] = np.where(test_df['change_pred']/test_df['change'] > 0, 1, -1) 
  test_df['profit'] = np.abs(test_df['change']) * test_df['MadeMoney']
  profit_dollars = test_df['profit'].sum()
  profit_days = len(test_df[test_df['MadeMoney'] == 1])
  tdays=round(profit_days/(len(test_df)-j),2)
  return tdays



def CalcProfit(test_df,pred,j): # Function to calculate aggregrate profit/loss made in the days
  # inputs: dataframe,predicted values, day
  # output: the aggregated profit/loss made in the predicted days(j)
  pd.set_option('mode.chained_assignment', None)
  test_df['pred'] = np.nan
  test_df['pred'].iloc[:-j] = pred
  test_df['change'] = test_df['Close_lag'] - test_df['Close'] 
  test_df['change_pred'] = test_df['pred'] - test_df['Close'] 
  test_df['MadeMoney'] = np.where(test_df['change_pred']/test_df['change'] > 0, 1, -1) 
  test_df['profit'] = np.abs(test_df['change']) * test_df['MadeMoney']
  profit_dollars = test_df['profit'].sum()
  pad=str(round(profit_dollars,1))
  print("\n Aggregated Profit/Loss Results")
  if pad[0]=='-':
      print('Loss: $ ' + str(round(profit_dollars,1)))
  else:
      print('Profit: $ ' + str(round(profit_dollars,1)))
  profit_days = len(test_df[test_df['MadeMoney'] == 1])
  td = str(round(profit_days/(len(test_df)-j),2)*100) 
  print('Percentage of good trading days: ' + str( round(profit_days/(len(test_df)-j),2)*100) )

  return test_df, profit_dollars,td
 

def disp_results(sfd,pa,tpd): # Displays important details after the graphs 
 # inputs: sfd(list), profit_dollars(list), goodtrade days(list)
 # output: None
  for i in range(len(sfd)):
    for j in range(len(pa)):
      for k in range(len(tpd)):
        if i==j and i==k and j==k :
          print("\n For Day {0} the aggregated profit/loss would be {1} and the estimated percentage of good trading days would be {2}".format(sfd[i],pa[j],tpd[k]))
        else:
          continue
  
def PlotModelProfit_Plotly(train, test, pred,shift_days,name,shift):  # Function to make the plots    
  # inputs: train dataframe, test dataframe, predicted value (list), shift size (int), name (string)
  # output: Graph
  w = 25 # width
  h = 25 # height
  # Create lines of the training actual, testing actual, prediction 
  D1 = go.Scatter(x=train.index,y=train['Profit/Loss (C)'],name = 'Actual Profit/Loss based on  Train data') # Training actuals
  D2 = go.Scatter(x=test.index[:shift],y=test['Profit/Loss (C)'],name = 'Actual Profit/Loss based on  Test data') # Testing actuals
  D3 = go.Scatter(x=test.index[:shift],y=pred,name = 'Predicted Profit/Loss from model') # Testing predction
  tickerSymbol="[Sim]F.US.GCEQ21"
  # Combine in an object  
  line = {'data': [D1,D2,D3],
          'layout': {
              'xaxis' :{'title': 'Date'},
              'yaxis' :{'title': 'Agregate Profit/Loss'},
              'title' : name + ' - ' + tickerSymbol + ' - ' + str(shift_days)
          }}
  # Send object to a figure 
  fig = go.Figure(line)

  # Show figure
  fig.show()

def create_dataframe(test,pa,tpd):
 # a=list(train['Profit/Loss (C)'])
  b=list(test['Profit/Loss (C)'])
  lst=zip(b,pa,tpd)
  df = pd.DataFrame(list(lst),columns =['Actual Profit/Loss for Train','Predicted Profit/Loss from model','Percenatge of good trading Days'])
  display(df)

def PlotModelResults_Plotly(train, test, pred,shift_days,name,shift):  # Function to make the plots    
  # inputs: train dataframe, test dataframe, predicted value (list), shift size (int), name (string)
  # output: Graph
  w = 25 # width
  h = 25 # height
  # Create lines of the training actual, testing actual, prediction 
  D1 = go.Scatter(x=train.index,y=train['Close'],name = 'Train Actual') # Training actuals
  D2 = go.Scatter(x=test.index[:shift],y=test['Close'],name = 'Test Actual') # Testing actuals
  D3 = go.Scatter(x=test.index[:shift],y=pred,name = 'Model Prediction') # Testing predction
  tickerSymbol="[Sim]F.US.GCEQ21"
  # Combine in an object  
  line = {'data': [D1,D2,D3],
          'layout': {
              'xaxis' :{'title': 'Date'},
              'yaxis' :{'title': 'Money'},
              'title' : name + ' - ' + tickerSymbol + ' - ' + str(shift_days)
          }}
  # Send object to a figure 
  fig = go.Figure(line)

  # Show figure
  fig.show()

def best_model(df,shifts,train_pct,bm):
  # inputs: train dataframe, list,train percenatge(float), best model name(str)
  # output: Number of good trading days calculated by the prediction made by the best model
  td=[]
  if bm=='Linear Regression':
    for j in shifts: 
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred = LinearRegression_fnc(x_train,y_train, x_test, y_test)
      temp=Calctradingdays(test,lr_pred,j)
      td.append(temp)
  elif bm=='K-Nearest Regression':
    for j in shifts: 
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred =KNearestRegression_fnc(x_train,y_train, x_test, y_test)
      temp=Calctradingdays(test,lr_pred,j)
      td.append(temp)
  elif bm=='Decision Tree Regression':
    for j in shifts: 
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred = DecisionTreeRegression_fnc(x_train,y_train, x_test, y_test)
      temp=Calctradingdays(test,lr_pred,j)
      td.append(temp)

  elif bm=='Bagging Regression':
    for j in shifts: 
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred = BaggingRegressor_fnc(x_train,y_train, x_test, y_test)
      temp=Calctradingdays(test,lr_pred,j)
      td.append(temp)

  elif bm=='Extra Tree Regression':
      for j in shifts: 
        df_lag, shift = CreateLags(df,j)
        df_lag = CorrectColumnTypes(df_lag)
        x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
        lr_pred = ExtraTreesRegressor_fnc(x_train,y_train, x_test, y_test)
        temp=Calctradingdays(test,lr_pred,j)
        td.append(temp)
  return shifts[td.index(max(td))]


def models_log(df,shifts,train_pct):
  # inputs: train dataframe, list,train percenatge(float)
  # output: The best model name which could be used for further evaluation 
  LMSE=[]
  KMSE=[]
  BMSE=[]
  DMSE=[]
  RMSE=[]
  EMSE=[]
  ovr=[]
  # Linear Regression
  LMSE = LinearRegression_fnc1(df,shifts,train_pct)
  # K-Neareast Neighbors
  KMSE =KNearestRegression_fnc1(df,shifts,train_pct)
  # DecisionTree Regression
  DMSE = DecisionTreeRegression_fnc1(df,shifts,train_pct)
  # Bagging Regression
  # BMSE = BaggingRegressor_fnc1(df,shifts,train_pct)
  # ExtraTrees Regression
  # EMSE=ExtraTreesRegressor_fnc1(df,shifts,train_pct)
  # Chossing the Best Model
  n=3# Number of Models Active
  bom=['Linear Regression','K-Nearest Regression','Decision Tree Regression','Bagging Regression','Extra Tree Regression']
  LR=int(sum(LMSE)/36500)
  KNR=int(sum(KMSE)/36500)
  DTR=int(sum(DMSE)/36500)
  #BR=int(sum(BMSE)/36500)
  EFR=int(sum(EMSE)/36500)
  print(" Mean MSE for Linear Regression for the entire list is {}".format(LR))
  print(" Mean MSE for K-Nearest Neighbors Regression for the entire list is {}".format(KNR))
  print(" Mean MSE for Decision Tree Regression for the entire list is {}".format(DTR))
  ovr.append(LR)
  ovr.append(KNR)
  ovr.append(DTR)
  #ovr.append(BR)
  #ovr.append(EFR)
  idx=minimum(ovr)
  return bom[idx]

def minimum(ovr):
  current_min = ovr[0]  
  for num in ovr:       
    if num < current_min:
      current_min = num  
  return ovr.index(current_min)

def process(pos,shft): # Creates a new list till the maximum limit
 # inputs: position of the maximum number of day for which the model is valid (int),list of days
 # output: Creates a new list containing the number of days for which the model remains valid
  shift=[]
  ele=pos+1
  for k in range(1,ele,1):
    shift.append(k)
  return shift

def logic(bp):
 # inputs: the dataframe of the best permutation
 # output: None
  print("\n welcome to model selection and prediction algorithm")
  shft=[] # Store number of days with a max limit of one year including multiples of seven which makes n week ,and also multiple of 28 which on the whole makes n month as( 4 weeks{4*7} make a month)
  for i in range(1,366): # Max limit for the number of days could be  based on the number of years so for time being i have enclosed the same as one year as 1year=365 days
    shft.append(i)
  train_pct =75
  train_pct=train_pct/100;
  print("\n Columns Format checking initialised")
  bp=CorrectColumnTypes(bp)
  print("\n Columns Format checking performed succesfully")
  bm=models_log(bp,shft,train_pct)
  print("\n The best Model for the given dataset after evaluation is {}".format(bm))
  pos=best_model(bp,shft,train_pct,bm)
  print("The model {0} is valid for {1} days".format(bm,pos))
  sft=process(pos,shft)
  print(sft)
  calc_prof_plot(bp,sft,pos,bm,train_pct)

def active_hour(bp):# Recursively activates the algorithm on an hourly basis
 # inputs: the dataframe of the best permutation
 # output: None
  while 1:
    print("\n Initialising the Model Prediction Algorithm")
    logic(bp)

    dt = datetime.now() + timedelta(hours=1)
    dt = dt.replace(minute=59) # Recursively runs the code at the start of every hour

    while datetime.now() < dt:
        time.sleep(1)

active_hour(bp)

bp=pd.read_csv("Best Permutation file sim120.csv",index_col=False)
bp=bp.set_index('Date')

bp

bp = bp.reindex(['Open','High','Low','Close','Volume','Profit/Loss (C)'], axis=1)

bp

date_change = '%Y-%m-%d'
bp['Date'] = bp.index
bp['Date'] = pd.to_datetime(bp['Date'], format = date_change)
Dates = bp['Date']

date_change = '%Y-%m-%d'
# Define the date parts 
fastai.tabular.add_datepart(bp,'Date', drop = 'True')


# Ensure the correct format
bp['Date'] = pd.to_datetime(bp.index.values, format = date_change)


# Add the date parts
fastai.tabular.add_cyclic_datepart(bp, 'Date', drop = 'True')

"""**with cross validation**"""

def CorrectColumnTypes(bp):# Ensure column types are correct
  # Input: dataframe 
  # ouptut: dataframe (with column types changed)

  # Numbers
  for col in bp.columns[1:80]:
      bp[col] = bp[col].astype('float')

  for col in bp.columns[-10:]:
      bp[col] = bp[col].astype('float')

  # Categories 
  for col in bp.columns[80:-10]:
      bp[col] = bp[col].astype('category')
  return bp

def create_lags(df,shifts):
  for i in shifts:
    col_name = 'Close{}'.format(i)
    df[col_name] = df['Close'].shift(periods=-1 * i)
  df = df.dropna()
  return df


def cv_SplitData(df, train_pct): # Splitting the dataframe into train and test
  # inputs: dataframe , training_pct (float between 0 and 1), size of the lag (int)
  # ouptut: x train dataframe, y train data frame, x test dataframe, y test dataframe, train data frame, test dataframe
  train_pt = int(len(df.columns)*train_pct)
  X = df.iloc[:,:train_pt]
  y = df.iloc[:,train_pt:]
  index = df. index
  number_of_rows = len(index)
  shift=number_of_rows//2
  X_train = X.iloc[:shift, :]
  y_train = y.iloc[:shift, :]
  X_test = X.iloc[shift:, :]
  y_test = y.iloc[shift:, :]
  return X_train, y_train, X_test, y_test, X, y

def CreateLags(df,lag_size): # Creating lags for prediction os OOS (Out of Samples)
  # inputs: dataframe , size of the lag (int)
  # ouptut: dataframe ( with extra lag column), shift size (int)
  # add lag
  shiftdays = int(lag_size)
  shft = -shiftdays
  df['Close_lag'] = df['Close'].shift(shft)
  return df, shft

def SplitData(df, train_pct, shift): # Splitting the dataframe into train and test
  # inputs: dataframe , training_pct (float between 0 and 1), size of the lag (int)
  # ouptut: x train dataframe, y train data frame, x test dataframe, y test dataframe, train data frame, test dataframe

  train_pt = int(len(df)*train_pct)
  train = df.iloc[:train_pt,:]
  test = df.iloc[train_pt:,:]
  x_train = train.iloc[:shift,1:-1]
  y_train = train['Close_lag'][:shift]
  x_test = test.iloc[:shift,1:-1]
  y_test = test['Close'][:shift]

  return x_train, y_train, x_test, y_test, train, test

def calc_prof_plot(df,shft,pos,bm,train_pct):
  # inputs: dataframe , list,maximum  number of days position(int), best model(str)
  # ouptut: plot,details on a daily basis based on shft list
  disp(pos,shft)
  sfd=shft.copy()
  tpd=[]
  pa=[]
  if bm=='Linear Regression':
    for j in shft:
      print(str(j) + ' days out:')
      print('------------')
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred =LinearRegression_fnc(x_train,y_train, x_test, y_test)
      test2, profit_dollars, td = CalcProfit(test,lr_pred,j)
      pa.append(profit_dollars)
      tpd.append(td)
      if j<=min(shft):
        PlotModelResults_Plotly(train, test, lr_pred, j, 'Linear Regression',shift)
      else:
        print("\n As a lot of API calls occur this leads to crashing of the colab notebook and hence the graphs for the subsequent days are not displayed  ")
    x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
    PlotModelProfit_Plotly(train, test, pa ,pos,'Linear Regression',shift)
    create_dataframe(test,pa,tpd)


        
  elif bm=='K-Nearest Regression':
    for j in shft:
      print(str(j) + ' days out:')
      print('------------')
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred =KNearestRegression_fnc(x_train,y_train, x_test, y_test)
      test2, profit_dollars,td = CalcProfit(test,lr_pred,j)
      pa.append(profit_dollars)
      tpd.append(td)
      if j<=min(shft):
        PlotModelResults_Plotly(train, test, lr_pred, j, 'K-Nearest Regression',shift)
      else:
        print("As a lot of API calls occur this leads to crashing of the colab notebook and hence the graphs for the subsequent days are not displayed")
    x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
    PlotModelProfit_Plotly(train, test, pa ,pos,'Linear Regression',shift)
    create_dataframe(test,pa,tpd)

  elif bm=='Decision Tree Regression':
      for j in shft:
        print(str(j) + ' days out:')
        print('------------')
        df_lag, shift = CreateLags(df,j)
        df_lag = CorrectColumnTypes(df_lag)
        x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
        lr_pred =DecisionTreeRegression_fnc(x_train,y_train, x_test, y_test)
        test2, profit_dollars,td = CalcProfit(test,lr_pred,j)
        pa.append(profit_dollars)
        tpd.append(td)
        if j<=min(shft):
          PlotModelResults_Plotly(train, test, lr_pred, j, 'Decision Tree Regression',shift)
        else:
          print("As a lot of API calls occur this leads to crashing of the colab notebook and hence the graphs for the subsequent days are not displayed")
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      PlotModelProfit_Plotly(train, test, pa ,pos,'Linear Regression',shift)
      create_dataframe(test,pa,tpd)

  elif bm=='Bagging Regression':
    for j in shifts: 
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred = BaggingRegressor_fnc(x_train,y_train, x_test, y_test)
      test2, profit_dollars,td = CalcProfit(test,lr_pred,j)
      pa.append(profit_dollars)
      tpd.append(td)
      if j<=min(shft):
        PlotModelResults_Plotly(train, test, lr_pred, j, 'Bagging Regression',shift)
      else:
        print("As a lot of API calls occur this leads to crashing of the colab notebook and hence the graphs for the subsequent days are not displayed")
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      PlotModelProfit_Plotly(train, test, pa ,pos,'Linear Regression',shift)
      create_dataframe(test,pa,tpd)

  elif bm=='Extra Tree Regression':
      for j in shft:
          print(str(j) + ' days out:')
          print('------------')
          df_lag, shift = CreateLags(df,j)
          df_lag = CorrectColumnTypes(df_lag)
          x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
          lr_pred =ExtraTreeRegression_fnc(x_train,y_train, x_test, y_test)
          test2, profit_dollars,td = CalcProfit(test,lr_pred,j)
          pa.append(profit_dollars)
          tpd.append(td)
          if j<=min(shft):
            PlotModelResults_Plotly(train, test, lr_pred, j, 'Extra Tree Regression',shift)
          else:
            print("As a lot of API calls occur this leads to crashing of the colab notebook and hence the graphs for the subsequent days are not displayed")
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      PlotModelProfit_Plotly(train, test, pa ,pos,'Linear Regression',shift)
      create_dataframe(test,pa,tpd)
   

def disp(pos,shft): # Displays the valid number of days,months,weeks during the model is considered to be valid

   if pos %7==0 and pos %28!=0:
      print("The model can work for {} weeks".format(pos//7))
   elif pos %28==0 and pos %7!=0:
      print("The model can work for {} months".format(pos//28))
   else:
      print("The model can work for {} days".format(pos))

# Regreesion Functions

def LinearRegression_fnc(x_train,y_train, x_test, y_test):
  #inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the predicted values of the test data (list)
  #print("\n Linear Regression Model")
  lr = LinearRegression()
  lr.fit(x_train,y_train)
  lr_pred = lr.predict(x_test)
  return lr_pred



def LinearRegression_fnc1(df,shifts,train_pct):
    # inputs: x train data, y train data, x test data, y test data (all dataframe's)
    # output: the  list of values for MSE
    print("\n Linear Regression Model")
    LMSE=[]
    df_lag = create_lags(df,shifts)
    df_lag = CorrectColumnTypes(df_lag)
    x_train, y_train, x_test, y_test, train, test = cv_SplitData(df, train_pct)
    lr = LinearRegression()
    tscv = TimeSeriesSplit(n_splits=5)
    scores = cross_val_score(lr, x_train, y_train, cv=tscv, scoring='r2')
    tmp=mean(scores)
    LMSE.append(tmp)
    return LMSE



def KNearestRegression_fnc(x_train,y_train, x_test, y_test):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the predicted values for the test data (list)
  #print("\n K- Nearest Neighbors Regression Model")
  knr = KNeighborsRegressor()
  knr.fit(x_train,y_train)
  knr_pred = knr.predict(x_test)
  return knr_pred

def KNearestRegression_fnc1(df,shifts,train_pct):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the  list of values for MSE
  print("\n K- Nearest Neighbors Regression Model")
  KMSE=[]
  df_lag = create_lags(df,shifts)
  df_lag = CorrectColumnTypes(df_lag)
  x_train, y_train, x_test, y_test, train, test = cv_SplitData(df, train_pct)
  knr = KNeighborsRegressor()
  tscv = TimeSeriesSplit(n_splits=5)
  scores = cross_val_score(knr, x_train, y_train, cv=tscv, scoring='r2')
  tmp=mean(scores)
  KMSE.append(tmp)
  return KMSE



def DecisionTreeRegression_fnc(x_train,y_train, x_test, y_test):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the predicted values for the test data (list)
  #print("\n Decision Tree Regression Model")
  dtr = DecisionTreeRegressor()
  dtr.fit(x_train,y_train)
  dtr_pred = dtr.predict(x_test)
  return dtr_pred

def DecisionTreeRegression_fnc1(df,shifts,train_pct):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the  list of values for MSE
    print("\n Decision Tree Regression Model")
    DMSE=[] 
    df_lag = create_lags(df,shifts)
    df_lag = CorrectColumnTypes(df_lag)
    x_train, y_train, x_test, y_test, train, test = cv_SplitData(df, train_pct)
    dtr = DecisionTreeRegressor()
    tscv = TimeSeriesSplit(n_splits=5)
    scores = cross_val_score(dtr, x_train, y_train, cv=tscv, scoring='r2')
    tmp=mean(scores)
    DMSE.append(tmp)
    return DMSE

def BaggingRegressor_fnc(x_train,y_train, x_test, y_test):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the predicted values for the test data (list)
  #print("\n Bagging Regression Model")
  br = BaggingRegressor()
  br.fit(x_train,y_train)
  br_pred = br.predict(x_test)
  return br_pred

def BaggingRegressor_fnc1(df,shifts,train_pct):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the  list of values for MSE
  print("\n Bagging Regression Model")
  BMSE=[]
  df_lag = create_lags(df,shifts)
  df_lag = CorrectColumnTypes(df_lag)
  x_train, y_train, x_test, y_test, train, test = cv_SplitData(df, train_pct)
  br = BaggingRegressor()
  tscv = TimeSeriesSplit(n_splits=5)
  scores = cross_val_score(br, x_train, y_train, cv=tscv, scoring='r2')
  tmp=mean(scores)
  BMSE.append(tmp)
  return BMSE


def ExtraTreesRegressor_fnc(x_train,y_train, x_test, y_test):
  #inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the predicted values for the test data (list)
  #print("\n Extra Trees Regression Model")
  etr = RandomForestRegressor()
  etr.fit(x_train,y_train)
  etr_pred = etr.predict(x_test)
  return etr_pred


def ExtraTreesRegressor_fnc1(df,shifts,train_pct):
  #inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the  list of values for MSE
  print("\n Extra Trees Regression Model")
  EMSE=[]
  df_lag = create_lags(df,shifts)
  df_lag = CorrectColumnTypes(df_lag)
  x_train, y_train, x_test, y_test, train, test = cv_SplitData(df, train_pct)
  etr = RandomForestRegressor()
  tscv = TimeSeriesSplit(n_splits=5)
  scores = cross_val_score(etr, x_train, y_train, cv=tscv, scoring='r2')
  tmp=mean(scores)
  EMSE.append(tmp)
  return EMSE


def Calctradingdays(test_df,pred,j):# Calculates number of good trading days based on the model prediction
  # inputs: dataframe,predicted values, day
  # output: the number of good trading days
  pd.set_option('mode.chained_assignment', None)
  test_df['pred'] = np.nan
  test_df['pred'].iloc[:-j] = pred
  test_df['change'] = test_df['Close_lag'] - test_df['Close'] 
  test_df['change_pred'] = test_df['pred'] - test_df['Close'] 
  test_df['MadeMoney'] = np.where(test_df['change_pred']/test_df['change'] > 0, 1, -1) 
  test_df['profit'] = np.abs(test_df['change']) * test_df['MadeMoney']
  profit_dollars = test_df['profit'].sum()
  profit_days = len(test_df[test_df['MadeMoney'] == 1])
  tdays=round(profit_days/(len(test_df)-j),2)
  return tdays



def CalcProfit(test_df,pred,j): # Function to calculate aggregrate profit/loss made in the days
  # inputs: dataframe,predicted values, day
  # output: the aggregated profit/loss made in the predicted days(j)
  pd.set_option('mode.chained_assignment', None)
  test_df['pred'] = np.nan
  test_df['pred'].iloc[:-j] = pred
  test_df['change'] = test_df['Close_lag'] - test_df['Close'] 
  test_df['change_pred'] = test_df['pred'] - test_df['Close'] 
  test_df['MadeMoney'] = np.where(test_df['change_pred']/test_df['change'] > 0, 1, -1) 
  test_df['profit'] = np.abs(test_df['change']) * test_df['MadeMoney']
  profit_dollars = test_df['profit'].sum()
  pad=str(round(profit_dollars,1))
  print("\n Aggregated Profit/Loss Results")
  if pad[0]=='-':
      print('Loss: $ ' + str(round(profit_dollars,1)))
  else:
      print('Profit: $ ' + str(round(profit_dollars,1)))
  profit_days = len(test_df[test_df['MadeMoney'] == 1])
  td = str(round(profit_days/(len(test_df)-j),2)*100) 
  print('Percentage of good trading days: ' + str( round(profit_days/(len(test_df)-j),2)*100) )

  return test_df, profit_dollars,td
 

def disp_results(sfd,pa,tpd): # Displays important details after the graphs 
 # inputs: sfd(list), profit_dollars(list), goodtrade days(list)
 # output: None
  for i in range(len(sfd)):
    for j in range(len(pa)):
      for k in range(len(tpd)):
        if i==j and i==k and j==k :
          print("\n For Day {0} the aggregated profit/loss would be {1} and the estimated percentage of good trading days would be {2}".format(sfd[i],pa[j],tpd[k]))
        else:
          continue
  
def PlotModelProfit_Plotly(train, test, pred,shift_days,name,shift):  # Function to make the plots    
  # inputs: train dataframe, test dataframe, predicted value (list), shift size (int), name (string)
  # output: Graph
  w = 25 # width
  h = 25 # height
  # Create lines of the training actual, testing actual, prediction 
  D1 = go.Scatter(x=train.index,y=train['Profit/Loss (C)'],name = 'Actual Profit/Loss based on  Train data') # Training actuals
  D2 = go.Scatter(x=test.index[:shift],y=test['Profit/Loss (C)'],name = 'Actual Profit/Loss based on  Test data') # Testing actuals
  D3 = go.Scatter(x=test.index[:shift],y=pred,name = 'Predicted Profit/Loss from model') # Testing predction
  tickerSymbol="[Sim]F.US.GCEQ21"
  # Combine in an object  
  line = {'data': [D1,D2,D3],
          'layout': {
              'xaxis' :{'title': 'Date'},
              'yaxis' :{'title': 'Agregate Profit/Loss'},
              'title' : name + ' - ' + tickerSymbol + ' - ' + str(shift_days)
          }}
  # Send object to a figure 
  fig = go.Figure(line)

  # Show figure
  fig.show()

def create_dataframe(test,pa,tpd):
 # a=list(train['Profit/Loss (C)'])
  b=list(test['Profit/Loss (C)'])
  lst=zip(b,pa,tpd)
  df = pd.DataFrame(list(lst),columns =['Actual Profit/Loss for Train','Predicted Profit/Loss from model','Percenatge of good trading Days'])
  display(df)

def PlotModelResults_Plotly(train, test, pred,shift_days,name,shift):  # Function to make the plots    
  # inputs: train dataframe, test dataframe, predicted value (list), shift size (int), name (string)
  # output: Graph
  w = 25 # width
  h = 25 # height
  # Create lines of the training actual, testing actual, prediction 
  D1 = go.Scatter(x=train.index,y=train['Close'],name = 'Train Actual') # Training actuals
  D2 = go.Scatter(x=test.index[:shift],y=test['Close'],name = 'Test Actual') # Testing actuals
  D3 = go.Scatter(x=test.index[:shift],y=pred,name = 'Model Prediction') # Testing predction
  tickerSymbol="[Sim]F.US.GCEQ21"
  # Combine in an object  
  line = {'data': [D1,D2,D3],
          'layout': {
              'xaxis' :{'title': 'Date'},
              'yaxis' :{'title': 'Money'},
              'title' : name + ' - ' + tickerSymbol + ' - ' + str(shift_days)
          }}
  # Send object to a figure 
  fig = go.Figure(line)

  # Show figure
  fig.show()

def best_model(df,shifts,train_pct,bm):
  # inputs: train dataframe, list,train percenatge(float), best model name(str)
  # output: Number of good trading days calculated by the prediction made by the best model
  td=[]
  if bm=='Linear Regression':
    for j in shifts: 
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred = LinearRegression_fnc(x_train,y_train, x_test, y_test)
      temp=Calctradingdays(test,lr_pred,j)
      td.append(temp)
  elif bm=='K-Nearest Regression':
    for j in shifts: 
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred =KNearestRegression_fnc(x_train,y_train, x_test, y_test)
      temp=Calctradingdays(test,lr_pred,j)
      td.append(temp)
  elif bm=='Decision Tree Regression':
    for j in shifts: 
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred = DecisionTreeRegression_fnc(x_train,y_train, x_test, y_test)
      temp=Calctradingdays(test,lr_pred,j)
      td.append(temp)

  elif bm=='Bagging Regression':
    for j in shifts: 
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred = BaggingRegressor_fnc(x_train,y_train, x_test, y_test)
      temp=Calctradingdays(test,lr_pred,j)
      td.append(temp)

  elif bm=='Extra Tree Regression':
      for j in shifts: 
        df_lag, shift = CreateLags(df,j)
        df_lag = CorrectColumnTypes(df_lag)
        x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
        lr_pred = ExtraTreesRegressor_fnc(x_train,y_train, x_test, y_test)
        temp=Calctradingdays(test,lr_pred,j)
        td.append(temp)
  return shifts[td.index(max(td))]


def models_log(df,shifts,train_pct):
  # inputs: train dataframe, list,train percenatge(float)
  # output: The best model name which could be used for further evaluation 
  LMSE=[]
  KMSE=[]
  BMSE=[]
  DMSE=[]
  RMSE=[]
  EMSE=[]
  ovr=[]
  # Linear Regression
  LMSE = LinearRegression_fnc1(df,shifts,train_pct)
  # K-Neareast Neighbors
  KMSE =KNearestRegression_fnc1(df,shifts,train_pct)
  # DecisionTree Regression
  DMSE = DecisionTreeRegression_fnc1(df,shifts,train_pct)
  # Bagging Regression
  # BMSE = BaggingRegressor_fnc1(df,shifts,train_pct)
  # ExtraTrees Regression
  # EMSE=ExtraTreesRegressor_fnc1(df,shifts,train_pct)
  # Chossing the Best Model
  n=3# Number of Models Active
  bom=['Linear Regression','K-Nearest Regression','Decision Tree Regression','Bagging Regression','Extra Tree Regression']
  LR=int(sum(LMSE)/36500)
  KNR=int(sum(KMSE)/36500)
  DTR=int(sum(DMSE)/36500)
  #BR=int(sum(BMSE)/36500)
  EFR=int(sum(EMSE)/36500)
  print(" Mean R2 score after cross validation for Linear Regression for the entire list is {}".format(LR))
  print(" Mean R2 score after cross validation for K-Nearest Neighbors Regression for the entire list is {}".format(KNR))
  print(" Mean R2 score after cross validation for Decision Tree Regression for the entire list is {}".format(DTR))
  ovr.append(LR)
  ovr.append(KNR)
  ovr.append(DTR)
  #ovr.append(BR)
  #ovr.append(EFR)
  #idx=minimum(ovr)
  idx=minimum(ovr)
  return bom[idx]

def minimum(ovr):
  current_min = ovr[0]  
  for num in ovr:       
    if num < current_min:
      current_min = num  
  return ovr.index(current_min)

def process(pos,shft): # Creates a new list till the maximum limit
 # inputs: position of the maximum number of day for which the model is valid (int),list of days
 # output: Creates a new list containing the number of days for which the model remains valid
  shift=[]
  ele=pos+1
  for k in range(1,ele,1):
    shift.append(k)
  return shift

def logic(bp):
 # inputs: the dataframe of the best permutation
 # output: None
  print("\n welcome to model selection and prediction algorithm")
  shft=[] # Store number of days with a max limit of one year including multiples of seven which makes n week ,and also multiple of 28 which on the whole makes n month as( 4 weeks{4*7} make a month)
  for i in range(1,366): # Max limit for the number of days could be  based on the number of years so for time being i have enclosed the same as one year as 1year=365 days
    shft.append(i)
  train_pct =75
  train_pct=train_pct/100;
  print("\n Columns Format checking initialised")
  bp=CorrectColumnTypes(bp)
  bp1=bp.copy()
  print("\n Columns Format checking performed succesfully")
  bm=models_log(bp,shft,train_pct)
  print("\n The best Model for the given dataset after evaluation is {}".format(bm))
  pos=best_model(bp1,shft,train_pct,bm)
  print("The model {0} is valid for {1} days".format(bm,pos))
  sft=process(pos,shft)
  print(sft)
  calc_prof_plot(bp1,sft,pos,bm,train_pct)

def active_hour(bp):# Recursively activates the algorithm on an hourly basis
 # inputs: the dataframe of the best permutation
 # output: None
  while 1:
    print("\n Initialising the Model Prediction Algorithm")
    logic(bp)

    dt = datetime.now() + timedelta(hours=1)
    dt = dt.replace(minute=59) # Recursively runs the code at the start of every hour

    while datetime.now() < dt:
        time.sleep(1)

active_hour(bp)

"""### **Stage-3**"""

#data preprocessing libraries
import pandas as pd # Library to process the dataframe
import numpy as np # Library to handle with numpy arrays
#import zipfile# Library to extract zip files
from ta import add_all_ta_features # Library that does financial technical analysis 
import fastai.tabular # Library that does date factors
import plotly.graph_objs as go  # Import the graph objects 
import os # Library that locates the respective files or folders and processes them
import time # Library that handles time and processes the same
import sys # Library that handles all system functions like exit , etc
import random # Library that handles all functions like randomise etc
import warnings # Library that handles all the types of warnings during execution
warnings.filterwarnings("ignore") # Ignore all the warnings
#Model libraries
from sklearn.metrics import mean_squared_error # Install error metrics 
from sklearn.preprocessing import StandardScaler # to scale for ann
# importing all the seven different regression models 
from sklearn.linear_model import LinearRegression 
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.svm import SVR
from sklearn.ensemble import AdaBoostRegressor
from sklearn.ensemble import BaggingRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import ExtraTreesRegressor
from sklearn.model_selection import TimeSeriesSplit
from sklearn.model_selection import cross_val_score
from numpy import mean

"""### **Model-1:Trading Analysis based on user input and Super Learner model (without cross validation score)**

**Part-1**
"""

def CorrectColumnTypes(bp):# Ensure column types are correct
  # Input: dataframe 
  # ouptut: dataframe (with column types changed)

  # Numbers
  for col in bp.columns[1:80]:
      bp[col] = bp[col].astype('float')

  for col in bp.columns[-10:]:
      bp[col] = bp[col].astype('float')

  # Categories 
  for col in bp.columns[80:-10]:
      bp[col] = bp[col].astype('category')
  return bp


def CreateLags(df,lag_size): # Creating lags for prediction os OOS (Out of Samples)
  # inputs: dataframe , size of the lag (int)
  # ouptut: dataframe ( with extra lag column), shift size (int)
  # add lag
  shiftdays = int(lag_size)
  shft = -shiftdays
  df['Close_lag'] = df['Close'].shift(shft)
  return df, shft

def SplitData(df, train_pct, shift): # Splitting the dataframe into train and test
  # inputs: dataframe , training_pct (float between 0 and 1), size of the lag (int)
  # ouptut: x train dataframe, y train data frame, x test dataframe, y test dataframe, train data frame, test dataframe

  train_pt = int(len(df)*train_pct)
  train = df.iloc[:train_pt,:]
  test = df.iloc[train_pt:,:]
  x_train = train.iloc[:shift,1:-1]
  y_train = train['Close_lag'][:shift]
  x_test = test.iloc[:shift,1:-1]
  y_test = test['Close'][:shift]

  return x_train, y_train, x_test, y_test, train, test

def calc_prof_plot(df,shft,pos,bm,train_pct):
  # inputs: dataframe , list,maximum  number of days position(int), best model(str)
  # ouptut: plot,details on a daily basis based on shft list
  disp(pos,shft)
  sfd=shft.copy()
  tpd=[]
  pa=[]
  if bm=='Linear Regression':
    for j in shft:
      print(str(j) + ' days out:')
      print('------------')
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred =LinearRegression_fnc(x_train,y_train, x_test, y_test)
      test2, profit_dollars, td = CalcProfit(test,lr_pred,j)
      pa.append(profit_dollars)
      tpd.append(td)
      if j<=min(shft):
        PlotModelResults_Plotly(train, test, lr_pred, j, 'Linear Regression',shift)
      else:
        print("\n As a lot of API calls occur this leads to crashing of the colab notebook and hence the graphs for the subsequent days are not displayed  ")
    x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
    PlotModelProfit_Plotly(train, test, pa ,pos,'Linear Regression',shift)
    create_dataframe(test,pa,tpd)


        
  elif bm=='K-Nearest Regression':
    for j in shft:
      print(str(j) + ' days out:')
      print('------------')
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred =KNearestRegression_fnc(x_train,y_train, x_test, y_test)
      test2, profit_dollars,td = CalcProfit(test,lr_pred,j)
      pa.append(profit_dollars)
      tpd.append(td)
      if j<=min(shft):
        PlotModelResults_Plotly(train, test, lr_pred, j, 'K-Nearest Regression',shift)
      else:
        print("As a lot of API calls occur this leads to crashing of the colab notebook and hence the graphs for the subsequent days are not displayed")
    x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
    PlotModelProfit_Plotly(train, test, pa ,pos,'Linear Regression',shift)
    create_dataframe(test,pa,tpd)

  elif bm=='Decision Tree Regression':
      for j in shft:
        print(str(j) + ' days out:')
        print('------------')
        df_lag, shift = CreateLags(df,j)
        df_lag = CorrectColumnTypes(df_lag)
        x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
        lr_pred =DecisionTreeRegression_fnc(x_train,y_train, x_test, y_test)
        test2, profit_dollars,td = CalcProfit(test,lr_pred,j)
        pa.append(profit_dollars)
        tpd.append(td)
        if j<=min(shft):
          PlotModelResults_Plotly(train, test, lr_pred, j, 'Decision Tree Regression',shift)
        else:
          print("As a lot of API calls occur this leads to crashing of the colab notebook and hence the graphs for the subsequent days are not displayed")
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      PlotModelProfit_Plotly(train, test, pa ,pos,'Linear Regression',shift)
      create_dataframe(test,pa,tpd)

  elif bm=='Bagging Regression':
    for j in shifts: 
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred = BaggingRegressor_fnc(x_train,y_train, x_test, y_test)
      test2, profit_dollars,td = CalcProfit(test,lr_pred,j)
      pa.append(profit_dollars)
      tpd.append(td)
      if j<=min(shft):
        PlotModelResults_Plotly(train, test, lr_pred, j, 'Bagging Regression',shift)
      else:
        print("As a lot of API calls occur this leads to crashing of the colab notebook and hence the graphs for the subsequent days are not displayed")
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      PlotModelProfit_Plotly(train, test, pa ,pos,'Linear Regression',shift)
      create_dataframe(test,pa,tpd)

  elif bm=='Extra Tree Regression':
      for j in shft:
          print(str(j) + ' days out:')
          print('------------')
          df_lag, shift = CreateLags(df,j)
          df_lag = CorrectColumnTypes(df_lag)
          x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
          lr_pred =ExtraTreeRegression_fnc(x_train,y_train, x_test, y_test)
          test2, profit_dollars,td = CalcProfit(test,lr_pred,j)
          pa.append(profit_dollars)
          tpd.append(td)
          if j<=min(shft):
            PlotModelResults_Plotly(train, test, lr_pred, j, 'Extra Tree Regression',shift)
          else:
            print("As a lot of API calls occur this leads to crashing of the colab notebook and hence the graphs for the subsequent days are not displayed")
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      PlotModelProfit_Plotly(train, test, pa ,pos,'Linear Regression',shift)
      create_dataframe(test,pa,tpd)
   

def disp(pos,shft): # Displays the valid number of days,months,weeks during the model is considered to be valid

   if pos %7==0 and pos %28!=0:
      print("The model can work for {} weeks".format(pos//7))
   elif pos %28==0 and pos %7!=0:
      print("The model can work for {} months".format(pos//28))
   else:
      print("The model can work for {} days".format(pos))

# Regreesion Functions

def LinearRegression_fnc(x_train,y_train, x_test, y_test):
  #inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the predicted values of the test data (list)
  #print("\n Linear Regression Model")
  lr = LinearRegression()
  lr.fit(x_train,y_train)
  lr_pred = lr.predict(x_test)
  return lr_pred



def LinearRegression_fnc1(df,shifts,train_pct):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the  list of values for MSE
  print("\n Linear Regression Model")
  LMSE=[]
  for j in shifts: 
    df_lag, shift = CreateLags(df,j)
    df_lag = CorrectColumnTypes(df_lag)
    x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
    lr = LinearRegression()
    lr.fit(x_train,y_train)
    lr_pred = lr.predict(x_test)
    lr_MSE = mean_squared_error(y_test, lr_pred)
    lr_R2 = lr.score(x_test, y_test)
    LMSE.append(lr_MSE)
  return LMSE




def KNearestRegression_fnc(x_train,y_train, x_test, y_test):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the predicted values for the test data (list)
  #print("\n K- Nearest Neighbors Regression Model")
  knr = KNeighborsRegressor()
  knr.fit(x_train,y_train)
  knr_pred = knr.predict(x_test)
  return knr_pred



def KNearestRegression_fnc1(df,shifts,train_pct):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the  list of values for MSE
  print("\n K- Nearest Neighbors Regression Model")
  KMSE=[]
  for j in shifts: 
    df_lag, shift = CreateLags(df,j)
    df_lag = CorrectColumnTypes(df_lag)
    x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
    knr = KNeighborsRegressor()
    knr.fit(x_train,y_train)
    knr_pred = knr.predict(x_test)
    knr_MSE = mean_squared_error(y_test, knr_pred)
    knr_R2 = knr.score(x_test, y_test)
    KMSE.append(knr_MSE)
  return KMSE

def DecisionTreeRegression_fnc(x_train,y_train, x_test, y_test):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the predicted values for the test data (list)
  #print("\n Decision Tree Regression Model")
  dtr = DecisionTreeRegressor()
  dtr.fit(x_train,y_train)
  dtr_pred = dtr.predict(x_test)
  return dtr_pred

def DecisionTreeRegression_fnc1(df,shifts,train_pct):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the  list of values for MSE
  print("\n Decision Tree Regression Model")
  DMSE=[]
  for j in shifts: 
    df_lag, shift = CreateLags(df,j)
    df_lag = CorrectColumnTypes(df_lag)
    x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
    dtr = DecisionTreeRegressor()
    dtr.fit(x_train,y_train)
    dtr_pred = dtr.predict(x_test)
    dtr_MSE = mean_squared_error(y_test, dtr_pred)
    dtr_R2 = dtr.score(x_test, y_test)
    DMSE.append(dtr_MSE)
  return DMSE

def BaggingRegressor_fnc(x_train,y_train, x_test, y_test):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the predicted values for the test data (list)
  #print("\n Bagging Regression Model")
  br = BaggingRegressor()
  br.fit(x_train,y_train)
  br_pred = br.predict(x_test)
  return br_pred

def BaggingRegressor_fnc1(df,shifts,train_pct):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the  list of values for MSE
  print("\n Bagging Regression Model")
  BMSE=[]
  for j in shifts: 
    df_lag, shift = CreateLags(df,j)
    df_lag = CorrectColumnTypes(df_lag)
    x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
    br = BaggingRegressor()
    br.fit(x_train,y_train)
    br_pred = br.predict(x_test)
    br_MSE = mean_squared_error(y_test, br_pred)
    br_R2 = br.score(x_test, y_test)
    BMSE.append(br_MSE)
  return BMSE


def ExtraTreesRegressor_fnc(x_train,y_train, x_test, y_test):
  #inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the predicted values for the test data (list)
  #print("\n Extra Trees Regression Model")
  etr = RandomForestRegressor()
  etr.fit(x_train,y_train)
  etr_pred = etr.predict(x_test)
  return etr_pred


def ExtraTreesRegressor_fnc1(df,shifts,train_pct):
  #inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the  list of values for MSE
  print("\n Extra Trees Regression Model")
  EMSE=[]
  for j in shifts: 
    df_lag, shift = CreateLags(df,j)
    df_lag = CorrectColumnTypes(df_lag)
    x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
    etr = RandomForestRegressor()
    etr.fit(x_train,y_train)
    etr_pred = etr.predict(x_test)  
    etr_MSE = mean_squared_error(y_test, etr_pred)
    etr_R2 = etr.score(x_test, y_test)
    EMSE.append(etr_MSE)
  return EMSE


def Calctradingdays(test_df,pred,j):# Calculates number of good trading days based on the model prediction
  # inputs: dataframe,predicted values, day
  # output: the number of good trading days
  pd.set_option('mode.chained_assignment', None)
  test_df['pred'] = np.nan
  test_df['pred'].iloc[:-j] = pred
  test_df['change'] = test_df['Close_lag'] - test_df['Close'] 
  test_df['change_pred'] = test_df['pred'] - test_df['Close'] 
  test_df['MadeMoney'] = np.where(test_df['change_pred']/test_df['change'] > 0, 1, -1) 
  test_df['profit'] = np.abs(test_df['change']) * test_df['MadeMoney']
  profit_dollars = test_df['profit'].sum()
  profit_days = len(test_df[test_df['MadeMoney'] == 1])
  tdays=round(profit_days/(len(test_df)-j),2)
  return tdays



def CalcProfit(test_df,pred,j): # Function to calculate aggregrate profit/loss made in the days
  # inputs: dataframe,predicted values, day
  # output: the aggregated profit/loss made in the predicted days(j)
  pd.set_option('mode.chained_assignment', None)
  test_df['pred'] = np.nan
  test_df['pred'].iloc[:-j] = pred
  test_df['change'] = test_df['Close_lag'] - test_df['Close'] 
  test_df['change_pred'] = test_df['pred'] - test_df['Close'] 
  test_df['MadeMoney'] = np.where(test_df['change_pred']/test_df['change'] > 0, 1, -1) 
  test_df['profit'] = np.abs(test_df['change']) * test_df['MadeMoney']
  profit_dollars = test_df['profit'].sum()
  pad=str(round(profit_dollars,1))
  print("\n Aggregated Profit/Loss Results")
  if pad[0]=='-':
      print('Loss: $ ' + str(round(profit_dollars,1)))
  else:
      print('Profit: $ ' + str(round(profit_dollars,1)))
  profit_days = len(test_df[test_df['MadeMoney'] == 1])
  td = str(round(profit_days/(len(test_df)-j),2)*100) 
  print('Percentage of good trading days: ' + str( round(profit_days/(len(test_df)-j),2)*100) )

  return test_df, profit_dollars,td
 

def disp_results(sfd,pa,tpd): # Displays important details after the graphs 
 # inputs: sfd(list), profit_dollars(list), goodtrade days(list)
 # output: None
  for i in range(len(sfd)):
    for j in range(len(pa)):
      for k in range(len(tpd)):
        if i==j and i==k and j==k :
          print("\n For Day {0} the aggregated profit/loss would be {1} and the estimated percentage of good trading days would be {2}".format(sfd[i],pa[j],tpd[k]))
        else:
          continue
  
def PlotModelProfit_Plotly(train, test, pred,shift_days,name,shift):  # Function to make the plots    
  # inputs: train dataframe, test dataframe, predicted value (list), shift size (int), name (string)
  # output: Graph
  w = 25 # width
  h = 25 # height
  # Create lines of the training actual, testing actual, prediction 
  D1 = go.Scatter(x=train.index,y=train['Profit/Loss (C)'],name = 'Actual Profit/Loss based on  Train data') # Training actuals
  D2 = go.Scatter(x=test.index[:shift],y=test['Profit/Loss (C)'],name = 'Actual Profit/Loss based on  Train data') # Testing actuals
  D3 = go.Scatter(x=test.index[:shift],y=pred,name = 'Predicted Profit/Loss from model') # Testing predction
  tickerSymbol="[Sim]F.US.GCEQ21"
  # Combine in an object  
  line = {'data': [D1,D2,D3],
          'layout': {
              'xaxis' :{'title': 'Date'},
              'yaxis' :{'title': 'Agregate Profit/Loss'},
              'title' : name + ' - ' + tickerSymbol + ' - ' + str(shift_days)
          }}
  # Send object to a figure 
  fig = go.Figure(line)

  # Show figure
  fig.show()

def create_dataframe(test,pa,tpd):
 # a=list(train['Profit/Loss (C)'])
  b=list(test['Profit/Loss (C)'])
  lst=zip(b,pa,tpd)
  df = pd.DataFrame(list(lst),columns =['Actual Profit/Loss for Train','Predicted Profit/Loss from model','Percenatge of good trading Days'])
  display(df)

def PlotModelResults_Plotly(train, test, pred,shift_days,name,shift):  # Function to make the plots    
  # inputs: train dataframe, test dataframe, predicted value (list), shift size (int), name (string)
  # output: Graph
  w = 25 # width
  h = 25 # height
  # Create lines of the training actual, testing actual, prediction 
  D1 = go.Scatter(x=train.index,y=train['Close'],name = 'Train Actual') # Training actuals
  D2 = go.Scatter(x=test.index[:shift],y=test['Close'],name = 'Test Actual') # Testing actuals
  D3 = go.Scatter(x=test.index[:shift],y=pred,name = 'Model Prediction') # Testing predction
  tickerSymbol="[Sim]F.US.GCEQ21"
  # Combine in an object  
  line = {'data': [D1,D2,D3],
          'layout': {
              'xaxis' :{'title': 'Date'},
              'yaxis' :{'title': 'Money'},
              'title' : name + ' - ' + tickerSymbol + ' - ' + str(shift_days)
          }}
  # Send object to a figure 
  fig = go.Figure(line)

  # Show figure
  fig.show()

def best_model(df,shifts,train_pct,bm):
  # inputs: train dataframe, list,train percenatge(float), best model name(str)
  # output: Number of good trading days calculated by the prediction made by the best model
  td=[]
  if bm=='Linear Regression':
    for j in shifts: 
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred = LinearRegression_fnc(x_train,y_train, x_test, y_test)
      temp=Calctradingdays(test,lr_pred,j)
      td.append(temp)
  elif bm=='K-Nearest Regression':
    for j in shifts: 
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred =KNearestRegression_fnc(x_train,y_train, x_test, y_test)
      temp=Calctradingdays(test,lr_pred,j)
      td.append(temp)
  elif bm=='Decision Tree Regression':
    for j in shifts: 
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred = DecisionTreeRegression_fnc(x_train,y_train, x_test, y_test)
      temp=Calctradingdays(test,lr_pred,j)
      td.append(temp)

  elif bm=='Bagging Regression':
    for j in shifts: 
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred = BaggingRegressor_fnc(x_train,y_train, x_test, y_test)
      temp=Calctradingdays(test,lr_pred,j)
      td.append(temp)

  elif bm=='Extra Tree Regression':
      for j in shifts: 
        df_lag, shift = CreateLags(df,j)
        df_lag = CorrectColumnTypes(df_lag)
        x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
        lr_pred = ExtraTreesRegressor_fnc(x_train,y_train, x_test, y_test)
        temp=Calctradingdays(test,lr_pred,j)
        td.append(temp)
  return shifts[td.index(max(td))]


def models_log(df,shifts,train_pct):
  # inputs: train dataframe, list,train percenatge(float)
  # output: The best model name which could be used for further evaluation 
  LMSE=[]
  KMSE=[]
  BMSE=[]
  DMSE=[]
  RMSE=[]
  EMSE=[]
  ovr=[]
  # Linear Regression
  LMSE = LinearRegression_fnc1(df,shifts,train_pct)
  # K-Neareast Neighbors
  KMSE =KNearestRegression_fnc1(df,shifts,train_pct)
  # DecisionTree Regression
  DMSE = DecisionTreeRegression_fnc1(df,shifts,train_pct)
  # Bagging Regression
  # BMSE = BaggingRegressor_fnc1(df,shifts,train_pct)
  # ExtraTrees Regression
  # EMSE=ExtraTreesRegressor_fnc1(df,shifts,train_pct)
  # Chossing the Best Model
  n=3# Number of Models Active
  bom=['Linear Regression','K-Nearest Regression','Decision Tree Regression','Bagging Regression','Extra Tree Regression']
  LR=int(sum(LMSE)/36500)
  KNR=int(sum(KMSE)/36500)
  DTR=int(sum(DMSE)/36500)
  #BR=int(sum(BMSE)/36500)
  EFR=int(sum(EMSE)/36500)
  print(" Mean MSE for Linear Regression for the entire list is {}".format(LR))
  print(" Mean MSE for K-Nearest Neighbors Regression for the entire list is {}".format(KNR))
  print(" Mean MSE for Decision Tree Regression for the entire list is {}".format(DTR))
  ovr.append(LR)
  ovr.append(KNR)
  ovr.append(DTR)
  #ovr.append(BR)
  #ovr.append(EFR)
  idx=minimum(ovr)
  return bom[idx]

def minimum(ovr):
  current_min = ovr[0]  
  for num in ovr:       
    if num < current_min:
      current_min = num  
  return ovr.index(current_min)

def process_2(pos,shft): # Creates a new list till the maximum limit
 # inputs: position of the maximum number of day for which the model is valid (int),list of days
 # output: Creates a new list containing the number of days for which the model remains valid
  shift=[]
  ele=pos+1
  for k in range(1,ele,1):
    shift.append(k)
  return shift

def logic(bp):
 # inputs: the dataframe of the best permutation
 # output: None
  print("\n welcome to model selection and prediction algorithm")
  shft=[] # Store number of days with a max limit of one year including multiples of seven which makes n week ,and also multiple of 28 which on the whole makes n month as( 4 weeks{4*7} make a month)
  for i in range(1,366): # Max limit for the number of days could be  based on the number of years so for time being i have enclosed the same as one year as 1year=365 days
    shft.append(i)
  train_pct =75
  train_pct=train_pct/100;
  print("\n Columns Format checking initialised")
  bp=CorrectColumnTypes(bp)
  print("\n Columns Format checking performed succesfully")
  bm=models_log(bp,shft,train_pct)
  print("\n The best Model for the given dataset after evaluation is {}".format(bm))
  pos=best_model(bp,shft,train_pct,bm)
  print("The model {0} is valid for {1} days".format(bm,pos))
  sft=process_2(pos,shft)
  print(sft)
  calc_prof_plot(bp,sft,pos,bm,train_pct)

def active_hour(bp):# Recursively activates the algorithm on an hourly basis
 # inputs: the dataframe of the best permutation
 # output: None
  while 1:
    print("\n Initialising the Model Prediction Algorithm")
    logic(bp)

    dt = datetime.now() + timedelta(hours=1)
    dt = dt.replace(minute=59) # Recursively runs the code at the start of every hour

    while datetime.now() < dt:
        time.sleep(1)

"""**Part-2**"""

def slm_preprocess(bp):# processing the inputs for initialsing Stage-2
  print("\n The unprocessed dataframe would be")
  display(bp)
  bp=bp.set_index('Date')
  bp = bp.reindex(['Open','High','Low','Close','Volume','Profit/Loss (C)'], axis=1)
  date_change = '%Y-%m-%d'
  bp['Date'] = bp.index
  bp['Date'] = pd.to_datetime(bp['Date'], format = date_change)
  Dates = bp['Date']
  bp = add_all_ta_features(bp, "Open", "High", "Low", "Close", "Volume", fillna=True) 
  #print(bp.columns)
  date_change = '%Y-%m-%d'
  # Define the date parts 
  fastai.tabular.add_datepart(bp,'Date', drop = 'True')
  # Ensure the correct format
  bp['Date'] = pd.to_datetime(bp.index.values, format = date_change)
  # Add the date parts
  fastai.tabular.add_cyclic_datepart(bp, 'Date', drop = 'True')
  print("\n The processed dataframe would be")
  display(bp)
  return bp

"""**Part-3**"""

def data_preprocess(df1,sim):
  df1['SIM']=str(sim)
  df1=df1.dropna(how='any')
  df1['Entry DateTime'] = pd.to_datetime(df1['Entry DateTime'])
  df1['Exit DateTime'] = pd.to_datetime(df1['Exit DateTime'])
  #df1['Day']=pd.to_datetime(df1['Entry DateTime']).dt.day
  #df1['Month']=pd.to_datetime(df1['Entry DateTime']).dt.month
  #df1['year']=pd.to_datetime(df1['Entry DateTime']).dt.year
  df1['Time(Entry)']=pd.to_datetime(df1['Entry DateTime']).dt.time
  #df['Time(Exit)']=pd.to_datetime(df['Exit DateTime']).dt.time
  df1['DOW']=pd.to_datetime(df1['Entry DateTime']).dt.day_name()#Type of day of the week
  df1["Entry DateTime"]=df1["Entry DateTime"].dt.strftime("%y-%m-%d")
  df1['Time(Entry)']=df1['Time(Entry)'].astype(str)
  df1['Time(Entry)']=(df1['Time(Entry)'].str.split(':').apply(lambda x: int(x[0]) * 60 + int(x[1]))).astype(int)
  df1['Duration']=df1['Duration'].astype(str)
  df1['Duration']=(df1['Duration'].str.split(':').apply(lambda x: int(x[0]) * 60 + int(x[1]))).astype(int)
  df1=df1.drop(columns=['Symbol','Trade Type','Exit DateTime','Max Open Quantity','Max Closed Quantity','Cumulative Profit/Loss (C)','Exit Efficiency','Entry Efficiency','FlatToFlat Profit/Loss (C)','FlatToFlat Max Open Profit (C)','FlatToFlat Max Open Loss (C)','Max Open Profit (C)','Max Open Loss (C)','Note','Commission (C)','Open Position Quantity','Close Position Quantity',])
  df1=df1.rename(columns ={'Entry DateTime':'Date',}, inplace = False)
  df1['Total Efficiency'] = list(map(lambda x: x[:-1], df1['Total Efficiency'].values))
  df1['Total Efficiency'] = [float(x) for x in df1['Total Efficiency'].values]
  df1['Profit/Loss (C)'] = list(map(lambda x: x[:-1], df1['Profit/Loss (C)'].values))
  df1['Profit/Loss (C)'] = [float(x) for x in df1['Profit/Loss (C)'].values]
  df1['Time(Entry)']=df1['Time(Entry)'].astype(int)
  return df1
  
def process(mn,day):  
   sim=['sim100','sim101','sim102','sim103','sim110','sim111','sim112','sim113','sim120','sim121','sim122','sim123','sim130','sim131','sim132','sim133']  
   dg=[]
   loc=['/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim100 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim101 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim102 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim103 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim110 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim111 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim112 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim113 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim120 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim121 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim122 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim123 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim130 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim131 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim132 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim133 Trades.txt'] 
   for i in range(len(loc)):
     for j in range(len(sim)):
       if i==j:
         t= 'df' + '{}'.format(i)
         t=pd.read_csv('{}'.format(loc[i]),delimiter="\t")
         dg.append(t)
       else:
          continue
   print("\n The total number of permutations files is {}".format(len(dg)))
   df1=data_preprocess(dg[0],sim[0])
   df2=data_preprocess(dg[1],sim[1])
   df3=data_preprocess(dg[2],sim[2])
   df4=data_preprocess(dg[3],sim[3])
   df5=data_preprocess(dg[4],sim[4])
   df6=data_preprocess(dg[5],sim[5])
   df7=data_preprocess(dg[6],sim[6])
   df8=data_preprocess(dg[7],sim[7])
   df9=data_preprocess(dg[8],sim[8])
   df10=data_preprocess(dg[9],sim[9])
   df11=data_preprocess(dg[10],sim[10])
   df12=data_preprocess(dg[11],sim[11])
   df13=data_preprocess(dg[12],sim[12])
   df14=data_preprocess(dg[13],sim[13])
   df15=data_preprocess(dg[14],sim[14])
   df16=data_preprocess(dg[15],sim[15])
   pnl=[]
   te=[]
   fg=[df1,df2,df3,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16]
   for i in range(len(sim)):
    for j in range(len(fg)):
      if i==j:
        l,k=gather_details(mn,day,fg[j],sim[i])
        te.append(int(l))
        pnl.append(int(k))
      else:
        continue
   #print("\n" ,pnl)
   #print("\n" ,te)
   sm=process_1(te,pnl,sim)
   return sm
   #return df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16





def time_valid(tim): # Function to check validity of time
# inputs: time(str)
# ouptut: boolean value
  try:
      time.strptime(tim, '%H:%M:%S')
      return True
  except ValueError:
        return False

def hour_format(str1): # Function to convert the given time in 24 hr clock based on am or pm format
# inputs: time with am/pm (str)
# ouptut: time in 24hr clock
     if (str1[-2:] == "AM" or str1[-2:] == "Am" or str1[-2:] == "aM" or str1[-2:] == 'am') and str1[:2] == "12":
         return "00" + str1[2:-2]
     elif (str1[-2:] == "AM" or str1[-2:] == "Am" or str1[-2:] == "aM" or str1[-2:] == 'am') :
         return str1[:-2]
     elif (str1[-2:] == "PM" or str1[-2:] == "Pm" or str1[-2:] == "pM" or str1[-2:] == 'pm') and str1[:2] == "12":
         return str1[:-2]
     else:
      return str(int(str1[:2]) + 12) + str1[2:8]

def calc_mins(tm):#Function to convert hrs ,mins,secs into minutes
# inputs: time in Hours,minutes,seconds
# ouptut: returns time in minutes

     if int(tm[0:1]) ==0 and int(tm[3:4])!=0 : #if time in am like 03:00:00 then answer should not be zero rather the answer should be 3*60=180 so this condito would oversee the same
        mn=int((int(tm[1:2])*60)+int(tm[3:5])+int(int(tm[6:8])/60))
     elif int(tm[3:4]) ==0 and int(tm[0:1]!=0): #if time in am like 13:06:00 then answer should not be zero rather the answer should be 13*60=180 + 6 so this condito would oversee the same
        mn=int((int(tm[0:2])*60)+int(tm[4:5])+int(int(tm[6:8])/60))
     elif int(tm[3:4]) ==0 and int(tm[0:1] ==0): #if time in am like 03:06:00 then answer should not be zero rather the answer should be 3*60=180 + 6 so this condito would oversee the same
        mn=int((int(tm[1:2])*60)+int(tm[4:5])+int(int(tm[6:8])/60))
     else:
        mn=int((int(tm[0:2])*60)+int(tm[3:5])+int(int(tm[6:8])/60))
     return mn

def gather_details(mn,day,df,s):
# inputs: minutes(int),day(str)
# ouptut: returns the best simulator type(str)
  tf=[]
  sim=[]
  pl=[]
  for i in range(len(df)):
    if df['DOW'][i] == day:
      if int(df['Time(Entry)'][i])<= int(mn):# This condition should be valid due to the fact that say a person whowants to invest in stocks would require the knowledge of the stocks trading in the earlier times(history of profit/loss for the  stock): same principle followed here
          tf.append(int(df['Total Efficiency'][i]))
          pl.append(int(df['Profit/Loss (C)'][i]))
          sim.append(s)
      else:
        continue
    else:
      continue
  if len(tf)!=0 and len(pl)!=0:
    Mt=sum(tf)
    Mp=sum(pl)
    return Mt,Mp
  else:
    Mt=0
    Mp=0
    return Mt,Mp
    
  
def process_1(Mt,Mp,sim):
  i=Mt.index(max(Mt))
  j=Mp.index(max(Mp))
  return sim[j] # Due to the fact that maximum profit/loss is exhibited by this permutation


def get_dataframe(sim):
# inputs: best simulator type 
# ouptut: returns the best permutaion dataframe based on simulator type 
  fn="/content/GC AT IPS(2)+TM(A) 2016-05_2021 {} Trades.txt".format(sim)
  bp=pd.read_csv(fn,delimiter="\t")
  bp=bp.dropna(how='any')
  bp=bp.reset_index(drop=True)
  #bp['DOW']=pd.to_datetime(bp['Entry DateTime']).dt.day_name()#Type of day of the week
  bp['Entry DateTime'] = pd.to_datetime(bp['Entry DateTime'])
  bp['Time(Entry)']=pd.to_datetime(bp['Entry DateTime']).dt.time
  bp["Entry DateTime"]=bp["Entry DateTime"].dt.strftime("%y-%m-%d")
  bp['Time(Entry)']=bp['Time(Entry)'].astype(str)
  bp['Time(Entry)']=(bp['Time(Entry)'].str.split(':').apply(lambda x: int(x[0]) * 60 + int(x[1]))).astype(int)
  bp=bp.drop(columns=['Symbol','Trade Type','Exit DateTime','Duration','Total Efficiency','Time(Entry)','Max Open Quantity','Max Closed Quantity','Cumulative Profit/Loss (C)','Exit Efficiency','Entry Efficiency','FlatToFlat Profit/Loss (C)','FlatToFlat Max Open Profit (C)','FlatToFlat Max Open Loss (C)','Max Open Profit (C)','Max Open Loss (C)','Note','Commission (C)','Open Position Quantity','Close Position Quantity',])
  bp=bp.rename(columns ={'Entry DateTime':'Date','Entry Price':'Open','Exit Price':'Close','High Price While Open':'High','Low Price While Open':'Low','Trade Quantity':'Volume'}, inplace = False)
  #bp['Total Efficiency'] = list(map(lambda x: x[:-1], bp['Total Efficiency'].values))
  #bp['Total Efficiency'] = [float(x) for x in bp['Total Efficiency'].values]
  #bp['Time(Entry)']=bp['Time(Entry)'].astype(int)
  bp['Profit/Loss (C)'] = list(map(lambda x: x[:-1], bp['Profit/Loss (C)'].values))
  bp['Profit/Loss (C)'] = [float(x) for x in bp['Profit/Loss (C)'].values]
  bp['Open']=bp['Open'].astype(int)
  bp['Close']=bp['Close'].astype(int)
  bp['Volume']=bp['Volume'].astype(int)
  bp['High']=bp['High'].astype(int)
  bp['Low']=bp['Low'].astype(int)
  return bp

def bp_process(bp):
# inputs: best permutation dataframe
# ouptut: returns the best permutaion dataframe with perfect stae format
  for i in range(len(bp)):
    tmp=bp['Date'][i]
    tmp="20"+tmp[0:2]+tmp[2:]
    bp['Date'][i]=tmp
  return bp


def welcome(): #  function to initialize
  print("\n Welcome to Stock Analysis")
  print("\n Kindly enter the details with care below")
  day=input("\n Enter the day of the week")
  f1=['monday','tuesday','wednesday','thursday','friday','sunday','Monday','Tuesday','Wednesday','Thursday','Friday','Sunday','Saturday','saturday']
  if day in f1:
    day=day.capitalize()
    if day =='Sunday' or day == 'sunday':
      tim=input("\n Enter the time  in the format (hrs:min:sec) followed by am/pm after a space")# Enter time in normal method like 01:00:00 am or 02:50:00pm and not in 24 hr clock format
      tmi=tim[0:8]
      if time_valid(tmi):
        tm=hour_format(tim)
        print("\n Conversion of the time in 24 hours format (if in pm) hence the time after conversion would {}".format(tm[0:8]))# converting to 24 hr format for ease of comparision with the primary permutation df
        mn=calc_mins(tm)
        if mn>1000:
          print("\n Calculation of the time in Minutes based on the above performed conversion hence the time in minutes would be {}".format(mn))# useful for comparing with the entry time denoted in minutes (converted from 24 hr clock format)
          sim=process(mn,day)
          print("\n The best results for the day {} of the week  during time {} of the day is given by {} the permutation (dataset)".format(day,tim,sim))
          bp=get_dataframe(sim)
          bp=bp_process(bp)
          return bp
        else:
          print("\n Data not valid")
          sys.exit()
      else:
        print("\n Time Format invalid Please try again")
        sys.exit()
    else:
      tim=input("\n Enter the time  in the format (hrs:min:sec) followed by a space, followed by am/pm")# Enter time in normal method like 01:00:00 am or 02:50:00pm and not in 24 hr clock format
      tmi=tim[0:8]
      if time_valid(tmi):
        tm=hour_format(tim)
        print("\n Conversion of the time in 24 hours format (if in pm) hence the time after conversion would {}".format(tm[0:8]))# converting to 24 hr format for ease of comparision with the primary permutation df
        mn=calc_mins(tm)
        print("\n Calculation of the time in Minutes based on the above performed conversion hence the time in minutes would be {}".format(mn))# useful for comparing with the entry time denoted in minutes (converted from 24 hr clock format)
        sim=process(mn,day)
        if sim==-1:
          print("\n Input Data not valid")
          sys.exit()
        else:
          print("\n The best results for the day {} of the week  during time {} of the day is given by {} the permutation (dataset)".format(day,tim,sim))
          bp=get_dataframe(sim)
          bp=bp_process(bp)
          bp.to_csv(r'Best Permutation file {}.csv'.format(sim), index=False)
          print("\n Local copy of the file is saved")
          return bp
      else:
        print("\n Time Format invalid Please try again")
        sys.exit()
  else:
     print("\n Invalid Format of day Please try again")
     sys.exit()

"""**Kindly execute the code cells Part-1 and Part-2 and Part-3 before executing the below code cell**"""

def main():
  bp=welcome()
  bp=slm_preprocess(bp)
  active_hour(bp)
main()

"""### **Model-2 Trading Analysis based on automated inputand super learner model(without cross validation score)**

**Part-1**
"""

def CorrectColumnTypes(bp):# Ensure column types are correct
  # Input: dataframe 
  # ouptut: dataframe (with column types changed)

  # Numbers
  for col in bp.columns[1:80]:
      bp[col] = bp[col].astype('float')

  for col in bp.columns[-10:]:
      bp[col] = bp[col].astype('float')

  # Categories 
  for col in bp.columns[80:-10]:
      bp[col] = bp[col].astype('category')
  return bp


def CreateLags(df,lag_size): # Creating lags for prediction os OOS (Out of Samples)
  # inputs: dataframe , size of the lag (int)
  # ouptut: dataframe ( with extra lag column), shift size (int)
  # add lag
  shiftdays = int(lag_size)
  shft = -shiftdays
  df['Close_lag'] = df['Close'].shift(shft)
  return df, shft

def SplitData(df, train_pct, shift): # Splitting the dataframe into train and test
  # inputs: dataframe , training_pct (float between 0 and 1), size of the lag (int)
  # ouptut: x train dataframe, y train data frame, x test dataframe, y test dataframe, train data frame, test dataframe

  train_pt = int(len(df)*train_pct)
  train = df.iloc[:train_pt,:]
  test = df.iloc[train_pt:,:]
  x_train = train.iloc[:shift,1:-1]
  y_train = train['Close_lag'][:shift]
  x_test = test.iloc[:shift,1:-1]
  y_test = test['Close'][:shift]

  return x_train, y_train, x_test, y_test, train, test

def calc_prof_plot(df,shft,pos,bm,train_pct):
  # inputs: dataframe , list,maximum  number of days position(int), best model(str)
  # ouptut: plot,details on a daily basis based on shft list
  disp(pos,shft)
  sfd=shft.copy()
  tpd=[]
  pa=[]
  if bm=='Linear Regression':
    for j in shft:
      print(str(j) + ' days out:')
      print('------------')
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred =LinearRegression_fnc(x_train,y_train, x_test, y_test)
      test2, profit_dollars, td = CalcProfit(test,lr_pred,j)
      pa.append(profit_dollars)
      tpd.append(td)
      if j<=min(shft):
        PlotModelResults_Plotly(train, test, lr_pred, j, 'Linear Regression',shift)
      else:
        print("\n As a lot of API calls occur this leads to crashing of the colab notebook and hence the graphs for the subsequent days are not displayed  ")
    x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
    PlotModelProfit_Plotly(train, test, pa ,pos,'Linear Regression',shift)
    create_dataframe(test,pa,tpd)


        
  elif bm=='K-Nearest Regression':
    for j in shft:
      print(str(j) + ' days out:')
      print('------------')
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred =KNearestRegression_fnc(x_train,y_train, x_test, y_test)
      test2, profit_dollars,td = CalcProfit(test,lr_pred,j)
      pa.append(profit_dollars)
      tpd.append(td)
      if j<=min(shft):
        PlotModelResults_Plotly(train, test, lr_pred, j, 'K-Nearest Regression',shift)
      else:
        print("As a lot of API calls occur this leads to crashing of the colab notebook and hence the graphs for the subsequent days are not displayed")
    x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
    PlotModelProfit_Plotly(train, test, pa ,pos,'Linear Regression',shift)
    create_dataframe(test,pa,tpd)

  elif bm=='Decision Tree Regression':
      for j in shft:
        print(str(j) + ' days out:')
        print('------------')
        df_lag, shift = CreateLags(df,j)
        df_lag = CorrectColumnTypes(df_lag)
        x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
        lr_pred =DecisionTreeRegression_fnc(x_train,y_train, x_test, y_test)
        test2, profit_dollars,td = CalcProfit(test,lr_pred,j)
        pa.append(profit_dollars)
        tpd.append(td)
        if j<=min(shft):
          PlotModelResults_Plotly(train, test, lr_pred, j, 'Decision Tree Regression',shift)
        else:
          print("As a lot of API calls occur this leads to crashing of the colab notebook and hence the graphs for the subsequent days are not displayed")
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      PlotModelProfit_Plotly(train, test, pa ,pos,'Linear Regression',shift)
      create_dataframe(test,pa,tpd)

  elif bm=='Bagging Regression':
    for j in shifts: 
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred = BaggingRegressor_fnc(x_train,y_train, x_test, y_test)
      test2, profit_dollars,td = CalcProfit(test,lr_pred,j)
      pa.append(profit_dollars)
      tpd.append(td)
      if j<=min(shft):
        PlotModelResults_Plotly(train, test, lr_pred, j, 'Bagging Regression',shift)
      else:
        print("As a lot of API calls occur this leads to crashing of the colab notebook and hence the graphs for the subsequent days are not displayed")
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      PlotModelProfit_Plotly(train, test, pa ,pos,'Linear Regression',shift)
      create_dataframe(test,pa,tpd)

  elif bm=='Extra Tree Regression':
      for j in shft:
          print(str(j) + ' days out:')
          print('------------')
          df_lag, shift = CreateLags(df,j)
          df_lag = CorrectColumnTypes(df_lag)
          x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
          lr_pred =ExtraTreeRegression_fnc(x_train,y_train, x_test, y_test)
          test2, profit_dollars,td = CalcProfit(test,lr_pred,j)
          pa.append(profit_dollars)
          tpd.append(td)
          if j<=min(shft):
            PlotModelResults_Plotly(train, test, lr_pred, j, 'Extra Tree Regression',shift)
          else:
            print("As a lot of API calls occur this leads to crashing of the colab notebook and hence the graphs for the subsequent days are not displayed")
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      PlotModelProfit_Plotly(train, test, pa ,pos,'Linear Regression',shift)
      create_dataframe(test,pa,tpd)
   

def disp(pos,shft): # Displays the valid number of days,months,weeks during the model is considered to be valid

   if pos %7==0 and pos %28!=0:
      print("The model can work for {} weeks".format(pos//7))
   elif pos %28==0 and pos %7!=0:
      print("The model can work for {} months".format(pos//28))
   else:
      print("The model can work for {} days".format(pos))

# Regreesion Functions

def LinearRegression_fnc(x_train,y_train, x_test, y_test):
  #inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the predicted values of the test data (list)
  #print("\n Linear Regression Model")
  lr = LinearRegression()
  lr.fit(x_train,y_train)
  lr_pred = lr.predict(x_test)
  return lr_pred



def LinearRegression_fnc1(df,shifts,train_pct):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the  list of values for MSE
  print("\n Linear Regression Model")
  LMSE=[]
  for j in shifts: 
    df_lag, shift = CreateLags(df,j)
    df_lag = CorrectColumnTypes(df_lag)
    x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
    lr = LinearRegression()
    lr.fit(x_train,y_train)
    lr_pred = lr.predict(x_test)
    lr_MSE = mean_squared_error(y_test, lr_pred)
    lr_R2 = lr.score(x_test, y_test)
    LMSE.append(lr_MSE)
  return LMSE




def KNearestRegression_fnc(x_train,y_train, x_test, y_test):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the predicted values for the test data (list)
  #print("\n K- Nearest Neighbors Regression Model")
  knr = KNeighborsRegressor()
  knr.fit(x_train,y_train)
  knr_pred = knr.predict(x_test)
  return knr_pred



def KNearestRegression_fnc1(df,shifts,train_pct):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the  list of values for MSE
  print("\n K- Nearest Neighbors Regression Model")
  KMSE=[]
  for j in shifts: 
    df_lag, shift = CreateLags(df,j)
    df_lag = CorrectColumnTypes(df_lag)
    x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
    knr = KNeighborsRegressor()
    knr.fit(x_train,y_train)
    knr_pred = knr.predict(x_test)
    knr_MSE = mean_squared_error(y_test, knr_pred)
    knr_R2 = knr.score(x_test, y_test)
    KMSE.append(knr_MSE)
  return KMSE

def DecisionTreeRegression_fnc(x_train,y_train, x_test, y_test):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the predicted values for the test data (list)
  #print("\n Decision Tree Regression Model")
  dtr = DecisionTreeRegressor()
  dtr.fit(x_train,y_train)
  dtr_pred = dtr.predict(x_test)
  return dtr_pred

def DecisionTreeRegression_fnc1(df,shifts,train_pct):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the  list of values for MSE
  print("\n Decision Tree Regression Model")
  DMSE=[]
  for j in shifts: 
    df_lag, shift = CreateLags(df,j)
    df_lag = CorrectColumnTypes(df_lag)
    x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
    dtr = DecisionTreeRegressor()
    dtr.fit(x_train,y_train)
    dtr_pred = dtr.predict(x_test)
    dtr_MSE = mean_squared_error(y_test, dtr_pred)
    dtr_R2 = dtr.score(x_test, y_test)
    DMSE.append(dtr_MSE)
  return DMSE

def BaggingRegressor_fnc(x_train,y_train, x_test, y_test):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the predicted values for the test data (list)
  #print("\n Bagging Regression Model")
  br = BaggingRegressor()
  br.fit(x_train,y_train)
  br_pred = br.predict(x_test)
  return br_pred

def BaggingRegressor_fnc1(df,shifts,train_pct):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the  list of values for MSE
  print("\n Bagging Regression Model")
  BMSE=[]
  for j in shifts: 
    df_lag, shift = CreateLags(df,j)
    df_lag = CorrectColumnTypes(df_lag)
    x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
    br = BaggingRegressor()
    br.fit(x_train,y_train)
    br_pred = br.predict(x_test)
    br_MSE = mean_squared_error(y_test, br_pred)
    br_R2 = br.score(x_test, y_test)
    BMSE.append(br_MSE)
  return BMSE


def ExtraTreesRegressor_fnc(x_train,y_train, x_test, y_test):
  #inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the predicted values for the test data (list)
  #print("\n Extra Trees Regression Model")
  etr = RandomForestRegressor()
  etr.fit(x_train,y_train)
  etr_pred = etr.predict(x_test)
  return etr_pred


def ExtraTreesRegressor_fnc1(df,shifts,train_pct):
  #inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the  list of values for MSE
  print("\n Extra Trees Regression Model")
  EMSE=[]
  for j in shifts: 
    df_lag, shift = CreateLags(df,j)
    df_lag = CorrectColumnTypes(df_lag)
    x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
    etr = RandomForestRegressor()
    etr.fit(x_train,y_train)
    etr_pred = etr.predict(x_test)  
    etr_MSE = mean_squared_error(y_test, etr_pred)
    etr_R2 = etr.score(x_test, y_test)
    EMSE.append(etr_MSE)
  return EMSE


def Calctradingdays(test_df,pred,j):# Calculates number of good trading days based on the model prediction
  # inputs: dataframe,predicted values, day
  # output: the number of good trading days
  pd.set_option('mode.chained_assignment', None)
  test_df['pred'] = np.nan
  test_df['pred'].iloc[:-j] = pred
  test_df['change'] = test_df['Close_lag'] - test_df['Close'] 
  test_df['change_pred'] = test_df['pred'] - test_df['Close'] 
  test_df['MadeMoney'] = np.where(test_df['change_pred']/test_df['change'] > 0, 1, -1) 
  test_df['profit'] = np.abs(test_df['change']) * test_df['MadeMoney']
  profit_dollars = test_df['profit'].sum()
  profit_days = len(test_df[test_df['MadeMoney'] == 1])
  tdays=round(profit_days/(len(test_df)-j),2)
  return tdays



def CalcProfit(test_df,pred,j): # Function to calculate aggregrate profit/loss made in the days
  # inputs: dataframe,predicted values, day
  # output: the aggregated profit/loss made in the predicted days(j)
  pd.set_option('mode.chained_assignment', None)
  test_df['pred'] = np.nan
  test_df['pred'].iloc[:-j] = pred
  test_df['change'] = test_df['Close_lag'] - test_df['Close'] 
  test_df['change_pred'] = test_df['pred'] - test_df['Close'] 
  test_df['MadeMoney'] = np.where(test_df['change_pred']/test_df['change'] > 0, 1, -1) 
  test_df['profit'] = np.abs(test_df['change']) * test_df['MadeMoney']
  profit_dollars = test_df['profit'].sum()
  pad=str(round(profit_dollars,1))
  print("\n Aggregated Profit/Loss Results")
  if pad[0]=='-':
      print('Loss: $ ' + str(round(profit_dollars,1)))
  else:
      print('Profit: $ ' + str(round(profit_dollars,1)))
  profit_days = len(test_df[test_df['MadeMoney'] == 1])
  td = str(round(profit_days/(len(test_df)-j),2)*100) 
  print('Percentage of good trading days: ' + str( round(profit_days/(len(test_df)-j),2)*100) )

  return test_df, profit_dollars,td
 

def disp_results(sfd,pa,tpd): # Displays important details after the graphs 
 # inputs: sfd(list), profit_dollars(list), goodtrade days(list)
 # output: None
  for i in range(len(sfd)):
    for j in range(len(pa)):
      for k in range(len(tpd)):
        if i==j and i==k and j==k :
          print("\n For Day {0} the aggregated profit/loss would be {1} and the estimated percentage of good trading days would be {2}".format(sfd[i],pa[j],tpd[k]))
        else:
          continue
  
def PlotModelProfit_Plotly(train, test, pred,shift_days,name,shift):  # Function to make the plots    
  # inputs: train dataframe, test dataframe, predicted value (list), shift size (int), name (string)
  # output: Graph
  w = 25 # width
  h = 25 # height
  # Create lines of the training actual, testing actual, prediction 
  D1 = go.Scatter(x=train.index,y=train['Profit/Loss (C)'],name = 'Actual Profit/Loss based on  Train data') # Training actuals
  D2 = go.Scatter(x=test.index[:shift],y=test['Profit/Loss (C)'],name = 'Actual Profit/Loss based on  Train data') # Testing actuals
  D3 = go.Scatter(x=test.index[:shift],y=pred,name = 'Predicted Profit/Loss from model') # Testing predction
  tickerSymbol="[Sim]F.US.GCEQ21"
  # Combine in an object  
  line = {'data': [D1,D2,D3],
          'layout': {
              'xaxis' :{'title': 'Date'},
              'yaxis' :{'title': 'Agregate Profit/Loss'},
              'title' : name + ' - ' + tickerSymbol + ' - ' + str(shift_days)
          }}
  # Send object to a figure 
  fig = go.Figure(line)

  # Show figure
  fig.show()

def create_dataframe(test,pa,tpd):
 # a=list(train['Profit/Loss (C)'])
  b=list(test['Profit/Loss (C)'])
  lst=zip(b,pa,tpd)
  df = pd.DataFrame(list(lst),columns =['Actual Profit/Loss for Train','Predicted Profit/Loss from model','Percenatge of good trading Days'])
  display(df)

def PlotModelResults_Plotly(train, test, pred,shift_days,name,shift):  # Function to make the plots    
  # inputs: train dataframe, test dataframe, predicted value (list), shift size (int), name (string)
  # output: Graph
  w = 25 # width
  h = 25 # height
  # Create lines of the training actual, testing actual, prediction 
  D1 = go.Scatter(x=train.index,y=train['Close'],name = 'Train Actual') # Training actuals
  D2 = go.Scatter(x=test.index[:shift],y=test['Close'],name = 'Test Actual') # Testing actuals
  D3 = go.Scatter(x=test.index[:shift],y=pred,name = 'Model Prediction') # Testing predction
  tickerSymbol="[Sim]F.US.GCEQ21"
  # Combine in an object  
  line = {'data': [D1,D2,D3],
          'layout': {
              'xaxis' :{'title': 'Date'},
              'yaxis' :{'title': 'Money'},
              'title' : name + ' - ' + tickerSymbol + ' - ' + str(shift_days)
          }}
  # Send object to a figure 
  fig = go.Figure(line)

  # Show figure
  fig.show()

def best_model(df,shifts,train_pct,bm):
  # inputs: train dataframe, list,train percenatge(float), best model name(str)
  # output: Number of good trading days calculated by the prediction made by the best model
  td=[]
  if bm=='Linear Regression':
    for j in shifts: 
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred = LinearRegression_fnc(x_train,y_train, x_test, y_test)
      temp=Calctradingdays(test,lr_pred,j)
      td.append(temp)
  elif bm=='K-Nearest Regression':
    for j in shifts: 
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred =KNearestRegression_fnc(x_train,y_train, x_test, y_test)
      temp=Calctradingdays(test,lr_pred,j)
      td.append(temp)
  elif bm=='Decision Tree Regression':
    for j in shifts: 
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred = DecisionTreeRegression_fnc(x_train,y_train, x_test, y_test)
      temp=Calctradingdays(test,lr_pred,j)
      td.append(temp)

  elif bm=='Bagging Regression':
    for j in shifts: 
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred = BaggingRegressor_fnc(x_train,y_train, x_test, y_test)
      temp=Calctradingdays(test,lr_pred,j)
      td.append(temp)

  elif bm=='Extra Tree Regression':
      for j in shifts: 
        df_lag, shift = CreateLags(df,j)
        df_lag = CorrectColumnTypes(df_lag)
        x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
        lr_pred = ExtraTreesRegressor_fnc(x_train,y_train, x_test, y_test)
        temp=Calctradingdays(test,lr_pred,j)
        td.append(temp)
  return shifts[td.index(max(td))]


def models_log(df,shifts,train_pct):
  # inputs: train dataframe, list,train percenatge(float)
  # output: The best model name which could be used for further evaluation 
  LMSE=[]
  KMSE=[]
  BMSE=[]
  DMSE=[]
  RMSE=[]
  EMSE=[]
  ovr=[]
  # Linear Regression
  LMSE = LinearRegression_fnc1(df,shifts,train_pct)
  # K-Neareast Neighbors
  KMSE =KNearestRegression_fnc1(df,shifts,train_pct)
  # DecisionTree Regression
  DMSE = DecisionTreeRegression_fnc1(df,shifts,train_pct)
  # Bagging Regression
  # BMSE = BaggingRegressor_fnc1(df,shifts,train_pct)
  # ExtraTrees Regression
  # EMSE=ExtraTreesRegressor_fnc1(df,shifts,train_pct)
  # Chossing the Best Model
  n=3# Number of Models Active
  bom=['Linear Regression','K-Nearest Regression','Decision Tree Regression','Bagging Regression','Extra Tree Regression']
  LR=int(sum(LMSE)/36500)
  KNR=int(sum(KMSE)/36500)
  DTR=int(sum(DMSE)/36500)
  #BR=int(sum(BMSE)/36500)
  EFR=int(sum(EMSE)/36500)
  print(" Mean MSE for Linear Regression for the entire list is {}".format(LR))
  print(" Mean MSE for K-Nearest Neighbors Regression for the entire list is {}".format(KNR))
  print(" Mean MSE for Decision Tree Regression for the entire list is {}".format(DTR))
  ovr.append(LR)
  ovr.append(KNR)
  ovr.append(DTR)
  #ovr.append(BR)
  #ovr.append(EFR)
  idx=minimum(ovr)
  return bom[idx]

def minimum(ovr):
  current_min = ovr[0]  
  for num in ovr:       
    if num < current_min:
      current_min = num  
  return ovr.index(current_min)

def process_2(pos,shft): # Creates a new list till the maximum limit
 # inputs: position of the maximum number of day for which the model is valid (int),list of days
 # output: Creates a new list containing the number of days for which the model remains valid
  shift=[]
  ele=pos+1
  for k in range(1,ele,1):
    shift.append(k)
  return shift

def logic(bp):
 # inputs: the dataframe of the best permutation
 # output: None
  print("\n welcome to model selection and prediction algorithm")
  shft=[] # Store number of days with a max limit of one year including multiples of seven which makes n week ,and also multiple of 28 which on the whole makes n month as( 4 weeks{4*7} make a month)
  for i in range(1,366): # Max limit for the number of days could be  based on the number of years so for time being i have enclosed the same as one year as 1year=365 days
    shft.append(i)
  train_pct =75
  train_pct=train_pct/100;
  print("\n Columns Format checking initialised")
  bp=CorrectColumnTypes(bp)
  print("\n Columns Format checking performed succesfully")
  bm=models_log(bp,shft,train_pct)
  print("\n The best Model for the given dataset after evaluation is {}".format(bm))
  pos=best_model(bp,shft,train_pct,bm)
  print("The model {0} is valid for {1} days".format(bm,pos))
  sft=process_2(pos,shft)
  print(sft)
  calc_prof_plot(bp,sft,pos,bm,train_pct)

def active_hour(bp):# Recursively activates the algorithm on an hourly basis
 # inputs: the dataframe of the best permutation
 # output: None
  from datetime import datetime, timedelta
  while 1:
    print("\n Initialising the Model Prediction Algorithm")
    logic(bp)

    dt = datetime.now() + timedelta(hours=1)
    dt = dt.replace(minute=59) # Recursively runs the code at the start of every hour

    while datetime.now() < dt:
        time.sleep(1)

"""**Part-2**"""

def slm_preprocess(bp):# processing the inputs for initialsing Stage-2
  #df=df.drop(["Date",	"Entry Price",	"Exit Price",	"Trade Quantity",	"Profit/Loss (C)",	"Duration",	"High Price While Open"	,"Low Price While Open",	"Total Efficiency","SIM","Day","Month","year",	"Time(Entry)"	,"DOW"], axis = 1, inplace = True)
  print("\n The unprocessed dataframe would be")
  display(bp)
  bp=bp.set_index('Date')
  bp = bp.reindex(['Open','High','Low','Close','Volume','Profit/Loss (C)'], axis=1)
  date_change = '%Y-%m-%d'
  bp['Date'] = bp.index
  bp['Date'] = pd.to_datetime(bp['Date'], format = date_change)
  Dates = bp['Date']
  bp = add_all_ta_features(bp, "Open", "High", "Low", "Close", "Volume", fillna=True) 
  #print(bp.columns)
  date_change = '%Y-%m-%d'
  # Define the date parts 
  fastai.tabular.add_datepart(bp,'Date', drop = 'True')
  # Ensure the correct format
  bp['Date'] = pd.to_datetime(bp.index.values, format = date_change)
  # Add the date parts
  fastai.tabular.add_cyclic_datepart(bp, 'Date', drop = 'True')
  print("\n The processed dataframe would be")
  display(bp)
  return bp

"""**Part-3**"""

import datetime # Library that handles datetime and processes the same
def data_preprocess(df1,sim):
  df1['SIM']=str(sim)
  df1=df1.dropna(how='any')
  df1['Entry DateTime'] = pd.to_datetime(df1['Entry DateTime'])
  df1['Exit DateTime'] = pd.to_datetime(df1['Exit DateTime'])
  #df1['Day']=pd.to_datetime(df1['Entry DateTime']).dt.day
  #df1['Month']=pd.to_datetime(df1['Entry DateTime']).dt.month
  #df1['year']=pd.to_datetime(df1['Entry DateTime']).dt.year
  df1['Time(Entry)']=pd.to_datetime(df1['Entry DateTime']).dt.time
  #df['Time(Exit)']=pd.to_datetime(df['Exit DateTime']).dt.time
  df1['DOW']=pd.to_datetime(df1['Entry DateTime']).dt.day_name()#Type of day of the week
  df1["Entry DateTime"]=df1["Entry DateTime"].dt.strftime("%y-%m-%d")
  df1['Time(Entry)']=df1['Time(Entry)'].astype(str)
  df1['Time(Entry)']=(df1['Time(Entry)'].str.split(':').apply(lambda x: int(x[0]) * 60 + int(x[1]))).astype(int)
  df1['Duration']=df1['Duration'].astype(str)
  df1['Duration']=(df1['Duration'].str.split(':').apply(lambda x: int(x[0]) * 60 + int(x[1]))).astype(int)
  df1=df1.drop(columns=['Symbol','Trade Type','Exit DateTime','Max Open Quantity','Max Closed Quantity','Cumulative Profit/Loss (C)','Exit Efficiency','Entry Efficiency','FlatToFlat Profit/Loss (C)','FlatToFlat Max Open Profit (C)','FlatToFlat Max Open Loss (C)','Max Open Profit (C)','Max Open Loss (C)','Note','Commission (C)','Open Position Quantity','Close Position Quantity',])
  df1=df1.rename(columns ={'Entry DateTime':'Date',}, inplace = False)
  df1['Total Efficiency'] = list(map(lambda x: x[:-1], df1['Total Efficiency'].values))
  df1['Total Efficiency'] = [float(x) for x in df1['Total Efficiency'].values]
  df1['Profit/Loss (C)'] = list(map(lambda x: x[:-1], df1['Profit/Loss (C)'].values))
  df1['Profit/Loss (C)'] = [float(x) for x in df1['Profit/Loss (C)'].values]
  df1['Time(Entry)']=df1['Time(Entry)'].astype(int)
  return df1
  
def process(mn,day):  
   sim=['sim100','sim101','sim102','sim103','sim110','sim111','sim112','sim113','sim120','sim121','sim122','sim123','sim130','sim131','sim132','sim133']  
   dg=[]
   loc=['/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim100 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim101 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim102 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim103 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim110 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim111 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim112 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim113 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim120 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim121 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim122 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim123 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim130 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim131 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim132 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim133 Trades.txt'] 
   for i in range(len(loc)):
     for j in range(len(sim)):
       if i==j:
         t= 'df' + '{}'.format(i)
         t=pd.read_csv('{}'.format(loc[i]),delimiter="\t")
         dg.append(t)
       else:
          continue
   print("\n The total number of permutations files is {}".format(len(dg)))
   df1=data_preprocess(dg[0],sim[0])
   df2=data_preprocess(dg[1],sim[1])
   df3=data_preprocess(dg[2],sim[2])
   df4=data_preprocess(dg[3],sim[3])
   df5=data_preprocess(dg[4],sim[4])
   df6=data_preprocess(dg[5],sim[5])
   df7=data_preprocess(dg[6],sim[6])
   df8=data_preprocess(dg[7],sim[7])
   df9=data_preprocess(dg[8],sim[8])
   df10=data_preprocess(dg[9],sim[9])
   df11=data_preprocess(dg[10],sim[10])
   df12=data_preprocess(dg[11],sim[11])
   df13=data_preprocess(dg[12],sim[12])
   df14=data_preprocess(dg[13],sim[13])
   df15=data_preprocess(dg[14],sim[14])
   df16=data_preprocess(dg[15],sim[15])
   pnl=[]
   te=[]
   fg=[df1,df2,df3,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16]
   for i in range(len(sim)):
    for j in range(len(fg)):
      if i==j:
        l,k=gather_details(mn,day,fg[j],sim[i])
        te.append(int(l))
        pnl.append(int(k))
      else:
        continue
   #print("\n" ,pnl)
   #print("\n" ,te)
   sm=process_1(te,pnl,sim)
   return sm
   #return df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16

def time_valid(tim): # Function to check validity of time
# inputs: time(str)
# ouptut: boolean value
  try:
      time.strptime(tim, '%H:%M:%S')
      return True
  except ValueError:
        return False

def calc_mins(tm):#Function to convert hrs ,mins,secs into minutes
# inputs: time in Hours,minutes,seconds
# ouptut: returns time in minutes
     if int(tm[0:1]) ==0 and int(tm[3:4])!=0 : #if time in am like 03:00:00 then answer should not be zero rather the answer should be 3*60=180 so this condito would oversee the same
        mn=int((int(tm[1:2])*60)+int(tm[3:5])+int(int(tm[6:8])/60))
     elif int(tm[3:4]) ==0 and int(tm[0:1]!=0): #if time in am like 13:06:00 then answer should not be zero rather the answer should be 13*60=180 + 6 so this condito would oversee the same
        mn=int((int(tm[0:2])*60)+int(tm[4:5])+int(int(tm[6:8])/60))
     elif int(tm[3:4]) ==0 and int(tm[0:1] ==0): #if time in am like 03:06:00 then answer should not be zero rather the answer should be 3*60=180 + 6 so this condito would oversee the same
        mn=int((int(tm[1:2])*60)+int(tm[4:5])+int(int(tm[6:8])/60))
     else:
        mn=int((int(tm[0:2])*60)+int(tm[3:5])+int(int(tm[6:8])/60))
     return mn
     
def gather_details(mn,day,df,s):
# inputs: minutes(int),day(str)
# ouptut: returns the best simulator type(str)
  tf=[]
  sim=[]
  pl=[]
  for i in range(len(df)):
    if df['DOW'][i] == day:
      if int(df['Time(Entry)'][i])<= int(mn):# This condition should be valid due to the fact that say a person whowants to invest in stocks would require the knowledge of the stocks trading in the earlier times(history of profit/loss for the  stock): same principle followed here
          tf.append(int(df['Total Efficiency'][i]))
          pl.append(int(df['Profit/Loss (C)'][i]))
          sim.append(s)
      else:
        continue
    else:
      continue
  if len(tf)!=0 and len(pl)!=0:
    Mt=sum(tf)
    Mp=sum(pl)
    return Mt,Mp
  else:
    Mt=0
    Mp=0
    return Mt,Mp
    
  
def process_1(Mt,Mp,sim):
  i=Mt.index(max(Mt))
  j=Mp.index(max(Mp))
  return sim[j] # Due to the fact that maximum profit/loss is exhibited by this permutation



def get_dataframe(sim):
# inputs: best simulator type 
# ouptut: returns the best permutaion dataframe based on simulator type 
  fn="/content/GC AT IPS(2)+TM(A) 2016-05_2021 {} Trades.txt".format(sim)
  bp=pd.read_csv(fn,delimiter="\t")
  bp=bp.dropna(how='any')
  bp=bp.reset_index(drop=True)
  #bp['DOW']=pd.to_datetime(bp['Entry DateTime']).dt.day_name()#Type of day of the week
  bp['Entry DateTime'] = pd.to_datetime(bp['Entry DateTime'])
  bp['Time(Entry)']=pd.to_datetime(bp['Entry DateTime']).dt.time
  bp["Entry DateTime"]=bp["Entry DateTime"].dt.strftime("%y-%m-%d")
  bp['Time(Entry)']=bp['Time(Entry)'].astype(str)
  bp['Time(Entry)']=(bp['Time(Entry)'].str.split(':').apply(lambda x: int(x[0]) * 60 + int(x[1]))).astype(int)
  bp=bp.drop(columns=['Symbol','Trade Type','Exit DateTime','Duration','Total Efficiency','Time(Entry)','Max Open Quantity','Max Closed Quantity','Cumulative Profit/Loss (C)','Exit Efficiency','Entry Efficiency','FlatToFlat Profit/Loss (C)','FlatToFlat Max Open Profit (C)','FlatToFlat Max Open Loss (C)','Max Open Profit (C)','Max Open Loss (C)','Note','Commission (C)','Open Position Quantity','Close Position Quantity',])
  bp=bp.rename(columns ={'Entry DateTime':'Date','Entry Price':'Open','Exit Price':'Close','High Price While Open':'High','Low Price While Open':'Low','Trade Quantity':'Volume'}, inplace = False)
  #bp['Total Efficiency'] = list(map(lambda x: x[:-1], bp['Total Efficiency'].values))
  #bp['Total Efficiency'] = [float(x) for x in bp['Total Efficiency'].values]
  #bp['Time(Entry)']=bp['Time(Entry)'].astype(int)
  bp['Profit/Loss (C)'] = list(map(lambda x: x[:-1], bp['Profit/Loss (C)'].values))
  bp['Profit/Loss (C)'] = [float(x) for x in bp['Profit/Loss (C)'].values]
  bp['Open']=bp['Open'].astype(int)
  bp['Close']=bp['Close'].astype(int)
  bp['Volume']=bp['Volume'].astype(int)
  bp['High']=bp['High'].astype(int)
  bp['Low']=bp['Low'].astype(int)
  return bp

def bp_process(bp):
# inputs: best permutation dataframe
# ouptut: returns the best permutaion dataframe with perfect stae format
  for i in range(len(bp)):
    tmp=bp['Date'][i]
    tmp="20"+tmp[0:2]+tmp[2:]
    bp['Date'][i]=tmp
  return bp


def welcome(): #  function to initialize
  print("\n Welcome to Stock Analysis")
  today=datetime.date.today()
  today=today.strftime('%d %m %Y')
  dy=datetime.datetime.strptime(today, '%d %m %Y').weekday()
  d=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']
  day=d[dy]
  print("The day of the week based on the date is {}".format(day))
  f1=['monday','tuesday','wednesday','thursday','friday','sunday','Monday','Tuesday','Wednesday','Thursday','Friday','Sunday','Saturday','saturday']
  if day in f1:
    day=day.capitalize()
    if day =='Sunday' or day == 'sunday':
      tim=datetime.datetime.now().time()
      tim=tim.strftime("%H:%M:%S")
      tmi=tim[0:8]
      if time_valid(tmi):
        print("\n Conversion of the time in 24 hours format (if in pm) hence the time after conversion would {}".format(tim))# converting to 24 hr format for ease of comparision with the primary permutation df
        mn=calc_mins(tmi)
        if mn>1000:
          print("\n Calculation of the time in Minutes based on the above performed conversion hence the time in minutes would be {}".format(mn))# useful for comparing with the entry time denoted in minutes (converted from 24 hr clock format)
          sim=process(mn,day)
          print("\n The best results for the day {} of the week  during time {} of the day is given by {} the permutation (dataset)".format(day,tim,sim))
          bp=get_dataframe(sim)
          bp=bp_process(bp)
          return bp
        else:
          print("\n Data not valid")
      else:
        print("\n Time Format invalid Please try again")
        sys.exit()
    else:
      tim=datetime.datetime.now().time()
      tim=tim.strftime("%H:%M:%S")
      tmi=tim[0:8]
      if time_valid(tmi):
        print("\n Conversion of the time in 24 hours format (if in pm) hence the time after conversion would {}".format(tim))# converting to 24 hr format for ease of comparision with the primary permutation df
        mn=calc_mins(tmi)
        print("\n Calculation of the time in Minutes based on the above performed conversion hence the time in minutes would be {}".format(mn))# useful for comparing with the entry time denoted in minutes (converted from 24 hr clock format)
        sim=process(mn,day)
        if sim==-1:
          print("\n Input Data not valid")
          sys.exit()
        else:
          print("\n The best results for the day {} of the week  during time {} of the day is given by {} the permutation (dataset)".format(day,tim,sim))
          bp=get_dataframe(sim)
          bp=bp_process(bp)
          bp.to_csv(r'Best Permutation file {}.csv'.format(sim), index=False)
          print("\n Local copy of the file is saved")
          return bp
      else:
        print("\n Time Format invalid Please try again")
        sys.exit()
  else:
     print("\n Invalid Format of day Please try again")
     sys.exit()

"""**Kindly execute the code cells Part-1 and Part-2 and Part-3 before executing the below code cell**"""

def main():
  bp=welcome()
  bp=slm_preprocess(bp)
  active_hour(bp)
main()

"""### **Model-3: Trading Analysis based on user input and Super Learner Model(with cross validation score)**

**Part-1**
"""

def CorrectColumnTypes(bp):# Ensure column types are correct
  # Input: dataframe 
  # ouptut: dataframe (with column types changed)

  # Numbers
  for col in bp.columns[1:80]:
      bp[col] = bp[col].astype('float')

  for col in bp.columns[-10:]:
      bp[col] = bp[col].astype('float')

  # Categories 
  for col in bp.columns[80:-10]:
      bp[col] = bp[col].astype('category')
  return bp

def create_lags(df,shifts):
  for i in shifts:
    col_name = 'Close{}'.format(i)
    df[col_name] = df['Close'].shift(periods=-1 * i)
  df = df.dropna()
  return df


def cv_SplitData(df, train_pct): # Splitting the dataframe into train and test
  # inputs: dataframe , training_pct (float between 0 and 1), size of the lag (int)
  # ouptut: x train dataframe, y train data frame, x test dataframe, y test dataframe, train data frame, test dataframe
  train_pt = int(len(df.columns)*train_pct)
  X = df.iloc[:,:train_pt]
  y = df.iloc[:,train_pt:]
  index = df. index
  number_of_rows = len(index)
  shift=number_of_rows//2
  X_train = X.iloc[:shift, :]
  y_train = y.iloc[:shift, :]
  X_test = X.iloc[shift:, :]
  y_test = y.iloc[shift:, :]
  return X_train, y_train, X_test, y_test, X, y

def CreateLags(df,lag_size): # Creating lags for prediction os OOS (Out of Samples)
  # inputs: dataframe , size of the lag (int)
  # ouptut: dataframe ( with extra lag column), shift size (int)
  # add lag
  shiftdays = int(lag_size)
  shft = -shiftdays
  df['Close_lag'] = df['Close'].shift(shft)
  return df, shft

def SplitData(df, train_pct, shift): # Splitting the dataframe into train and test
  # inputs: dataframe , training_pct (float between 0 and 1), size of the lag (int)
  # ouptut: x train dataframe, y train data frame, x test dataframe, y test dataframe, train data frame, test dataframe

  train_pt = int(len(df)*train_pct)
  train = df.iloc[:train_pt,:]
  test = df.iloc[train_pt:,:]
  x_train = train.iloc[:shift,1:-1]
  y_train = train['Close_lag'][:shift]
  x_test = test.iloc[:shift,1:-1]
  y_test = test['Close'][:shift]

  return x_train, y_train, x_test, y_test, train, test

def calc_prof_plot(df,shft,pos,bm,train_pct):
  # inputs: dataframe , list,maximum  number of days position(int), best model(str)
  # ouptut: plot,details on a daily basis based on shft list
  disp(pos,shft)
  sfd=shft.copy()
  tpd=[]
  pa=[]
  if bm=='Linear Regression':
    for j in shft:
      print(str(j) + ' days out:')
      print('------------')
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred =LinearRegression_fnc(x_train,y_train, x_test, y_test)
      test2, profit_dollars, td = CalcProfit(test,lr_pred,j)
      pa.append(profit_dollars)
      tpd.append(td)
      if j<=min(shft):
        PlotModelResults_Plotly(train, test, lr_pred, j, 'Linear Regression',shift)
      else:
        print("\n As a lot of API calls occur this leads to crashing of the colab notebook and hence the graphs for the subsequent days are not displayed  ")
    x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
    PlotModelProfit_Plotly(train, test, pa ,pos,'Linear Regression',shift)
    create_dataframe(test,pa,tpd)


        
  elif bm=='K-Nearest Regression':
    for j in shft:
      print(str(j) + ' days out:')
      print('------------')
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred =KNearestRegression_fnc(x_train,y_train, x_test, y_test)
      test2, profit_dollars,td = CalcProfit(test,lr_pred,j)
      pa.append(profit_dollars)
      tpd.append(td)
      if j<=min(shft):
        PlotModelResults_Plotly(train, test, lr_pred, j, 'K-Nearest Regression',shift)
      else:
        print("As a lot of API calls occur this leads to crashing of the colab notebook and hence the graphs for the subsequent days are not displayed")
    x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
    PlotModelProfit_Plotly(train, test, pa ,pos,'Linear Regression',shift)
    create_dataframe(test,pa,tpd)

  elif bm=='Decision Tree Regression':
      for j in shft:
        print(str(j) + ' days out:')
        print('------------')
        df_lag, shift = CreateLags(df,j)
        df_lag = CorrectColumnTypes(df_lag)
        x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
        lr_pred =DecisionTreeRegression_fnc(x_train,y_train, x_test, y_test)
        test2, profit_dollars,td = CalcProfit(test,lr_pred,j)
        pa.append(profit_dollars)
        tpd.append(td)
        if j<=min(shft):
          PlotModelResults_Plotly(train, test, lr_pred, j, 'Decision Tree Regression',shift)
        else:
          print("As a lot of API calls occur this leads to crashing of the colab notebook and hence the graphs for the subsequent days are not displayed")
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      PlotModelProfit_Plotly(train, test, pa ,pos,'Linear Regression',shift)
      create_dataframe(test,pa,tpd)

  elif bm=='Bagging Regression':
    for j in shifts: 
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred = BaggingRegressor_fnc(x_train,y_train, x_test, y_test)
      test2, profit_dollars,td = CalcProfit(test,lr_pred,j)
      pa.append(profit_dollars)
      tpd.append(td)
      if j<=min(shft):
        PlotModelResults_Plotly(train, test, lr_pred, j, 'Bagging Regression',shift)
      else:
        print("As a lot of API calls occur this leads to crashing of the colab notebook and hence the graphs for the subsequent days are not displayed")
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      PlotModelProfit_Plotly(train, test, pa ,pos,'Linear Regression',shift)
      create_dataframe(test,pa,tpd)

  elif bm=='Extra Tree Regression':
      for j in shft:
          print(str(j) + ' days out:')
          print('------------')
          df_lag, shift = CreateLags(df,j)
          df_lag = CorrectColumnTypes(df_lag)
          x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
          lr_pred =ExtraTreeRegression_fnc(x_train,y_train, x_test, y_test)
          test2, profit_dollars,td = CalcProfit(test,lr_pred,j)
          pa.append(profit_dollars)
          tpd.append(td)
          if j<=min(shft):
            PlotModelResults_Plotly(train, test, lr_pred, j, 'Extra Tree Regression',shift)
          else:
            print("As a lot of API calls occur this leads to crashing of the colab notebook and hence the graphs for the subsequent days are not displayed")
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      PlotModelProfit_Plotly(train, test, pa ,pos,'Linear Regression',shift)
      create_dataframe(test,pa,tpd)
   

def disp(pos,shft): # Displays the valid number of days,months,weeks during the model is considered to be valid

   if pos %7==0 and pos %28!=0:
      print("The model can work for {} weeks".format(pos//7))
   elif pos %28==0 and pos %7!=0:
      print("The model can work for {} months".format(pos//28))
   else:
      print("The model can work for {} days".format(pos))

# Regreesion Functions

def LinearRegression_fnc(x_train,y_train, x_test, y_test):
  #inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the predicted values of the test data (list)
  #print("\n Linear Regression Model")
  lr = LinearRegression()
  lr.fit(x_train,y_train)
  lr_pred = lr.predict(x_test)
  return lr_pred



def LinearRegression_fnc1(df,shifts,train_pct):
    # inputs: x train data, y train data, x test data, y test data (all dataframe's)
    # output: the  list of values for MSE
    print("\n Linear Regression Model")
    LMSE=[]
    df_lag = create_lags(df,shifts)
    df_lag = CorrectColumnTypes(df_lag)
    x_train, y_train, x_test, y_test, train, test = cv_SplitData(df, train_pct)
    lr = LinearRegression()
    tscv = TimeSeriesSplit(n_splits=5)
    scores = cross_val_score(lr, x_train, y_train, cv=tscv, scoring='r2')
    tmp=mean(scores)
    LMSE.append(tmp)
    return LMSE



def KNearestRegression_fnc(x_train,y_train, x_test, y_test):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the predicted values for the test data (list)
  #print("\n K- Nearest Neighbors Regression Model")
  knr = KNeighborsRegressor()
  knr.fit(x_train,y_train)
  knr_pred = knr.predict(x_test)
  return knr_pred

def KNearestRegression_fnc1(df,shifts,train_pct):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the  list of values for MSE
  print("\n K- Nearest Neighbors Regression Model")
  KMSE=[]
  df_lag = create_lags(df,shifts)
  df_lag = CorrectColumnTypes(df_lag)
  x_train, y_train, x_test, y_test, train, test = cv_SplitData(df, train_pct)
  knr = KNeighborsRegressor()
  tscv = TimeSeriesSplit(n_splits=5)
  scores = cross_val_score(knr, x_train, y_train, cv=tscv, scoring='r2')
  tmp=mean(scores)
  KMSE.append(tmp)
  return KMSE



def DecisionTreeRegression_fnc(x_train,y_train, x_test, y_test):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the predicted values for the test data (list)
  #print("\n Decision Tree Regression Model")
  dtr = DecisionTreeRegressor()
  dtr.fit(x_train,y_train)
  dtr_pred = dtr.predict(x_test)
  return dtr_pred

def DecisionTreeRegression_fnc1(df,shifts,train_pct):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the  list of values for MSE
    print("\n Decision Tree Regression Model")
    DMSE=[] 
    df_lag = create_lags(df,shifts)
    df_lag = CorrectColumnTypes(df_lag)
    x_train, y_train, x_test, y_test, train, test = cv_SplitData(df, train_pct)
    dtr = DecisionTreeRegressor()
    tscv = TimeSeriesSplit(n_splits=5)
    scores = cross_val_score(dtr, x_train, y_train, cv=tscv, scoring='r2')
    tmp=mean(scores)
    DMSE.append(tmp)
    return DMSE

def BaggingRegressor_fnc(x_train,y_train, x_test, y_test):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the predicted values for the test data (list)
  #print("\n Bagging Regression Model")
  br = BaggingRegressor()
  br.fit(x_train,y_train)
  br_pred = br.predict(x_test)
  return br_pred

def BaggingRegressor_fnc1(df,shifts,train_pct):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the  list of values for MSE
  print("\n Bagging Regression Model")
  BMSE=[]
  df_lag = create_lags(df,shifts)
  df_lag = CorrectColumnTypes(df_lag)
  x_train, y_train, x_test, y_test, train, test = cv_SplitData(df, train_pct)
  br = BaggingRegressor()
  tscv = TimeSeriesSplit(n_splits=5)
  scores = cross_val_score(br, x_train, y_train, cv=tscv, scoring='r2')
  tmp=mean(scores)
  BMSE.append(tmp)
  return BMSE


def ExtraTreesRegressor_fnc(x_train,y_train, x_test, y_test):
  #inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the predicted values for the test data (list)
  #print("\n Extra Trees Regression Model")
  etr = RandomForestRegressor()
  etr.fit(x_train,y_train)
  etr_pred = etr.predict(x_test)
  return etr_pred


def ExtraTreesRegressor_fnc1(df,shifts,train_pct):
  #inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the  list of values for MSE
  print("\n Extra Trees Regression Model")
  EMSE=[]
  df_lag = create_lags(df,shifts)
  df_lag = CorrectColumnTypes(df_lag)
  x_train, y_train, x_test, y_test, train, test = cv_SplitData(df, train_pct)
  etr = RandomForestRegressor()
  tscv = TimeSeriesSplit(n_splits=5)
  scores = cross_val_score(etr, x_train, y_train, cv=tscv, scoring='r2')
  tmp=mean(scores)
  EMSE.append(tmp)
  return EMSE


def Calctradingdays(test_df,pred,j):# Calculates number of good trading days based on the model prediction
  # inputs: dataframe,predicted values, day
  # output: the number of good trading days
  pd.set_option('mode.chained_assignment', None)
  test_df['pred'] = np.nan
  test_df['pred'].iloc[:-j] = pred
  test_df['change'] = test_df['Close_lag'] - test_df['Close'] 
  test_df['change_pred'] = test_df['pred'] - test_df['Close'] 
  test_df['MadeMoney'] = np.where(test_df['change_pred']/test_df['change'] > 0, 1, -1) 
  test_df['profit'] = np.abs(test_df['change']) * test_df['MadeMoney']
  profit_dollars = test_df['profit'].sum()
  profit_days = len(test_df[test_df['MadeMoney'] == 1])
  tdays=round(profit_days/(len(test_df)-j),2)
  return tdays



def CalcProfit(test_df,pred,j): # Function to calculate aggregrate profit/loss made in the days
  # inputs: dataframe,predicted values, day
  # output: the aggregated profit/loss made in the predicted days(j)
  pd.set_option('mode.chained_assignment', None)
  test_df['pred'] = np.nan
  test_df['pred'].iloc[:-j] = pred
  test_df['change'] = test_df['Close_lag'] - test_df['Close'] 
  test_df['change_pred'] = test_df['pred'] - test_df['Close'] 
  test_df['MadeMoney'] = np.where(test_df['change_pred']/test_df['change'] > 0, 1, -1) 
  test_df['profit'] = np.abs(test_df['change']) * test_df['MadeMoney']
  profit_dollars = test_df['profit'].sum()
  pad=str(round(profit_dollars,1))
  print("\n Aggregated Profit/Loss Results")
  if pad[0]=='-':
      print('Loss: $ ' + str(round(profit_dollars,1)))
  else:
      print('Profit: $ ' + str(round(profit_dollars,1)))
  profit_days = len(test_df[test_df['MadeMoney'] == 1])
  td = str(round(profit_days/(len(test_df)-j),2)*100) 
  print('Percentage of good trading days: ' + str( round(profit_days/(len(test_df)-j),2)*100) )

  return test_df, profit_dollars,td
 

def disp_results(sfd,pa,tpd): # Displays important details after the graphs 
 # inputs: sfd(list), profit_dollars(list), goodtrade days(list)
 # output: None
  for i in range(len(sfd)):
    for j in range(len(pa)):
      for k in range(len(tpd)):
        if i==j and i==k and j==k :
          print("\n For Day {0} the aggregated profit/loss would be {1} and the estimated percentage of good trading days would be {2}".format(sfd[i],pa[j],tpd[k]))
        else:
          continue
  
def PlotModelProfit_Plotly(train, test, pred,shift_days,name,shift):  # Function to make the plots    
  # inputs: train dataframe, test dataframe, predicted value (list), shift size (int), name (string)
  # output: Graph
  w = 25 # width
  h = 25 # height
  # Create lines of the training actual, testing actual, prediction 
  D1 = go.Scatter(x=train.index,y=train['Profit/Loss (C)'],name = 'Actual Profit/Loss based on  Train data') # Training actuals
  D2 = go.Scatter(x=test.index[:shift],y=test['Profit/Loss (C)'],name = 'Actual Profit/Loss based on  Train data') # Testing actuals
  D3 = go.Scatter(x=test.index[:shift],y=pred,name = 'Predicted Profit/Loss from model') # Testing predction
  tickerSymbol="[Sim]F.US.GCEQ21"
  # Combine in an object  
  line = {'data': [D1,D2,D3],
          'layout': {
              'xaxis' :{'title': 'Date'},
              'yaxis' :{'title': 'Agregate Profit/Loss'},
              'title' : name + ' - ' + tickerSymbol + ' - ' + str(shift_days)
          }}
  # Send object to a figure 
  fig = go.Figure(line)

  # Show figure
  fig.show()

def create_dataframe(test,pa,tpd):
 # a=list(train['Profit/Loss (C)'])
  b=list(test['Profit/Loss (C)'])
  lst=zip(b,pa,tpd)
  df = pd.DataFrame(list(lst),columns =['Actual Profit/Loss for Train','Predicted Profit/Loss from model','Percenatge of good trading Days'])
  display(df)

def PlotModelResults_Plotly(train, test, pred,shift_days,name,shift):  # Function to make the plots    
  # inputs: train dataframe, test dataframe, predicted value (list), shift size (int), name (string)
  # output: Graph
  w = 25 # width
  h = 25 # height
  # Create lines of the training actual, testing actual, prediction 
  D1 = go.Scatter(x=train.index,y=train['Close'],name = 'Train Actual') # Training actuals
  D2 = go.Scatter(x=test.index[:shift],y=test['Close'],name = 'Test Actual') # Testing actuals
  D3 = go.Scatter(x=test.index[:shift],y=pred,name = 'Model Prediction') # Testing predction
  tickerSymbol="[Sim]F.US.GCEQ21"
  # Combine in an object  
  line = {'data': [D1,D2,D3],
          'layout': {
              'xaxis' :{'title': 'Date'},
              'yaxis' :{'title': 'Money'},
              'title' : name + ' - ' + tickerSymbol + ' - ' + str(shift_days)
          }}
  # Send object to a figure 
  fig = go.Figure(line)

  # Show figure
  fig.show()

def best_model(df,shifts,train_pct,bm):
  # inputs: train dataframe, list,train percenatge(float), best model name(str)
  # output: Number of good trading days calculated by the prediction made by the best model
  td=[]
  if bm=='Linear Regression':
    for j in shifts: 
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred = LinearRegression_fnc(x_train,y_train, x_test, y_test)
      temp=Calctradingdays(test,lr_pred,j)
      td.append(temp)
  elif bm=='K-Nearest Regression':
    for j in shifts: 
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred =KNearestRegression_fnc(x_train,y_train, x_test, y_test)
      temp=Calctradingdays(test,lr_pred,j)
      td.append(temp)
  elif bm=='Decision Tree Regression':
    for j in shifts: 
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred = DecisionTreeRegression_fnc(x_train,y_train, x_test, y_test)
      temp=Calctradingdays(test,lr_pred,j)
      td.append(temp)

  elif bm=='Bagging Regression':
    for j in shifts: 
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred = BaggingRegressor_fnc(x_train,y_train, x_test, y_test)
      temp=Calctradingdays(test,lr_pred,j)
      td.append(temp)

  elif bm=='Extra Tree Regression':
      for j in shifts: 
        df_lag, shift = CreateLags(df,j)
        df_lag = CorrectColumnTypes(df_lag)
        x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
        lr_pred = ExtraTreesRegressor_fnc(x_train,y_train, x_test, y_test)
        temp=Calctradingdays(test,lr_pred,j)
        td.append(temp)
  return shifts[td.index(max(td))]


def models_log(df,shifts,train_pct):
  # inputs: train dataframe, list,train percenatge(float)
  # output: The best model name which could be used for further evaluation 
  LMSE=[]
  KMSE=[]
  BMSE=[]
  DMSE=[]
  RMSE=[]
  EMSE=[]
  ovr=[]
  # Linear Regression
  LMSE = LinearRegression_fnc1(df,shifts,train_pct)
  # K-Neareast Neighbors
  KMSE =KNearestRegression_fnc1(df,shifts,train_pct)
  # DecisionTree Regression
  DMSE = DecisionTreeRegression_fnc1(df,shifts,train_pct)
  # Bagging Regression
  # BMSE = BaggingRegressor_fnc1(df,shifts,train_pct)
  # ExtraTrees Regression
  # EMSE=ExtraTreesRegressor_fnc1(df,shifts,train_pct)
  # Chossing the Best Model
  n=3# Number of Models Active
  bom=['Linear Regression','K-Nearest Regression','Decision Tree Regression','Bagging Regression','Extra Tree Regression']
  LR=int(sum(LMSE)/36500)
  KNR=int(sum(KMSE)/36500)
  DTR=int(sum(DMSE)/36500)
  #BR=int(sum(BMSE)/36500)
  EFR=int(sum(EMSE)/36500)
  print(" Mean R2 score after cross validation for Linear Regression for the entire list is {}".format(LR))
  print(" Mean R2 score after cross validation for K-Nearest Neighbors Regression for the entire list is {}".format(KNR))
  print(" Mean R2 score after cross validation for Decision Tree Regression for the entire list is {}".format(DTR))
  ovr.append(LR)
  ovr.append(KNR)
  ovr.append(DTR)
  #ovr.append(BR)
  #ovr.append(EFR)
  idx=minimum(ovr)
  return bom[idx]

def minimum(ovr):
  current_min = ovr[0]  
  for num in ovr:       
    if num < current_min:
      current_min = num  
  return ovr.index(current_min)

def process_2(pos,shft): # Creates a new list till the maximum limit
 # inputs: position of the maximum number of day for which the model is valid (int),list of days
 # output: Creates a new list containing the number of days for which the model remains valid
  shift=[]
  ele=pos+1
  for k in range(1,ele,1):
    shift.append(k)
  return shift

def logic(bp):
 # inputs: the dataframe of the best permutation
 # output: None
  print("\n welcome to model selection and prediction algorithm")
  shft=[] # Store number of days with a max limit of one year including multiples of seven which makes n week ,and also multiple of 28 which on the whole makes n month as( 4 weeks{4*7} make a month)
  for i in range(1,366): # Max limit for the number of days could be  based on the number of years so for time being i have enclosed the same as one year as 1year=365 days
    shft.append(i)
  train_pct =75
  train_pct=train_pct/100;
  print("\n Columns Format checking initialised")
  bp=CorrectColumnTypes(bp)
  bp1=bp.copy()
  print("\n Columns Format checking performed succesfully")
  bm=models_log(bp,shft,train_pct)
  print("\n The best Model for the given dataset after evaluation is {}".format(bm))
  pos=best_model(bp1,shft,train_pct,bm)
  print("The model {0} is valid for {1} days".format(bm,pos))
  sft=process_2(pos,shft)
  print(sft)
  calc_prof_plot(bp1,sft,pos,bm,train_pct)

def active_hour(bp):# Recursively activates the algorithm on an hourly basis
 # inputs: the dataframe of the best permutation
 # output: None
  from datetime import datetime, timedelta
  while 1:
    print("\n Initialising the Model Prediction Algorithm")
    logic(bp)

    dt = datetime.now() + timedelta(hours=1)
    dt = dt.replace(minute=59) # Recursively runs the code at the start of every hour

    while datetime.now() < dt:
        time.sleep(1)

"""**Part-2**"""

def slm_preprocess(bp):# processing the inputs for initialsing Stage-2
  #df=df.drop(["Date",	"Entry Price",	"Exit Price",	"Trade Quantity",	"Profit/Loss (C)",	"Duration",	"High Price While Open"	,"Low Price While Open",	"Total Efficiency","SIM","Day","Month","year",	"Time(Entry)"	,"DOW"], axis = 1, inplace = True)
  print("\n The unprocessed dataframe would be")
  display(bp)
  bp=bp.set_index('Date')
  bp = bp.reindex(['Open','High','Low','Close','Volume','Profit/Loss (C)'], axis=1)
  date_change = '%Y-%m-%d'
  bp['Date'] = bp.index
  bp['Date'] = pd.to_datetime(bp['Date'], format = date_change)
  Dates = bp['Date']
  bp = add_all_ta_features(bp, "Open", "High", "Low", "Close", "Volume", fillna=True) 
  #print(bp.columns)
  date_change = '%Y-%m-%d'
  # Define the date parts 
  fastai.tabular.add_datepart(bp,'Date', drop = 'True')
  # Ensure the correct format
  bp['Date'] = pd.to_datetime(bp.index.values, format = date_change)
  # Add the date parts
  fastai.tabular.add_cyclic_datepart(bp, 'Date', drop = 'True')
  print("\n The processed dataframe would be")
  display(bp)
  return bp

"""**Part-3**"""

def data_preprocess(df1,sim):
  df1['SIM']=str(sim)
  df1=df1.dropna(how='any')
  df1['Entry DateTime'] = pd.to_datetime(df1['Entry DateTime'])
  df1['Exit DateTime'] = pd.to_datetime(df1['Exit DateTime'])
  #df1['Day']=pd.to_datetime(df1['Entry DateTime']).dt.day
  #df1['Month']=pd.to_datetime(df1['Entry DateTime']).dt.month
  #df1['year']=pd.to_datetime(df1['Entry DateTime']).dt.year
  df1['Time(Entry)']=pd.to_datetime(df1['Entry DateTime']).dt.time
  #df['Time(Exit)']=pd.to_datetime(df['Exit DateTime']).dt.time
  df1['DOW']=pd.to_datetime(df1['Entry DateTime']).dt.day_name()#Type of day of the week
  df1["Entry DateTime"]=df1["Entry DateTime"].dt.strftime("%y-%m-%d")
  df1['Time(Entry)']=df1['Time(Entry)'].astype(str)
  df1['Time(Entry)']=(df1['Time(Entry)'].str.split(':').apply(lambda x: int(x[0]) * 60 + int(x[1]))).astype(int)
  df1['Duration']=df1['Duration'].astype(str)
  df1['Duration']=(df1['Duration'].str.split(':').apply(lambda x: int(x[0]) * 60 + int(x[1]))).astype(int)
  df1=df1.drop(columns=['Symbol','Trade Type','Exit DateTime','Max Open Quantity','Max Closed Quantity','Cumulative Profit/Loss (C)','Exit Efficiency','Entry Efficiency','FlatToFlat Profit/Loss (C)','FlatToFlat Max Open Profit (C)','FlatToFlat Max Open Loss (C)','Max Open Profit (C)','Max Open Loss (C)','Note','Commission (C)','Open Position Quantity','Close Position Quantity',])
  df1=df1.rename(columns ={'Entry DateTime':'Date',}, inplace = False)
  df1['Total Efficiency'] = list(map(lambda x: x[:-1], df1['Total Efficiency'].values))
  df1['Total Efficiency'] = [float(x) for x in df1['Total Efficiency'].values]
  df1['Profit/Loss (C)'] = list(map(lambda x: x[:-1], df1['Profit/Loss (C)'].values))
  df1['Profit/Loss (C)'] = [float(x) for x in df1['Profit/Loss (C)'].values]
  df1['Time(Entry)']=df1['Time(Entry)'].astype(int)
  return df1
  
def process(mn,day):  
   sim=['sim100','sim101','sim102','sim103','sim110','sim111','sim112','sim113','sim120','sim121','sim122','sim123','sim130','sim131','sim132','sim133']  
   dg=[]
   loc=['/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim100 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim101 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim102 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim103 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim110 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim111 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim112 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim113 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim120 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim121 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim122 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim123 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim130 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim131 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim132 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim133 Trades.txt'] 
   for i in range(len(loc)):
     for j in range(len(sim)):
       if i==j:
         t= 'df' + '{}'.format(i)
         t=pd.read_csv('{}'.format(loc[i]),delimiter="\t")
         dg.append(t)
       else:
          continue
   print("\n The total number of permutations files is {}".format(len(dg)))
   df1=data_preprocess(dg[0],sim[0])
   df2=data_preprocess(dg[1],sim[1])
   df3=data_preprocess(dg[2],sim[2])
   df4=data_preprocess(dg[3],sim[3])
   df5=data_preprocess(dg[4],sim[4])
   df6=data_preprocess(dg[5],sim[5])
   df7=data_preprocess(dg[6],sim[6])
   df8=data_preprocess(dg[7],sim[7])
   df9=data_preprocess(dg[8],sim[8])
   df10=data_preprocess(dg[9],sim[9])
   df11=data_preprocess(dg[10],sim[10])
   df12=data_preprocess(dg[11],sim[11])
   df13=data_preprocess(dg[12],sim[12])
   df14=data_preprocess(dg[13],sim[13])
   df15=data_preprocess(dg[14],sim[14])
   df16=data_preprocess(dg[15],sim[15])
   pnl=[]
   te=[]
   fg=[df1,df2,df3,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16]
   for i in range(len(sim)):
    for j in range(len(fg)):
      if i==j:
        l,k=gather_details(mn,day,fg[j],sim[i])
        te.append(int(l))
        pnl.append(int(k))
      else:
        continue
   #print("\n" ,pnl)
   #print("\n" ,te)
   sm=process_1(te,pnl,sim)
   return sm
   #return df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16





def time_valid(tim): # Function to check validity of time
# inputs: time(str)
# ouptut: boolean value
  try:
      time.strptime(tim, '%H:%M:%S')
      return True
  except ValueError:
        return False

def hour_format(str1): # Function to convert the given time in 24 hr clock based on am or pm format
# inputs: time with am/pm (str)
# ouptut: time in 24hr clock
     if (str1[-2:] == "AM" or str1[-2:] == "Am" or str1[-2:] == "aM" or str1[-2:] == 'am') and str1[:2] == "12":
         return "00" + str1[2:-2]
     elif (str1[-2:] == "AM" or str1[-2:] == "Am" or str1[-2:] == "aM" or str1[-2:] == 'am') :
         return str1[:-2]
     elif (str1[-2:] == "PM" or str1[-2:] == "Pm" or str1[-2:] == "pM" or str1[-2:] == 'pm') and str1[:2] == "12":
         return str1[:-2]
     else:
      return str(int(str1[:2]) + 12) + str1[2:8]

def calc_mins(tm):#Function to convert hrs ,mins,secs into minutes
# inputs: time in Hours,minutes,seconds
# ouptut: returns time in minutes

     if int(tm[0:1]) ==0 and int(tm[3:4])!=0 : #if time in am like 03:00:00 then answer should not be zero rather the answer should be 3*60=180 so this condito would oversee the same
        mn=int((int(tm[1:2])*60)+int(tm[3:5])+int(int(tm[6:8])/60))
     elif int(tm[3:4]) ==0 and int(tm[0:1]!=0): #if time in am like 13:06:00 then answer should not be zero rather the answer should be 13*60=180 + 6 so this condito would oversee the same
        mn=int((int(tm[0:2])*60)+int(tm[4:5])+int(int(tm[6:8])/60))
     elif int(tm[3:4]) ==0 and int(tm[0:1] ==0): #if time in am like 03:06:00 then answer should not be zero rather the answer should be 3*60=180 + 6 so this condito would oversee the same
        mn=int((int(tm[1:2])*60)+int(tm[4:5])+int(int(tm[6:8])/60))
     else:
        mn=int((int(tm[0:2])*60)+int(tm[3:5])+int(int(tm[6:8])/60))
     return mn

def gather_details(mn,day,df,s):
# inputs: minutes(int),day(str)
# ouptut: returns the best simulator type(str)
  tf=[]
  sim=[]
  pl=[]
  for i in range(len(df)):
    if df['DOW'][i] == day:
      if int(df['Time(Entry)'][i])<= int(mn):# This condition should be valid due to the fact that say a person whowants to invest in stocks would require the knowledge of the stocks trading in the earlier times(history of profit/loss for the  stock): same principle followed here
          tf.append(int(df['Total Efficiency'][i]))
          pl.append(int(df['Profit/Loss (C)'][i]))
          sim.append(s)
      else:
        continue
    else:
      continue
  if len(tf)!=0 and len(pl)!=0:
    Mt=sum(tf)
    Mp=sum(pl)
    return Mt,Mp
  else:
    Mt=0
    Mp=0
    return Mt,Mp
    
  
def process_1(Mt,Mp,sim):
  i=Mt.index(max(Mt))
  j=Mp.index(max(Mp))
  return sim[j] # Due to the fact that maximum profit/loss is exhibited by this permutation


def get_dataframe(sim):
# inputs: best simulator type 
# ouptut: returns the best permutaion dataframe based on simulator type 
  fn="/content/GC AT IPS(2)+TM(A) 2016-05_2021 {} Trades.txt".format(sim)
  bp=pd.read_csv(fn,delimiter="\t")
  bp=bp.dropna(how='any')
  bp=bp.reset_index(drop=True)
  #bp['DOW']=pd.to_datetime(bp['Entry DateTime']).dt.day_name()#Type of day of the week
  bp['Entry DateTime'] = pd.to_datetime(bp['Entry DateTime'])
  bp['Time(Entry)']=pd.to_datetime(bp['Entry DateTime']).dt.time
  bp["Entry DateTime"]=bp["Entry DateTime"].dt.strftime("%y-%m-%d")
  bp['Time(Entry)']=bp['Time(Entry)'].astype(str)
  bp['Time(Entry)']=(bp['Time(Entry)'].str.split(':').apply(lambda x: int(x[0]) * 60 + int(x[1]))).astype(int)
  bp=bp.drop(columns=['Symbol','Trade Type','Exit DateTime','Duration','Total Efficiency','Time(Entry)','Max Open Quantity','Max Closed Quantity','Cumulative Profit/Loss (C)','Exit Efficiency','Entry Efficiency','FlatToFlat Profit/Loss (C)','FlatToFlat Max Open Profit (C)','FlatToFlat Max Open Loss (C)','Max Open Profit (C)','Max Open Loss (C)','Note','Commission (C)','Open Position Quantity','Close Position Quantity',])
  bp=bp.rename(columns ={'Entry DateTime':'Date','Entry Price':'Open','Exit Price':'Close','High Price While Open':'High','Low Price While Open':'Low','Trade Quantity':'Volume'}, inplace = False)
  #bp['Total Efficiency'] = list(map(lambda x: x[:-1], bp['Total Efficiency'].values))
  #bp['Total Efficiency'] = [float(x) for x in bp['Total Efficiency'].values]
  #bp['Time(Entry)']=bp['Time(Entry)'].astype(int)
  bp['Profit/Loss (C)'] = list(map(lambda x: x[:-1], bp['Profit/Loss (C)'].values))
  bp['Profit/Loss (C)'] = [float(x) for x in bp['Profit/Loss (C)'].values]
  bp['Open']=bp['Open'].astype(int)
  bp['Close']=bp['Close'].astype(int)
  bp['Volume']=bp['Volume'].astype(int)
  bp['High']=bp['High'].astype(int)
  bp['Low']=bp['Low'].astype(int)
  return bp

def bp_process(bp):
# inputs: best permutation dataframe
# ouptut: returns the best permutaion dataframe with perfect stae format
  for i in range(len(bp)):
    tmp=bp['Date'][i]
    tmp="20"+tmp[0:2]+tmp[2:]
    bp['Date'][i]=tmp
  return bp


def welcome(): #  function to initialize
  print("\n Welcome to Stock Analysis")
  print("\n Kindly enter the details with care below")
  day=input("\n Enter the day of the week")
  f1=['monday','tuesday','wednesday','thursday','friday','sunday','Monday','Tuesday','Wednesday','Thursday','Friday','Sunday','Saturday','saturday']
  if day in f1:
    day=day.capitalize()
    if day =='Sunday' or day == 'sunday':
      tim=input("\n Enter the time  in the format (hrs:min:sec) followed by am/pm after a space")# Enter time in normal method like 01:00:00 am or 02:50:00pm and not in 24 hr clock format
      tmi=tim[0:8]
      if time_valid(tmi):
        tm=hour_format(tim)
        print("\n Conversion of the time in 24 hours format (if in pm) hence the time after conversion would {}".format(tm[0:8]))# converting to 24 hr format for ease of comparision with the primary permutation df
        mn=calc_mins(tm)
        if mn>1000:
          print("\n Calculation of the time in Minutes based on the above performed conversion hence the time in minutes would be {}".format(mn))# useful for comparing with the entry time denoted in minutes (converted from 24 hr clock format)
          sim=process(mn,day)
          print("\n The best results for the day {} of the week  during time {} of the day is given by {} the permutation (dataset)".format(day,tim,sim))
          bp=get_dataframe(sim)
          bp=bp_process(bp)
          return bp
        else:
          print("\n Data not valid")
          sys.exit()
      else:
        print("\n Time Format invalid Please try again")
        sys.exit()
    else:
      tim=input("\n Enter the time  in the format (hrs:min:sec) followed by a space, followed by am/pm")# Enter time in normal method like 01:00:00 am or 02:50:00pm and not in 24 hr clock format
      tmi=tim[0:8]
      if time_valid(tmi):
        tm=hour_format(tim)
        print("\n Conversion of the time in 24 hours format (if in pm) hence the time after conversion would {}".format(tm[0:8]))# converting to 24 hr format for ease of comparision with the primary permutation df
        mn=calc_mins(tm)
        print("\n Calculation of the time in Minutes based on the above performed conversion hence the time in minutes would be {}".format(mn))# useful for comparing with the entry time denoted in minutes (converted from 24 hr clock format)
        sim=process(mn,day)
        if sim==-1:
          print("\n Input Data not valid")
          sys.exit()
        else:
          print("\n The best results for the day {} of the week  during time {} of the day is given by {} the permutation (dataset)".format(day,tim,sim))
          bp=get_dataframe(sim)
          bp=bp_process(bp)
          bp.to_csv(r'Best Permutation file {}.csv'.format(sim), index=False)
          print("\n Local copy of the file is saved")
          return bp
      else:
        print("\n Time Format invalid Please try again")
        sys.exit()
  else:
     print("\n Invalid Format of day Please try again")
     sys.exit()

"""**Kindly execute the code cells Part-1 and Part-2 and Part-3 before executing the below code cell**"""

def main():
  bp=welcome()
  bp=slm_preprocess(bp)
  active_hour(bp)
main()

"""### **Model-4:Trading Analysis based on automated input and Super Learner model with cross validation score**

**Part-1**
"""

def CorrectColumnTypes(bp):# Ensure column types are correct
  # Input: dataframe 
  # ouptut: dataframe (with column types changed)

  # Numbers
  for col in bp.columns[1:80]:
      bp[col] = bp[col].astype('float')

  for col in bp.columns[-10:]:
      bp[col] = bp[col].astype('float')

  # Categories 
  for col in bp.columns[80:-10]:
      bp[col] = bp[col].astype('category')
  return bp

def create_lags(df,shifts):
  for i in shifts:
    col_name = 'Close{}'.format(i)
    df[col_name] = df['Close'].shift(periods=-1 * i)
  df = df.dropna()
  return df


def cv_SplitData(df, train_pct): # Splitting the dataframe into train and test
  # inputs: dataframe , training_pct (float between 0 and 1), size of the lag (int)
  # ouptut: x train dataframe, y train data frame, x test dataframe, y test dataframe, train data frame, test dataframe
  train_pt = int(len(df.columns)*train_pct)
  X = df.iloc[:,:train_pt]
  y = df.iloc[:,train_pt:]
  index = df. index
  number_of_rows = len(index)
  shift=number_of_rows//2
  X_train = X.iloc[:shift, :]
  y_train = y.iloc[:shift, :]
  X_test = X.iloc[shift:, :]
  y_test = y.iloc[shift:, :]
  return X_train, y_train, X_test, y_test, X, y

def CreateLags(df,lag_size): # Creating lags for prediction os OOS (Out of Samples)
  # inputs: dataframe , size of the lag (int)
  # ouptut: dataframe ( with extra lag column), shift size (int)
  # add lag
  shiftdays = int(lag_size)
  shft = -shiftdays
  df['Close_lag'] = df['Close'].shift(shft)
  return df, shft

def SplitData(df, train_pct, shift): # Splitting the dataframe into train and test
  # inputs: dataframe , training_pct (float between 0 and 1), size of the lag (int)
  # ouptut: x train dataframe, y train data frame, x test dataframe, y test dataframe, train data frame, test dataframe

  train_pt = int(len(df)*train_pct)
  train = df.iloc[:train_pt,:]
  test = df.iloc[train_pt:,:]
  x_train = train.iloc[:shift,1:-1]
  y_train = train['Close_lag'][:shift]
  x_test = test.iloc[:shift,1:-1]
  y_test = test['Close'][:shift]

  return x_train, y_train, x_test, y_test, train, test

def calc_prof_plot(df,shft,pos,bm,train_pct):
  # inputs: dataframe , list,maximum  number of days position(int), best model(str)
  # ouptut: plot,details on a daily basis based on shft list
  disp(pos,shft)
  sfd=shft.copy()
  tpd=[]
  pa=[]
  if bm=='Linear Regression':
    for j in shft:
      print(str(j) + ' days out:')
      print('------------')
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred =LinearRegression_fnc(x_train,y_train, x_test, y_test)
      test2, profit_dollars, td = CalcProfit(test,lr_pred,j)
      pa.append(profit_dollars)
      tpd.append(td)
      if j<=min(shft):
        PlotModelResults_Plotly(train, test, lr_pred, j, 'Linear Regression',shift)
      else:
        print("\n As a lot of API calls occur this leads to crashing of the colab notebook and hence the graphs for the subsequent days are not displayed  ")
    x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
    PlotModelProfit_Plotly(train, test, pa ,pos,'Linear Regression',shift)
    create_dataframe(test,pa,tpd)


        
  elif bm=='K-Nearest Regression':
    for j in shft:
      print(str(j) + ' days out:')
      print('------------')
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred =KNearestRegression_fnc(x_train,y_train, x_test, y_test)
      test2, profit_dollars,td = CalcProfit(test,lr_pred,j)
      pa.append(profit_dollars)
      tpd.append(td)
      if j<=min(shft):
        PlotModelResults_Plotly(train, test, lr_pred, j, 'K-Nearest Regression',shift)
      else:
        print("As a lot of API calls occur this leads to crashing of the colab notebook and hence the graphs for the subsequent days are not displayed")
    x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
    PlotModelProfit_Plotly(train, test, pa ,pos,'Linear Regression',shift)
    create_dataframe(test,pa,tpd)

  elif bm=='Decision Tree Regression':
      for j in shft:
        print(str(j) + ' days out:')
        print('------------')
        df_lag, shift = CreateLags(df,j)
        df_lag = CorrectColumnTypes(df_lag)
        x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
        lr_pred =DecisionTreeRegression_fnc(x_train,y_train, x_test, y_test)
        test2, profit_dollars,td = CalcProfit(test,lr_pred,j)
        pa.append(profit_dollars)
        tpd.append(td)
        if j<=min(shft):
          PlotModelResults_Plotly(train, test, lr_pred, j, 'Decision Tree Regression',shift)
        else:
          print("As a lot of API calls occur this leads to crashing of the colab notebook and hence the graphs for the subsequent days are not displayed")
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      PlotModelProfit_Plotly(train, test, pa ,pos,'Linear Regression',shift)
      create_dataframe(test,pa,tpd)

  elif bm=='Bagging Regression':
    for j in shifts: 
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred = BaggingRegressor_fnc(x_train,y_train, x_test, y_test)
      test2, profit_dollars,td = CalcProfit(test,lr_pred,j)
      pa.append(profit_dollars)
      tpd.append(td)
      if j<=min(shft):
        PlotModelResults_Plotly(train, test, lr_pred, j, 'Bagging Regression',shift)
      else:
        print("As a lot of API calls occur this leads to crashing of the colab notebook and hence the graphs for the subsequent days are not displayed")
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      PlotModelProfit_Plotly(train, test, pa ,pos,'Linear Regression',shift)
      create_dataframe(test,pa,tpd)

  elif bm=='Extra Tree Regression':
      for j in shft:
          print(str(j) + ' days out:')
          print('------------')
          df_lag, shift = CreateLags(df,j)
          df_lag = CorrectColumnTypes(df_lag)
          x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
          lr_pred =ExtraTreeRegression_fnc(x_train,y_train, x_test, y_test)
          test2, profit_dollars,td = CalcProfit(test,lr_pred,j)
          pa.append(profit_dollars)
          tpd.append(td)
          if j<=min(shft):
            PlotModelResults_Plotly(train, test, lr_pred, j, 'Extra Tree Regression',shift)
          else:
            print("As a lot of API calls occur this leads to crashing of the colab notebook and hence the graphs for the subsequent days are not displayed")
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      PlotModelProfit_Plotly(train, test, pa ,pos,'Linear Regression',shift)
      create_dataframe(test,pa,tpd)
   

def disp(pos,shft): # Displays the valid number of days,months,weeks during the model is considered to be valid

   if pos %7==0 and pos %28!=0:
      print("The model can work for {} weeks".format(pos//7))
   elif pos %28==0 and pos %7!=0:
      print("The model can work for {} months".format(pos//28))
   else:
      print("The model can work for {} days".format(pos))

# Regreesion Functions

def LinearRegression_fnc(x_train,y_train, x_test, y_test):
  #inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the predicted values of the test data (list)
  #print("\n Linear Regression Model")
  lr = LinearRegression()
  lr.fit(x_train,y_train)
  lr_pred = lr.predict(x_test)
  return lr_pred



def LinearRegression_fnc1(df,shifts,train_pct):
    # inputs: x train data, y train data, x test data, y test data (all dataframe's)
    # output: the  list of values for MSE
    print("\n Linear Regression Model")
    LMSE=[]
    df_lag = create_lags(df,shifts)
    df_lag = CorrectColumnTypes(df_lag)
    x_train, y_train, x_test, y_test, train, test = cv_SplitData(df, train_pct)
    lr = LinearRegression()
    tscv = TimeSeriesSplit(n_splits=5)
    scores = cross_val_score(lr, x_train, y_train, cv=tscv, scoring='r2')
    tmp=mean(scores)
    LMSE.append(tmp)
    return LMSE



def KNearestRegression_fnc(x_train,y_train, x_test, y_test):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the predicted values for the test data (list)
  #print("\n K- Nearest Neighbors Regression Model")
  knr = KNeighborsRegressor()
  knr.fit(x_train,y_train)
  knr_pred = knr.predict(x_test)
  return knr_pred

def KNearestRegression_fnc1(df,shifts,train_pct):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the  list of values for MSE
  print("\n K- Nearest Neighbors Regression Model")
  KMSE=[]
  df_lag = create_lags(df,shifts)
  df_lag = CorrectColumnTypes(df_lag)
  x_train, y_train, x_test, y_test, train, test = cv_SplitData(df, train_pct)
  knr = KNeighborsRegressor()
  tscv = TimeSeriesSplit(n_splits=5)
  scores = cross_val_score(knr, x_train, y_train, cv=tscv, scoring='r2')
  tmp=mean(scores)
  KMSE.append(tmp)
  return KMSE



def DecisionTreeRegression_fnc(x_train,y_train, x_test, y_test):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the predicted values for the test data (list)
  #print("\n Decision Tree Regression Model")
  dtr = DecisionTreeRegressor()
  dtr.fit(x_train,y_train)
  dtr_pred = dtr.predict(x_test)
  return dtr_pred

def DecisionTreeRegression_fnc1(df,shifts,train_pct):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the  list of values for MSE
    print("\n Decision Tree Regression Model")
    DMSE=[] 
    df_lag = create_lags(df,shifts)
    df_lag = CorrectColumnTypes(df_lag)
    x_train, y_train, x_test, y_test, train, test = cv_SplitData(df, train_pct)
    dtr = DecisionTreeRegressor()
    tscv = TimeSeriesSplit(n_splits=5)
    scores = cross_val_score(dtr, x_train, y_train, cv=tscv, scoring='r2')
    tmp=mean(scores)
    DMSE.append(tmp)
    return DMSE

def BaggingRegressor_fnc(x_train,y_train, x_test, y_test):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the predicted values for the test data (list)
  #print("\n Bagging Regression Model")
  br = BaggingRegressor()
  br.fit(x_train,y_train)
  br_pred = br.predict(x_test)
  return br_pred

def BaggingRegressor_fnc1(df,shifts,train_pct):
  # inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the  list of values for MSE
  print("\n Bagging Regression Model")
  BMSE=[]
  df_lag = create_lags(df,shifts)
  df_lag = CorrectColumnTypes(df_lag)
  x_train, y_train, x_test, y_test, train, test = cv_SplitData(df, train_pct)
  br = BaggingRegressor()
  tscv = TimeSeriesSplit(n_splits=5)
  scores = cross_val_score(br, x_train, y_train, cv=tscv, scoring='r2')
  tmp=mean(scores)
  BMSE.append(tmp)
  return BMSE


def ExtraTreesRegressor_fnc(x_train,y_train, x_test, y_test):
  #inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the predicted values for the test data (list)
  #print("\n Extra Trees Regression Model")
  etr = RandomForestRegressor()
  etr.fit(x_train,y_train)
  etr_pred = etr.predict(x_test)
  return etr_pred


def ExtraTreesRegressor_fnc1(df,shifts,train_pct):
  #inputs: x train data, y train data, x test data, y test data (all dataframe's)
  # output: the  list of values for MSE
  print("\n Extra Trees Regression Model")
  EMSE=[]
  df_lag = create_lags(df,shifts)
  df_lag = CorrectColumnTypes(df_lag)
  x_train, y_train, x_test, y_test, train, test = cv_SplitData(df, train_pct)
  etr = RandomForestRegressor()
  tscv = TimeSeriesSplit(n_splits=5)
  scores = cross_val_score(etr, x_train, y_train, cv=tscv, scoring='r2')
  tmp=mean(scores)
  EMSE.append(tmp)
  return EMSE


def Calctradingdays(test_df,pred,j):# Calculates number of good trading days based on the model prediction
  # inputs: dataframe,predicted values, day
  # output: the number of good trading days
  pd.set_option('mode.chained_assignment', None)
  test_df['pred'] = np.nan
  test_df['pred'].iloc[:-j] = pred
  test_df['change'] = test_df['Close_lag'] - test_df['Close'] 
  test_df['change_pred'] = test_df['pred'] - test_df['Close'] 
  test_df['MadeMoney'] = np.where(test_df['change_pred']/test_df['change'] > 0, 1, -1) 
  test_df['profit'] = np.abs(test_df['change']) * test_df['MadeMoney']
  profit_dollars = test_df['profit'].sum()
  profit_days = len(test_df[test_df['MadeMoney'] == 1])
  tdays=round(profit_days/(len(test_df)-j),2)
  return tdays



def CalcProfit(test_df,pred,j): # Function to calculate aggregrate profit/loss made in the days
  # inputs: dataframe,predicted values, day
  # output: the aggregated profit/loss made in the predicted days(j)
  pd.set_option('mode.chained_assignment', None)
  test_df['pred'] = np.nan
  test_df['pred'].iloc[:-j] = pred
  test_df['change'] = test_df['Close_lag'] - test_df['Close'] 
  test_df['change_pred'] = test_df['pred'] - test_df['Close'] 
  test_df['MadeMoney'] = np.where(test_df['change_pred']/test_df['change'] > 0, 1, -1) 
  test_df['profit'] = np.abs(test_df['change']) * test_df['MadeMoney']
  profit_dollars = test_df['profit'].sum()
  pad=str(round(profit_dollars,1))
  print("\n Aggregated Profit/Loss Results")
  if pad[0]=='-':
      print('Loss: $ ' + str(round(profit_dollars,1)))
  else:
      print('Profit: $ ' + str(round(profit_dollars,1)))
  profit_days = len(test_df[test_df['MadeMoney'] == 1])
  td = str(round(profit_days/(len(test_df)-j),2)*100) 
  print('Percentage of good trading days: ' + str( round(profit_days/(len(test_df)-j),2)*100) )

  return test_df, profit_dollars,td
 

def disp_results(sfd,pa,tpd): # Displays important details after the graphs 
 # inputs: sfd(list), profit_dollars(list), goodtrade days(list)
 # output: None
  for i in range(len(sfd)):
    for j in range(len(pa)):
      for k in range(len(tpd)):
        if i==j and i==k and j==k :
          print("\n For Day {0} the aggregated profit/loss would be {1} and the estimated percentage of good trading days would be {2}".format(sfd[i],pa[j],tpd[k]))
        else:
          continue
  
def PlotModelProfit_Plotly(train, test, pred,shift_days,name,shift):  # Function to make the plots    
  # inputs: train dataframe, test dataframe, predicted value (list), shift size (int), name (string)
  # output: Graph
  w = 25 # width
  h = 25 # height
  # Create lines of the training actual, testing actual, prediction 
  D1 = go.Scatter(x=train.index,y=train['Profit/Loss (C)'],name = 'Actual Profit/Loss based on  Train data') # Training actuals
  D2 = go.Scatter(x=test.index[:shift],y=test['Profit/Loss (C)'],name = 'Actual Profit/Loss based on  Train data') # Testing actuals
  D3 = go.Scatter(x=test.index[:shift],y=pred,name = 'Predicted Profit/Loss from model') # Testing predction
  tickerSymbol="[Sim]F.US.GCEQ21"
  # Combine in an object  
  line = {'data': [D1,D2,D3],
          'layout': {
              'xaxis' :{'title': 'Date'},
              'yaxis' :{'title': 'Agregate Profit/Loss'},
              'title' : name + ' - ' + tickerSymbol + ' - ' + str(shift_days)
          }}
  # Send object to a figure 
  fig = go.Figure(line)

  # Show figure
  fig.show()

def create_dataframe(test,pa,tpd):
 # a=list(train['Profit/Loss (C)'])
  b=list(test['Profit/Loss (C)'])
  lst=zip(b,pa,tpd)
  df = pd.DataFrame(list(lst),columns =['Actual Profit/Loss for Train','Predicted Profit/Loss from model','Percenatge of good trading Days'])
  display(df)

def PlotModelResults_Plotly(train, test, pred,shift_days,name,shift):  # Function to make the plots    
  # inputs: train dataframe, test dataframe, predicted value (list), shift size (int), name (string)
  # output: Graph
  w = 25 # width
  h = 25 # height
  # Create lines of the training actual, testing actual, prediction 
  D1 = go.Scatter(x=train.index,y=train['Close'],name = 'Train Actual') # Training actuals
  D2 = go.Scatter(x=test.index[:shift],y=test['Close'],name = 'Test Actual') # Testing actuals
  D3 = go.Scatter(x=test.index[:shift],y=pred,name = 'Model Prediction') # Testing predction
  tickerSymbol="[Sim]F.US.GCEQ21"
  # Combine in an object  
  line = {'data': [D1,D2,D3],
          'layout': {
              'xaxis' :{'title': 'Date'},
              'yaxis' :{'title': 'Money'},
              'title' : name + ' - ' + tickerSymbol + ' - ' + str(shift_days)
          }}
  # Send object to a figure 
  fig = go.Figure(line)

  # Show figure
  fig.show()

def best_model(df,shifts,train_pct,bm):
  # inputs: train dataframe, list,train percenatge(float), best model name(str)
  # output: Number of good trading days calculated by the prediction made by the best model
  td=[]
  if bm=='Linear Regression':
    for j in shifts: 
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred = LinearRegression_fnc(x_train,y_train, x_test, y_test)
      temp=Calctradingdays(test,lr_pred,j)
      td.append(temp)
  elif bm=='K-Nearest Regression':
    for j in shifts: 
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred =KNearestRegression_fnc(x_train,y_train, x_test, y_test)
      temp=Calctradingdays(test,lr_pred,j)
      td.append(temp)
  elif bm=='Decision Tree Regression':
    for j in shifts: 
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred = DecisionTreeRegression_fnc(x_train,y_train, x_test, y_test)
      temp=Calctradingdays(test,lr_pred,j)
      td.append(temp)

  elif bm=='Bagging Regression':
    for j in shifts: 
      df_lag, shift = CreateLags(df,j)
      df_lag = CorrectColumnTypes(df_lag)
      x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
      lr_pred = BaggingRegressor_fnc(x_train,y_train, x_test, y_test)
      temp=Calctradingdays(test,lr_pred,j)
      td.append(temp)

  elif bm=='Extra Tree Regression':
      for j in shifts: 
        df_lag, shift = CreateLags(df,j)
        df_lag = CorrectColumnTypes(df_lag)
        x_train, y_train, x_test, y_test, train, test = SplitData(df, train_pct, shift)
        lr_pred = ExtraTreesRegressor_fnc(x_train,y_train, x_test, y_test)
        temp=Calctradingdays(test,lr_pred,j)
        td.append(temp)
  return shifts[td.index(max(td))]


def models_log(df,shifts,train_pct):
  # inputs: train dataframe, list,train percenatge(float)
  # output: The best model name which could be used for further evaluation 
  LMSE=[]
  KMSE=[]
  BMSE=[]
  DMSE=[]
  RMSE=[]
  EMSE=[]
  ovr=[]
  # Linear Regression
  LMSE = LinearRegression_fnc1(df,shifts,train_pct)
  # K-Neareast Neighbors
  KMSE =KNearestRegression_fnc1(df,shifts,train_pct)
  # DecisionTree Regression
  DMSE = DecisionTreeRegression_fnc1(df,shifts,train_pct)
  # Bagging Regression
  # BMSE = BaggingRegressor_fnc1(df,shifts,train_pct)
  # ExtraTrees Regression
  # EMSE=ExtraTreesRegressor_fnc1(df,shifts,train_pct)
  # Chossing the Best Model
  n=3# Number of Models Active
  bom=['Linear Regression','K-Nearest Regression','Decision Tree Regression','Bagging Regression','Extra Tree Regression']
  LR=int(sum(LMSE)/36500)
  KNR=int(sum(KMSE)/36500)
  DTR=int(sum(DMSE)/36500)
  #BR=int(sum(BMSE)/36500)
  EFR=int(sum(EMSE)/36500)
  print(" Mean R2 score after cross validation for Linear Regression for the entire list is {}".format(LR))
  print(" Mean R2 score after cross validation for K-Nearest Neighbors Regression for the entire list is {}".format(KNR))
  print(" Mean R2 score after cross validation for Decision Tree Regression for the entire list is {}".format(DTR))
  ovr.append(LR)
  ovr.append(KNR)
  ovr.append(DTR)
  #ovr.append(BR)
  #ovr.append(EFR)
  idx=minimum(ovr)
  return bom[idx]

def minimum(ovr):
  current_min = ovr[0]  
  for num in ovr:       
    if num < current_min:
      current_min = num  
  return ovr.index(current_min)

def process_2(pos,shft): # Creates a new list till the maximum limit
 # inputs: position of the maximum number of day for which the model is valid (int),list of days
 # output: Creates a new list containing the number of days for which the model remains valid
  shift=[]
  ele=pos+1
  for k in range(1,ele,1):
    shift.append(k)
  return shift

def logic(bp):
 # inputs: the dataframe of the best permutation
 # output: None
  print("\n welcome to model selection and prediction algorithm")
  shft=[] # Store number of days with a max limit of one year including multiples of seven which makes n week ,and also multiple of 28 which on the whole makes n month as( 4 weeks{4*7} make a month)
  for i in range(1,366): # Max limit for the number of days could be  based on the number of years so for time being i have enclosed the same as one year as 1year=365 days
    shft.append(i)
  train_pct =75
  train_pct=train_pct/100;
  print("\n Columns Format checking initialised")
  bp=CorrectColumnTypes(bp)
  bp1=bp.copy()
  print("\n Columns Format checking performed succesfully")
  bm=models_log(bp,shft,train_pct)
  print("\n The best Model for the given dataset after evaluation is {}".format(bm))
  pos=best_model(bp1,shft,train_pct,bm)
  print("The model {0} is valid for {1} days".format(bm,pos))
  sft=process_2(pos,shft)
  print(sft)
  calc_prof_plot(bp1,sft,pos,bm,train_pct)

def active_hour(bp):# Recursively activates the algorithm on an hourly basis
 # inputs: the dataframe of the best permutation
 # output: None
  from datetime import datetime, timedelta
  while 1:
    print("\n Initialising the Model Prediction Algorithm")
    logic(bp)

    dt = datetime.now() + timedelta(hours=1)
    dt = dt.replace(minute=59) # Recursively runs the code at the start of every hour

    while datetime.now() < dt:
        time.sleep(1)

"""**Part-2**"""

def slm_preprocess(bp):# processing the inputs for initialsing Stage-2
  #df=df.drop(["Date",	"Entry Price",	"Exit Price",	"Trade Quantity",	"Profit/Loss (C)",	"Duration",	"High Price While Open"	,"Low Price While Open",	"Total Efficiency","SIM","Day","Month","year",	"Time(Entry)"	,"DOW"], axis = 1, inplace = True)
  print("\n The unprocessed dataframe would be")
  display(bp)
  bp=bp.set_index('Date')
  bp = bp.reindex(['Open','High','Low','Close','Volume','Profit/Loss (C)'], axis=1)
  date_change = '%Y-%m-%d'
  bp['Date'] = bp.index
  bp['Date'] = pd.to_datetime(bp['Date'], format = date_change)
  Dates = bp['Date']
  bp = add_all_ta_features(bp, "Open", "High", "Low", "Close", "Volume", fillna=True) 
  #print(bp.columns)
  date_change = '%Y-%m-%d'
  # Define the date parts 
  fastai.tabular.add_datepart(bp,'Date', drop = 'True')
  # Ensure the correct format
  bp['Date'] = pd.to_datetime(bp.index.values, format = date_change)
  # Add the date parts
  fastai.tabular.add_cyclic_datepart(bp, 'Date', drop = 'True')
  print("\n The processed dataframe would be")
  display(bp)
  return bp

"""**Part-3**"""

def data_preprocess(df1,sim):
  df1['SIM']=str(sim)
  df1=df1.dropna(how='any')
  df1['Entry DateTime'] = pd.to_datetime(df1['Entry DateTime'])
  df1['Exit DateTime'] = pd.to_datetime(df1['Exit DateTime'])
  #df1['Day']=pd.to_datetime(df1['Entry DateTime']).dt.day
  #df1['Month']=pd.to_datetime(df1['Entry DateTime']).dt.month
  #df1['year']=pd.to_datetime(df1['Entry DateTime']).dt.year
  df1['Time(Entry)']=pd.to_datetime(df1['Entry DateTime']).dt.time
  #df['Time(Exit)']=pd.to_datetime(df['Exit DateTime']).dt.time
  df1['DOW']=pd.to_datetime(df1['Entry DateTime']).dt.day_name()#Type of day of the week
  df1["Entry DateTime"]=df1["Entry DateTime"].dt.strftime("%y-%m-%d")
  df1['Time(Entry)']=df1['Time(Entry)'].astype(str)
  df1['Time(Entry)']=(df1['Time(Entry)'].str.split(':').apply(lambda x: int(x[0]) * 60 + int(x[1]))).astype(int)
  df1['Duration']=df1['Duration'].astype(str)
  df1['Duration']=(df1['Duration'].str.split(':').apply(lambda x: int(x[0]) * 60 + int(x[1]))).astype(int)
  df1=df1.drop(columns=['Symbol','Trade Type','Exit DateTime','Max Open Quantity','Max Closed Quantity','Cumulative Profit/Loss (C)','Exit Efficiency','Entry Efficiency','FlatToFlat Profit/Loss (C)','FlatToFlat Max Open Profit (C)','FlatToFlat Max Open Loss (C)','Max Open Profit (C)','Max Open Loss (C)','Note','Commission (C)','Open Position Quantity','Close Position Quantity',])
  df1=df1.rename(columns ={'Entry DateTime':'Date',}, inplace = False)
  df1['Total Efficiency'] = list(map(lambda x: x[:-1], df1['Total Efficiency'].values))
  df1['Total Efficiency'] = [float(x) for x in df1['Total Efficiency'].values]
  df1['Profit/Loss (C)'] = list(map(lambda x: x[:-1], df1['Profit/Loss (C)'].values))
  df1['Profit/Loss (C)'] = [float(x) for x in df1['Profit/Loss (C)'].values]
  df1['Time(Entry)']=df1['Time(Entry)'].astype(int)
  return df1
  
def process(mn,day):  
   sim=['sim100','sim101','sim102','sim103','sim110','sim111','sim112','sim113','sim120','sim121','sim122','sim123','sim130','sim131','sim132','sim133']  
   dg=[]
   loc=['/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim100 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim101 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim102 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim103 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim110 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim111 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim112 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim113 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim120 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim121 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim122 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim123 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim130 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim131 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim132 Trades.txt','/content/GC AT IPS(2)+TM(A) 2016-05_2021 sim133 Trades.txt'] 
   for i in range(len(loc)):
     for j in range(len(sim)):
       if i==j:
         t= 'df' + '{}'.format(i)
         t=pd.read_csv('{}'.format(loc[i]),delimiter="\t")
         dg.append(t)
       else:
          continue
   print("\n The total number of permutations files is {}".format(len(dg)))
   df1=data_preprocess(dg[0],sim[0])
   df2=data_preprocess(dg[1],sim[1])
   df3=data_preprocess(dg[2],sim[2])
   df4=data_preprocess(dg[3],sim[3])
   df5=data_preprocess(dg[4],sim[4])
   df6=data_preprocess(dg[5],sim[5])
   df7=data_preprocess(dg[6],sim[6])
   df8=data_preprocess(dg[7],sim[7])
   df9=data_preprocess(dg[8],sim[8])
   df10=data_preprocess(dg[9],sim[9])
   df11=data_preprocess(dg[10],sim[10])
   df12=data_preprocess(dg[11],sim[11])
   df13=data_preprocess(dg[12],sim[12])
   df14=data_preprocess(dg[13],sim[13])
   df15=data_preprocess(dg[14],sim[14])
   df16=data_preprocess(dg[15],sim[15])
   pnl=[]
   te=[]
   fg=[df1,df2,df3,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16]
   for i in range(len(sim)):
    for j in range(len(fg)):
      if i==j:
        l,k=gather_details(mn,day,fg[j],sim[i])
        te.append(int(l))
        pnl.append(int(k))
      else:
        continue
   #print("\n" ,pnl)
   #print("\n" ,te)
   sm=process_1(te,pnl,sim)
   return sm
   #return df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16

def time_valid(tim): # Function to check validity of time
# inputs: time(str)
# ouptut: boolean value
  try:
      time.strptime(tim, '%H:%M:%S')
      return True
  except ValueError:
        return False

def calc_mins(tm):#Function to convert hrs ,mins,secs into minutes
# inputs: time in Hours,minutes,seconds
# ouptut: returns time in minutes
     if int(tm[0:1]) ==0 and int(tm[3:4])!=0 : #if time in am like 03:00:00 then answer should not be zero rather the answer should be 3*60=180 so this condito would oversee the same
        mn=int((int(tm[1:2])*60)+int(tm[3:5])+int(int(tm[6:8])/60))
     elif int(tm[3:4]) ==0 and int(tm[0:1]!=0): #if time in am like 13:06:00 then answer should not be zero rather the answer should be 13*60=180 + 6 so this condito would oversee the same
        mn=int((int(tm[0:2])*60)+int(tm[4:5])+int(int(tm[6:8])/60))
     elif int(tm[3:4]) ==0 and int(tm[0:1] ==0): #if time in am like 03:06:00 then answer should not be zero rather the answer should be 3*60=180 + 6 so this condito would oversee the same
        mn=int((int(tm[1:2])*60)+int(tm[4:5])+int(int(tm[6:8])/60))
     else:
        mn=int((int(tm[0:2])*60)+int(tm[3:5])+int(int(tm[6:8])/60))
     return mn
     
def gather_details(mn,day,df,s):
# inputs: minutes(int),day(str)
# ouptut: returns the best simulator type(str)
  tf=[]
  sim=[]
  pl=[]
  for i in range(len(df)):
    if df['DOW'][i] == day:
      if int(df['Time(Entry)'][i])<= int(mn):# This condition should be valid due to the fact that say a person whowants to invest in stocks would require the knowledge of the stocks trading in the earlier times(history of profit/loss for the  stock): same principle followed here
          tf.append(int(df['Total Efficiency'][i]))
          pl.append(int(df['Profit/Loss (C)'][i]))
          sim.append(s)
      else:
        continue
    else:
      continue
  if len(tf)!=0 and len(pl)!=0:
    Mt=sum(tf)
    Mp=sum(pl)
    return Mt,Mp
  else:
    Mt=0
    Mp=0
    return Mt,Mp
    
  
def process_1(Mt,Mp,sim):
  i=Mt.index(max(Mt))
  j=Mp.index(max(Mp))
  return sim[j] # Due to the fact that maximum profit/loss is exhibited by this permutation



def get_dataframe(sim):
# inputs: best simulator type 
# ouptut: returns the best permutaion dataframe based on simulator type 
  fn="/content/GC AT IPS(2)+TM(A) 2016-05_2021 {} Trades.txt".format(sim)
  bp=pd.read_csv(fn,delimiter="\t")
  bp=bp.dropna(how='any')
  bp=bp.reset_index(drop=True)
  #bp['DOW']=pd.to_datetime(bp['Entry DateTime']).dt.day_name()#Type of day of the week
  bp['Entry DateTime'] = pd.to_datetime(bp['Entry DateTime'])
  bp['Time(Entry)']=pd.to_datetime(bp['Entry DateTime']).dt.time
  bp["Entry DateTime"]=bp["Entry DateTime"].dt.strftime("%y-%m-%d")
  bp['Time(Entry)']=bp['Time(Entry)'].astype(str)
  bp['Time(Entry)']=(bp['Time(Entry)'].str.split(':').apply(lambda x: int(x[0]) * 60 + int(x[1]))).astype(int)
  bp=bp.drop(columns=['Symbol','Trade Type','Exit DateTime','Duration','Total Efficiency','Time(Entry)','Max Open Quantity','Max Closed Quantity','Cumulative Profit/Loss (C)','Exit Efficiency','Entry Efficiency','FlatToFlat Profit/Loss (C)','FlatToFlat Max Open Profit (C)','FlatToFlat Max Open Loss (C)','Max Open Profit (C)','Max Open Loss (C)','Note','Commission (C)','Open Position Quantity','Close Position Quantity',])
  bp=bp.rename(columns ={'Entry DateTime':'Date','Entry Price':'Open','Exit Price':'Close','High Price While Open':'High','Low Price While Open':'Low','Trade Quantity':'Volume'}, inplace = False)
  #bp['Total Efficiency'] = list(map(lambda x: x[:-1], bp['Total Efficiency'].values))
  #bp['Total Efficiency'] = [float(x) for x in bp['Total Efficiency'].values]
  #bp['Time(Entry)']=bp['Time(Entry)'].astype(int)
  bp['Profit/Loss (C)'] = list(map(lambda x: x[:-1], bp['Profit/Loss (C)'].values))
  bp['Profit/Loss (C)'] = [float(x) for x in bp['Profit/Loss (C)'].values]
  bp['Open']=bp['Open'].astype(int)
  bp['Close']=bp['Close'].astype(int)
  bp['Volume']=bp['Volume'].astype(int)
  bp['High']=bp['High'].astype(int)
  bp['Low']=bp['Low'].astype(int)
  return bp

def bp_process(bp):
# inputs: best permutation dataframe
# ouptut: returns the best permutaion dataframe with perfect stae format
  for i in range(len(bp)):
    tmp=bp['Date'][i]
    tmp="20"+tmp[0:2]+tmp[2:]
    bp['Date'][i]=tmp
  return bp


def welcome(): #  function to initialize
  print("\n Welcome to Stock Analysis")
  today=datetime.date.today()
  today=today.strftime('%d %m %Y')
  dy=datetime.datetime.strptime(today, '%d %m %Y').weekday()
  d=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']
  day=d[dy]
  print("The day of the week based on the date is {}".format(day))
  f1=['monday','tuesday','wednesday','thursday','friday','sunday','Monday','Tuesday','Wednesday','Thursday','Friday','Sunday','Saturday','saturday']
  if day in f1:
    day=day.capitalize()
    if day =='Sunday' or day == 'sunday':
      tim=datetime.datetime.now().time()
      tim=tim.strftime("%H:%M:%S")
      tmi=tim[0:8]
      if time_valid(tmi):
        print("\n Conversion of the time in 24 hours format (if in pm) hence the time after conversion would {}".format(tim))# converting to 24 hr format for ease of comparision with the primary permutation df
        mn=calc_mins(tmi)
        if mn>1000:
          print("\n Calculation of the time in Minutes based on the above performed conversion hence the time in minutes would be {}".format(mn))# useful for comparing with the entry time denoted in minutes (converted from 24 hr clock format)
          sim=process(mn,day)
          print("\n The best results for the day {} of the week  during time {} of the day is given by {} the permutation (dataset)".format(day,tim,sim))
          bp=get_dataframe(sim)
          bp=bp_process(bp)
          return bp
        else:
          print("\n Data not valid")
      else:
        print("\n Time Format invalid Please try again")
        sys.exit()
    else:
      tim=datetime.datetime.now().time()
      tim=tim.strftime("%H:%M:%S")
      tmi=tim[0:8]
      if time_valid(tmi):
        print("\n Conversion of the time in 24 hours format (if in pm) hence the time after conversion would {}".format(tim))# converting to 24 hr format for ease of comparision with the primary permutation df
        mn=calc_mins(tmi)
        print("\n Calculation of the time in Minutes based on the above performed conversion hence the time in minutes would be {}".format(mn))# useful for comparing with the entry time denoted in minutes (converted from 24 hr clock format)
        sim=process(mn,day)
        if sim==-1:
          print("\n Input Data not valid")
          sys.exit()
        else:
          print("\n The best results for the day {} of the week  during time {} of the day is given by {} the permutation (dataset)".format(day,tim,sim))
          bp=get_dataframe(sim)
          bp=bp_process(bp)
          bp.to_csv(r'Best Permutation file {}.csv'.format(sim), index=False)
          print("\n Local copy of the file is saved")
          return bp
      else:
        print("\n Time Format invalid Please try again")
        sys.exit()
  else:
     print("\n Invalid Format of day Please try again")
     sys.exit()

"""**Kindly execute the code cells Part-1 and Part-2 and Part-3 before executing the below code cell**"""

def main():
  bp=welcome()
  bp=slm_preprocess(bp)
  active_hour(bp)
main()